{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Classifier Validation\n",
    "\n",
    "Load a trained group classifier model and generate validation plots:\n",
    "- Load model from checkpoint\n",
    "- Load validation data\n",
    "- Generate predictions\n",
    "- Create evaluation plots (confusion matrices, ROC curves, precision-recall, loss curves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in &lt;module&gt;:14                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">pioneerml.data.loaders</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> load_preprocessed_time_groups                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">pioneerml.training.datamodules</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> GroupClassificationDataModule                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">pioneerml.training.lightning</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> GraphLightningModule                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>14 <span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">from</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold; text-decoration: underline\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">pioneerml.evaluation.plots</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold; text-decoration: underline\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">import</span><span style=\"font-weight: bold; text-decoration: underline\"> (</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"font-weight: bold; text-decoration: underline\">plot_loss_curves,</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"font-weight: bold; text-decoration: underline\">plot_multilabel_confusion_matrix,</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"font-weight: bold; text-decoration: underline\">plot_precision_recall_curves,</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ImportError: </span>cannot import name <span style=\"color: #008000; text-decoration-color: #008000\">'plot_confidence_analysis'</span> from <span style=\"color: #008000; text-decoration-color: #008000\">'pioneerml.evaluation.plots'</span> \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080\">/home/jack/python_projects/pioneerML/src/pioneerml/evaluation/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">plots.py</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in <module>:14                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mpioneerml\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mdata\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mloaders\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m load_preprocessed_time_groups                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mpioneerml\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mtraining\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mdatamodules\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m GroupClassificationDataModule                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mpioneerml\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mtraining\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mlightning\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m GraphLightningModule                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m14 \u001b[1;4;94mfrom\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;96mpioneerml\u001b[0m\u001b[1;4;96m.\u001b[0m\u001b[1;4;96mevaluation\u001b[0m\u001b[1;4;96m.\u001b[0m\u001b[1;4;96mplots\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;94mimport\u001b[0m\u001b[1;4m (\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;4mplot_loss_curves,\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;4mplot_multilabel_confusion_matrix,\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;4mplot_precision_recall_curves,\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mImportError: \u001b[0mcannot import name \u001b[32m'plot_confidence_analysis'\u001b[0m from \u001b[32m'pioneerml.evaluation.plots'\u001b[0m \n",
       "\u001b[1m(\u001b[0m\u001b[35m/home/jack/python_projects/pioneerML/src/pioneerml/evaluation/\u001b[0m\u001b[95mplots.py\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "from pioneerml.zenml import utils as zenml_utils\n",
    "from pioneerml.models.classifiers.group_classifier import GroupClassifier\n",
    "from pioneerml.data import CLASS_NAMES, NUM_GROUP_CLASSES\n",
    "from pioneerml.data.loaders import load_preprocessed_time_groups\n",
    "from pioneerml.training.datamodules import GroupClassificationDataModule\n",
    "from pioneerml.training.lightning import GraphLightningModule\n",
    "from pioneerml.evaluation.plots import (\n",
    "    plot_loss_curves,\n",
    "    plot_multilabel_confusion_matrix,\n",
    "    plot_precision_recall_curves,\n",
    "    plot_roc_curves,\n",
    "    plot_embedding_space,\n",
    "    plot_probability_distributions,\n",
    "    plot_confidence_analysis,\n",
    ")\n",
    "\n",
    "PROJECT_ROOT = zenml_utils.find_project_root()\n",
    "checkpoints_dir = Path(PROJECT_ROOT) / \"trained_models\" / \"group_classifier\"\n",
    "checkpoints_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Checkpoints directory: {checkpoints_dir}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Available Checkpoints\n",
    "\n",
    "Find all saved model checkpoints and their metadata files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all checkpoint files\n",
    "checkpoint_files = sorted(checkpoints_dir.glob(\"group_classifier_*.pt\"), reverse=True)\n",
    "metadata_files = sorted(checkpoints_dir.glob(\"group_classifier_*_metadata.json\"), reverse=True)\n",
    "\n",
    "print(f\"Found {len(checkpoint_files)} checkpoint(s):\")\n",
    "for i, ckpt in enumerate(checkpoint_files, 1):\n",
    "    print(f\"  {i}. {ckpt.name}\")\n",
    "    # Find corresponding metadata\n",
    "    timestamp = ckpt.stem.replace(\"group_classifier_\", \"\")\n",
    "    metadata_file = checkpoints_dir / f\"group_classifier_{timestamp}_metadata.json\"\n",
    "    if metadata_file.exists():\n",
    "        with open(metadata_file) as f:\n",
    "            meta = json.load(f)\n",
    "        print(f\"     Timestamp: {meta.get('timestamp', 'unknown')}\")\n",
    "        print(f\"     Run: {meta.get('run_name', 'unknown')}\")\n",
    "        if 'model_architecture' in meta:\n",
    "            arch = meta['model_architecture']\n",
    "            print(f\"     Architecture: hidden={arch.get('hidden')}, num_blocks={arch.get('num_blocks')}, dropout={arch.get('dropout')}\")\n",
    "\n",
    "# Select the most recent checkpoint by default\n",
    "selected_checkpoint = checkpoint_files[0] if checkpoint_files else None\n",
    "selected_metadata = None\n",
    "if selected_checkpoint:\n",
    "    timestamp = selected_checkpoint.stem.replace(\"group_classifier_\", \"\")\n",
    "    metadata_file = checkpoints_dir / f\"group_classifier_{timestamp}_metadata.json\"\n",
    "    if metadata_file.exists():\n",
    "        with open(metadata_file) as f:\n",
    "            selected_metadata = json.load(f)\n",
    "        print(f\"\\nSelected checkpoint: {selected_checkpoint.name}\")\n",
    "        print(f\"Metadata loaded from: {metadata_file.name}\")\n",
    "else:\n",
    "    print(\"\\nNo checkpoints found! Train a model first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "Reconstruct the model architecture from metadata and load the saved weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_checkpoint is None or selected_metadata is None:\n",
    "    raise ValueError(\"No checkpoint or metadata found. Please train a model first.\")\n",
    "\n",
    "# Extract model architecture from metadata\n",
    "arch = selected_metadata.get(\"model_architecture\", {})\n",
    "best_params = selected_metadata.get(\"best_hyperparameters\", {})\n",
    "\n",
    "# Use architecture params from metadata, fallback to best_params\n",
    "hidden = arch.get(\"hidden\") or best_params.get(\"hidden\", 192)\n",
    "num_blocks = arch.get(\"num_blocks\") or best_params.get(\"num_blocks\", 3)\n",
    "dropout = arch.get(\"dropout\") or best_params.get(\"dropout\", 0.1)\n",
    "num_classes = arch.get(\"num_classes\") or NUM_GROUP_CLASSES\n",
    "\n",
    "print(f\"Reconstructing model with:\")\n",
    "print(f\"  hidden: {hidden}\")\n",
    "print(f\"  num_blocks: {num_blocks}\")\n",
    "print(f\"  dropout: {dropout}\")\n",
    "print(f\"  num_classes: {num_classes}\")\n",
    "\n",
    "# Create model with same architecture\n",
    "model = GroupClassifier(\n",
    "    hidden=int(hidden),\n",
    "    num_blocks=int(num_blocks),\n",
    "    dropout=float(dropout),\n",
    "    num_classes=int(num_classes),\n",
    ")\n",
    "\n",
    "# Load state dict\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "state_dict = torch.load(selected_checkpoint, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\nModel loaded successfully on {device}\")\n",
    "print(f\"  Checkpoint: {selected_checkpoint.name}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Data\n",
    "\n",
    "Load the same data pattern used during training (or a subset for faster validation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "# Use the same file pattern as training, or specify a different one\n",
    "file_pattern = str(Path(PROJECT_ROOT) / \"data\" / \"mainTimeGroups_*.npy\")\n",
    "\n",
    "# For validation, use full available data (no limiting by default)\n",
    "validation_groups = load_preprocessed_time_groups(\n",
    "    file_pattern,\n",
    "    max_files=1,\n",
    "    limit_groups=None,\n",
    "    min_hits=2,\n",
    "    min_hits_per_label=2,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(validation_groups)} groups for validation\")\n",
    "\n",
    "# Create datamodule\n",
    "# val_split=0.0 means we use the full set (train split) for evaluation here\n",
    "# to avoid unintended downsampling that was previously happening.\n",
    "datamodule = GroupClassificationDataModule(\n",
    "    records=validation_groups,\n",
    "    num_classes=NUM_GROUP_CLASSES,\n",
    "    batch_size=128,\n",
    "    num_workers=0,  # Set to 0 for validation to avoid multiprocessing issues\n",
    "    val_split=0.0,\n",
    "    test_split=0.0,\n",
    "    seed=42,\n",
    ")\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n",
    "val_dataset = datamodule.val_dataset or datamodule.train_dataset\n",
    "if val_dataset is None:\n",
    "    raise ValueError(\"No validation dataset available\")\n",
    "\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions\n",
    "\n",
    "Run inference on the validation dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Create dataloader\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "# Generate predictions\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        batch = batch.to(device)\n",
    "        preds = model(batch)\n",
    "        all_predictions.append(preds.cpu())\n",
    "        all_targets.append(batch.y.cpu())\n",
    "\n",
    "# Concatenate all predictions and targets\n",
    "predictions = torch.cat(all_predictions, dim=0)\n",
    "targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "print(f\"Generated predictions:\")\n",
    "print(f\"  Predictions shape: {predictions.shape}\")\n",
    "print(f\"  Targets shape: {targets.shape}\")\n",
    "print(f\"  Predictions range: [{predictions.min():.4f}, {predictions.max():.4f}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Validation Plots\n",
    "\n",
    "Create comprehensive evaluation plots to assess model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for plots\n",
    "plots_dir = Path(PROJECT_ROOT) / \"artifacts\" / \"validation_plots\" / \"group_classifier\"\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp_str = selected_metadata.get(\"timestamp\", datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "plot_prefix = f\"group_classifier_{timestamp_str}\"\n",
    "\n",
    "# Get class names from metadata or use defaults\n",
    "dataset_info = selected_metadata.get(\"dataset_info\", {})\n",
    "class_names = dataset_info.get(\"class_names\", list(CLASS_NAMES.values()))\n",
    "\n",
    "print(f\"Generating validation plots in: {plots_dir}\")\n",
    "print(f\"Class names: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Confusion Matrix\n",
    "print(\"\\n1. Generating confusion matrix...\")\n",
    "confusion_path = plots_dir / f\"{plot_prefix}_confusion_matrix.png\"\n",
    "plot_multilabel_confusion_matrix(\n",
    "    predictions=predictions,\n",
    "    targets=targets,\n",
    "    class_names=class_names,\n",
    "    threshold=0.5,\n",
    "    normalize=True,\n",
    "    show=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ROC Curves\n",
    "print(\"\\n2. Generating ROC curves...\")\n",
    "roc_path = plots_dir / f\"{plot_prefix}_roc_curves.png\"\n",
    "plot_roc_curves(\n",
    "    predictions=predictions,\n",
    "    targets=targets,\n",
    "    class_names=class_names,\n",
    "    show=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Precision-Recall Curves\n",
    "print(\"\\n3. Generating precision-recall curves...\")\n",
    "pr_path = plots_dir / f\"{plot_prefix}_precision_recall.png\"\n",
    "plot_precision_recall_curves(\n",
    "    predictions=predictions,\n",
    "    targets=targets,\n",
    "    class_names=class_names,\n",
    "    show=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings from the model\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "model.eval()\n",
    "embeddings_list = []\n",
    "targets_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        batch = batch.to(device)\n",
    "        # Extract embeddings (before classification head)\n",
    "        emb = model.extract_embeddings(batch)\n",
    "        embeddings_list.append(emb.cpu())\n",
    "        targets_list.append(batch.y.cpu())\n",
    "\n",
    "# Concatenate all embeddings and targets\n",
    "embeddings = torch.cat(embeddings_list, dim=0)\n",
    "targets_for_emb = torch.cat(targets_list, dim=0)\n",
    "\n",
    "# Ensure targets align with embeddings (handle flattened labels)\n",
    "if targets_for_emb.dim() == 1 and embeddings.shape[0] > 0:\n",
    "    if targets_for_emb.numel() % embeddings.shape[0] == 0:\n",
    "        targets_for_emb = targets_for_emb.view(embeddings.shape[0], -1)\n",
    "\n",
    "print(f\"Extracted embeddings:\")\n",
    "print(f\"  Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"  Targets shape: {targets_for_emb.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Space Visualization (t-SNE)\n",
    "\n",
    "Visualize the learned embedding space using t-SNE to see how well the model separates different particle types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pioneerml.evaluation.plots import plot_embedding_space\n",
    "\n",
    "print(\"\\nGenerating embedding space visualization (t-SNE)...\")\n",
    "embedding_path = plots_dir / f\"{plot_prefix}_embedding_space_tsne.png\"\n",
    "plot_embedding_space(\n",
    "    embeddings=embeddings,\n",
    "    targets=targets_for_emb,\n",
    "    class_names=class_names,\n",
    "    method=\"tsne\",\n",
    "    perplexity=30.0,\n",
    "    n_components=2,\n",
    "    #save_path=embedding_path,\n",
    "    show=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Distributions\n",
    "\n",
    "Show how well separated the probability distributions are for each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pioneerml.evaluation.plots import plot_probability_distributions\n",
    "\n",
    "print(\"\\nGenerating probability distribution plots...\")\n",
    "plot_probability_distributions(\n",
    "    predictions=predictions,\n",
    "    targets=targets,\n",
    "    class_names=class_names,\n",
    "    show=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Analysis\n",
    "\n",
    "Analyze model confidence through entropy and max probability metrics to understand prediction reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pioneerml.evaluation.plots import plot_confidence_analysis\n",
    "\n",
    "print(\"\\nGenerating confidence analysis plots...\")\n",
    "plot_confidence_analysis(\n",
    "    predictions=predictions,\n",
    "    targets=targets,\n",
    "    class_names=class_names,\n",
    "    show=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pioneerml)",
   "language": "python",
   "name": "pioneerml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
