{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b3c7dd",
   "metadata": {},
   "source": [
    "# Tutorial 1: Building ZenML Pipelines\n",
    "\n",
    "Learn how our tutorial pipelines are structured, trigger a run, and inspect\n",
    "the outputs produced by ZenML.\n",
    "\n",
    "What you'll see:\n",
    "- How to define ZenML steps/pipelines inline (no hidden magic).\n",
    "- How materializers control artifact serialization to avoid noisy warnings.\n",
    "- What each step contributes and how ZenML wires inputs/outputs.\n",
    "- A quick sanity-check metric and how to interpret the basic training run.\n",
    "\n",
    "Reading the notebook:\n",
    "- Markdown above each block explains inputs/outputs and why the code is there.\n",
    "- Pay attention to device placement when reloading artifacts (CPU vs GPU).\n",
    "- Treat the final accuracy as a smoke test, not a benchmark (synthetic data).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c068578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active ZenML stack: default\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from zenml import pipeline, step\n",
    "from zenml.utils import source_utils\n",
    "\n",
    "from pioneerml.models import GroupClassifier\n",
    "from pioneerml.training import GraphDataModule, GraphLightningModule, plot_loss_curves\n",
    "from pioneerml.zenml.materializers import (\n",
    "    GraphDataModuleMaterializer,\n",
    "    PyGDataListMaterializer,\n",
    ")\n",
    "from pioneerml.zenml.utils import detect_available_accelerator, load_step_output\n",
    "import pioneerml.zenml.utils as zenml_utils\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    \"\"\"Walk upward to locate the repo root (pyproject or .git).\"\"\"\n",
    "    start = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd().resolve()\n",
    "    for path in [start] + list(start.parents):\n",
    "        if (path / \"pyproject.toml\").exists() or (path / \".git\").exists():\n",
    "            return path\n",
    "    return start\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "source_utils.set_custom_source_root(PROJECT_ROOT / \"src\")\n",
    "\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(root_path=PROJECT_ROOT, use_in_memory=True)\n",
    "print(f\"Active ZenML stack: {zenml_client.active_stack_model.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eea712",
   "metadata": {},
   "source": [
    "## Define the basic training pipeline\n",
    "Build the steps directly in the notebook so you can see how ZenML pipelines\n",
    "are composed. The cell below walks through every piece:\n",
    "- `create_data`: synthetic graphs for a 3-class task, saved with a custom\n",
    "  materializer to avoid pickle spam.\n",
    "- `create_datamodule`: splits into train/val and sets sane batch/worker sizes.\n",
    "- `create_model` / `create_lightning_module`: model + Lightning wrapper.\n",
    "- `train_model`: short CPU/GPU-friendly fit with caching disabled.\n",
    "\n",
    "Inputs/outputs:\n",
    "- Steps communicate via return values; ZenML handles wiring.\n",
    "- Materializers specify how to serialize outputs; here we use lightweight\n",
    "  torch saves to keep artifact warnings quiet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96754ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_simple_synthetic_data(num_samples: int = 200) -> list[Data]:\n",
    "    \"\"\"Generate clustered graphs so the model can learn a clear signal.\"\"\"\n",
    "    class_offsets = torch.tensor(\n",
    "        [\n",
    "            [2.0, 0.0, 0.5, 0.0, 0.0],   # pi cluster: boost feature 0\n",
    "            [0.0, 2.0, 0.0, 0.5, 0.0],   # mu cluster: boost feature 1\n",
    "            [-2.0, -2.0, -0.5, 0.0, 0.5],  # e+ cluster: negative drift\n",
    "        ]\n",
    "    )\n",
    "    data: list[Data] = []\n",
    "    for _ in range(num_samples):\n",
    "        num_nodes = torch.randint(6, 10, (1,)).item()\n",
    "        label = torch.randint(0, 3, (1,)).item()\n",
    "\n",
    "        # Clustered node features with light noise make class boundaries learnable.\n",
    "        x = torch.randn(num_nodes, 5) * 0.4 + class_offsets[label]\n",
    "\n",
    "        # Random edges with low-variance attributes keep the task simple.\n",
    "        edge_index = torch.randint(0, num_nodes, (2, num_nodes * 3))\n",
    "        edge_attr = torch.randn(edge_index.shape[1], 4) * 0.3\n",
    "\n",
    "        y = torch.zeros(3)\n",
    "        y[label] = 1.0\n",
    "        data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n",
    "    return data\n",
    "\n",
    "\n",
    "@step(output_materializers=PyGDataListMaterializer, enable_cache=False)\n",
    "def create_data() -> list[Data]:\n",
    "    return create_simple_synthetic_data()\n",
    "\n",
    "\n",
    "@step(output_materializers=GraphDataModuleMaterializer, enable_cache=False)\n",
    "def create_datamodule(data: list[Data]) -> GraphDataModule:\n",
    "    # Slightly larger batch for faster iteration; keep workers=0 for portability/sandboxed runs.\n",
    "    return GraphDataModule(dataset=data, val_split=0.2, batch_size=32, num_workers=0)\n",
    "\n",
    "\n",
    "@step\n",
    "def create_model(num_classes: int = 3) -> GroupClassifier:\n",
    "    # Smaller hidden dim/block count to keep the tutorial quick on CPU.\n",
    "    return GroupClassifier(num_classes=num_classes, hidden=64, num_blocks=1)\n",
    "\n",
    "\n",
    "@step\n",
    "def create_lightning_module(model: GroupClassifier) -> GraphLightningModule:\n",
    "    return GraphLightningModule(model, task=\"classification\", lr=1e-3)\n",
    "\n",
    "\n",
    "@step\n",
    "def train_model(lightning_module: GraphLightningModule, datamodule: GraphDataModule) -> GraphLightningModule:\n",
    "    import pytorch_lightning as pl\n",
    "\n",
    "    accelerator, devices = detect_available_accelerator()\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        max_epochs=3,\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.fit(lightning_module, datamodule=datamodule)\n",
    "    return lightning_module.eval()\n",
    "\n",
    "\n",
    "@pipeline\n",
    "def basic_training_pipeline_demo():\n",
    "    data = create_data()\n",
    "    datamodule = create_datamodule(data)\n",
    "    model = create_model()\n",
    "    lightning_module = create_lightning_module(model)\n",
    "    trained_module = train_model(lightning_module, datamodule)\n",
    "    return trained_module, datamodule\n",
    "\n",
    "\n",
    "# Reuse the packaged pipeline implementation for execution while keeping the\n",
    "# definition above for learning purposes.\n",
    "from pioneerml.zenml.pipelines.tutorial_examples.basic_training import (\n",
    "    basic_training_pipeline as packaged_basic_training_pipeline,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14070dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mInitiating a new run for the pipeline: \u001b[0m\u001b[38;5;105mbasic_training_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mRegistered new pipeline: \u001b[0m\u001b[38;5;105mbasic_training_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mCaching is disabled by default for \u001b[0m\u001b[38;5;105mbasic_training_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mUsing user: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mUsing stack: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  artifact_store: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  orchestrator: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  deployer: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mYou can visualize your pipeline runs in the \u001b[0m\u001b[38;5;105mZenML Dashboard\u001b[37m. In order to try it locally, please run \u001b[0m\u001b[38;5;105mzenml login --local\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_data\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_data\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.265s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_model\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.247s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_datamodule\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_datamodule\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.172s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_lightning_module\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_lightning_module\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.143s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_model\u001b[37m has started.\u001b[0m\n",
      "\u001b[37m[train_model] GPU available: False, used: False\u001b[0m\n",
      "\u001b[37m[train_model] TPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[37m[train_model] \n",
      "  | Name    | Type              | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model   | GroupClassifier   | 55.1 K | train\n",
      "1 | loss_fn | BCEWithLogitsLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\u001b[0m\n",
      "\u001b[37m[train_model] \u001b[0m\u001b[38;5;105mTrainer.fit\u001b[37m stopped: \u001b[0m\u001b[38;5;105mmax_epochs=3\u001b[37m reached.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m2.811s\u001b[37m.\u001b[0m\n",
      "\u001b[37mPipeline run has finished in \u001b[0m\u001b[38;5;105m6.412s\u001b[37m.\u001b[0m\n",
      "Pipeline run basic_training_pipeline-2025_11_25-04_20_25_609074 status: completed\n"
     ]
    }
   ],
   "source": [
    "run = packaged_basic_training_pipeline.with_options(enable_cache=False)()\n",
    "print(f\"Pipeline run {run.name} status: {run.status}\")\n",
    "\n",
    "# Load artifacts from the run so we can inspect them locally\n",
    "trained_module = load_step_output(run, \"train_model\")\n",
    "datamodule = load_step_output(run, \"create_datamodule\")\n",
    "model = getattr(trained_module, \"model\", None) if trained_module is not None else None\n",
    "\n",
    "if trained_module is None or datamodule is None:\n",
    "    raise RuntimeError(\"Could not load artifacts from the basic_training_pipeline run.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trained_module = trained_module.to(device).eval()\n",
    "datamodule.setup(stage=\"fit\")\n",
    "plot_loss_curves(trained_module, title=\"Tutorial 1: Loss Curves\", show=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7684f",
   "metadata": {},
   "source": [
    "## Inspect the outputs\n",
    "Check the dataset size, batch shape, and key model parameters. This helps\n",
    "validate that the data/materializers round-tripped correctly and that the\n",
    "model config is what we expect.\n",
    "- Dataset size: confirms split sizes match expectations.\n",
    "- Batch shape: confirms node/edge dimensions align with model input.\n",
    "- Model config: sanity check on hidden dim and class count.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b0e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "- Run: basic_training_pipeline-2025_11_25-04_20_25_609074\n",
      "- Device: cpu\n",
      "- Dataset size: 200 samples (train=160, val=40)\n",
      "- Batch shape: x=(184, 5), edge_index=(2, 368)\n",
      "Model configuration:\n",
      "- Type: GroupClassifier\n",
      "- Hidden dimension: 64\n",
      "- Num classes: 3\n"
     ]
    }
   ],
   "source": [
    "device = next(trained_module.parameters()).device\n",
    "train_loader = datamodule.train_dataloader()\n",
    "first_batch = next(iter(train_loader))\n",
    "train_size = len(datamodule.train_dataset) if datamodule.train_dataset is not None else 0\n",
    "val_size = len(datamodule.val_dataset) if datamodule.val_dataset is not None else 0\n",
    "\n",
    "print(\"Training summary:\")\n",
    "print(f\"- Run: {run.name}\")\n",
    "print(f\"- Device: {device}\")\n",
    "print(f\"- Dataset size: {train_size + val_size} samples (train={train_size}, val={val_size})\")\n",
    "print(f\"- Batch shape: x={tuple(first_batch.x.shape)}, edge_index={tuple(first_batch.edge_index.shape)}\")\n",
    "\n",
    "if model:\n",
    "    print(\"Model configuration:\")\n",
    "    print(f\"- Type: {type(model).__name__}\")\n",
    "    print(f\"- Hidden dimension: {getattr(model, 'hidden', 'n/a')}\")\n",
    "    print(f\"- Num classes: {getattr(model, 'num_classes', 'n/a')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95626a27",
   "metadata": {},
   "source": [
    "## Evaluate quickly on the validation split\n",
    "Use the trained module to compute a lightweight accuracy metric so we have\n",
    "a sanity check that training worked. Accuracy here is on a tiny synthetic\n",
    "validation set, so treat it as a smoke test rather than a real benchmark.\n",
    "\n",
    "Metric details:\n",
    "- Inputs: logits from the model vs one-hot labels.\n",
    "- Computation: argmax over logits and labels → class IDs → compare for exact\n",
    "  match, averaged over the validation set.\n",
    "- Interpretation: >0.33 means the model is learning above random (3 classes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85505554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy (quick check): 0.350\n"
     ]
    }
   ],
   "source": [
    "val_loader = datamodule.val_dataloader()\n",
    "if isinstance(val_loader, list) and len(val_loader) == 0:\n",
    "    val_loader = datamodule.train_dataloader()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for batch in val_loader:\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = trained_module(batch)\n",
    "    labels = batch.y\n",
    "    if labels.dim() == 1 and logits.shape[-1] > 0 and labels.numel() % logits.shape[-1] == 0:\n",
    "        labels = labels.view(-1, logits.shape[-1])\n",
    "    if labels.dim() > 1:\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    correct += int((preds == labels).sum().item())\n",
    "    total += int(labels.numel())\n",
    "\n",
    "accuracy = correct / total if total else 0.0\n",
    "print(f\"Validation accuracy (quick check): {accuracy:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pioneerml)",
   "language": "python",
   "name": "pioneerml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
