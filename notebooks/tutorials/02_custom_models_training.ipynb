{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Tutorial 2: Custom Models and Training\n",
    "\n",
    "This tutorial demonstrates how to define a custom Graph Convolutional Network (GCN)\n",
    "and integrate it into a ZenML pipeline. You'll learn:\n",
    "\n",
    "- How to build a custom GCN model from scratch\n",
    "- How to structure the model to work with PyTorch Geometric\n",
    "- How to wrap your custom model in a ZenML pipeline\n",
    "- How to train and evaluate the custom model\n",
    "\n",
    "**Why custom models?** While PIONEER ML provides pre-built models like `GroupClassifier`,\n",
    "you may want to experiment with different architectures. This tutorial shows you how to\n",
    "create your own graph neural network and seamlessly integrate it into the ZenML workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe current repo active project is no longer available.\u001b[0m\n",
      "\u001b[37mSetting the repo active project to 'default'.\u001b[0m\n",
      "\u001b[33mThe current repo active stack is no longer available. Resetting the active stack to default.\u001b[0m\n",
      "ZenML initialized with stack: default\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from zenml import pipeline, step\n",
    "\n",
    "from pioneerml.models.base import GraphModel\n",
    "from pioneerml.training import GraphDataModule, GraphLightningModule\n",
    "from pioneerml.zenml.materializers import (\n",
    "    GraphDataModuleMaterializer,\n",
    "    PyGDataListMaterializer,\n",
    ")\n",
    "from pioneerml.zenml import load_step_output\n",
    "from pioneerml.zenml import utils as zenml_utils\n",
    "from pioneerml.zenml.utils import detect_available_accelerator\n",
    "\n",
    "# Initialize ZenML for notebook use\n",
    "# setup_zenml_for_notebook automatically finds the project root by searching\n",
    "# upward for .zen or .zenml directories, ensuring we use the root configuration.\n",
    "# use_in_memory=True creates a temporary in-memory SQLite store, perfect for\n",
    "# tutorials where we don't need persistent artifact storage.\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(use_in_memory=True)\n",
    "print(f\"ZenML initialized with stack: {zenml_client.active_stack_model.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_explanation",
   "metadata": {},
   "source": [
    "## Define a Custom Graph Convolutional Network\n",
    "\n",
    "We'll create a simple but effective GCN model for graph classification. The architecture\n",
    "consists of:\n",
    "\n",
    "1. **Two GCN layers**: Each layer aggregates information from neighboring nodes\n",
    "   - First layer: Projects 5D node features \u2192 hidden dimension (64)\n",
    "   - Second layer: Further refines node representations within the hidden space\n",
    "\n",
    "2. **Global mean pooling**: Aggregates all node features into a single graph-level\n",
    "   representation by taking the mean across all nodes\n",
    "\n",
    "3. **Classifier head**: A linear layer that maps the graph representation to class\n",
    "   logits (3 classes: \u03c0, \u03bc, e+)\n",
    "\n",
    "**Why this architecture?** GCNs are excellent for learning from graph-structured data\n",
    "because they respect the graph topology - nodes learn representations based on their\n",
    "neighbors. Global pooling allows us to make graph-level predictions from node features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "custom_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom GCN model created: 4,739 parameters\n"
     ]
    }
   ],
   "source": [
    "class SimpleGCN(GraphModel):\n",
    "    \"\"\"A simple custom Graph Convolutional Network for graph classification.\n",
    "    \n",
    "    This model demonstrates the core components of a GCN:\n",
    "    - Graph convolution layers that aggregate neighbor information\n",
    "    - Global pooling to create graph-level representations\n",
    "    - A classifier head for final predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes: int = 3, hidden_dim: int = 64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First GCN layer: projects 5D node features to hidden dimension\n",
    "        # GCNConv learns to aggregate information from each node's neighbors\n",
    "        self.conv1 = GCNConv(5, hidden_dim)\n",
    "        \n",
    "        # Second GCN layer: refines node representations within hidden space\n",
    "        # This allows the model to learn more complex patterns in the graph structure\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Classifier head: maps graph-level representation to class logits\n",
    "        # Output size matches number of classes (3 for \u03c0, \u03bc, e+)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Forward pass through the GCN.\n",
    "        \n",
    "        Args:\n",
    "            batch: PyTorch Geometric Batch object containing:\n",
    "                - x: Node features [num_nodes, 5]\n",
    "                - edge_index: Edge connectivity [2, num_edges]\n",
    "                - batch: Batch assignment vector [num_nodes]\n",
    "        \n",
    "        Returns:\n",
    "            Logits for each graph in the batch [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        # Extract graph components from the batch\n",
    "        x, edge_index, batch_indices = batch.x, batch.edge_index, batch.batch\n",
    "\n",
    "        # First graph convolution: aggregate neighbor features\n",
    "        # ReLU activation introduces non-linearity\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        \n",
    "        # Second graph convolution: further refine node representations\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "\n",
    "        # Global mean pooling: aggregate all node features into a single vector\n",
    "        # This creates one representation per graph in the batch\n",
    "        # Shape: [batch_size, hidden_dim]\n",
    "        x = global_mean_pool(x, batch_indices)\n",
    "\n",
    "        # Final classification: map graph representation to class logits\n",
    "        # Shape: [batch_size, num_classes]\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "# Verify the model can be instantiated\n",
    "model = SimpleGCN(num_classes=3, hidden_dim=64)\n",
    "print(f\"Custom GCN model created: {model.num_parameters:,} parameters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline_explanation",
   "metadata": {},
   "source": [
    "## Build the Training Pipeline\n",
    "\n",
    "Now we'll create a complete ZenML pipeline that uses our custom GCN model. The pipeline\n",
    "follows the same structure as Tutorial 1:\n",
    "\n",
    "1. **`create_data`**: Generates synthetic graph data with class labels\n",
    "2. **`create_datamodule`**: Splits data into train/validation sets\n",
    "3. **`create_model`**: Instantiates our custom SimpleGCN\n",
    "4. **`create_lightning_module`**: Wraps the model in PyTorch Lightning\n",
    "5. **`train_model`**: Executes the training loop\n",
    "\n",
    "**Key difference from Tutorial 1**: Here we use our custom `SimpleGCN` instead of the\n",
    "pre-built `GroupClassifier`. Everything else works exactly the same - this demonstrates\n",
    "the flexibility of the ZenML + GraphModel architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pipeline_definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_synthetic_data(num_samples: int = 150) -> list[Data]:\n",
    "    \"\"\"Generate synthetic graph data for the custom model.\n",
    "    \n",
    "    Creates graphs with random node features and edges, each labeled with\n",
    "    one of three classes (\u03c0, \u03bc, e+).\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        # Create graphs with 4-8 nodes\n",
    "        num_nodes = torch.randint(4, 9, (1,)).item()\n",
    "        \n",
    "        # Random node features (5D: coord, z, energy, view, group_energy)\n",
    "        x = torch.randn(num_nodes, 5)\n",
    "        \n",
    "        # Random edge connectivity\n",
    "        edge_index = torch.randint(0, num_nodes, (2, num_nodes * 2))\n",
    "        edge_attr = torch.randn(edge_index.shape[1], 4)\n",
    "\n",
    "        # Random class label (one-hot encoded)\n",
    "        label = torch.randint(0, 3, (1,)).item()\n",
    "        y = torch.zeros(3)\n",
    "        y[label] = 1.0\n",
    "\n",
    "        data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n",
    "    return data\n",
    "\n",
    "\n",
    "@step(output_materializers=PyGDataListMaterializer, enable_cache=False)\n",
    "def create_data() -> list[Data]:\n",
    "    \"\"\"Step 1: Generate synthetic graph data.\n",
    "    \n",
    "    The PyGDataListMaterializer ensures efficient serialization of PyTorch Geometric\n",
    "    Data objects, avoiding pickle warnings.\n",
    "    \"\"\"\n",
    "    return create_simple_synthetic_data()\n",
    "\n",
    "\n",
    "@step(output_materializers=GraphDataModuleMaterializer, enable_cache=False)\n",
    "def create_datamodule(data: list[Data]) -> GraphDataModule:\n",
    "    \"\"\"Step 2: Create data module with train/val split.\n",
    "    \n",
    "    - val_split=0.3: 70% train, 30% validation\n",
    "    - batch_size=16: smaller batches for the custom model\n",
    "    \"\"\"\n",
    "    return GraphDataModule(dataset=data, val_split=0.3, batch_size=16, num_workers=0)\n",
    "\n",
    "\n",
    "@step\n",
    "def create_model(num_classes: int = 3, hidden_dim: int = 64) -> SimpleGCN:\n",
    "    \"\"\"Step 3: Instantiate our custom GCN model.\n",
    "    \n",
    "    This step creates the SimpleGCN we defined above with the specified\n",
    "    number of classes and hidden dimension.\n",
    "    \"\"\"\n",
    "    return SimpleGCN(num_classes=num_classes, hidden_dim=hidden_dim)\n",
    "\n",
    "\n",
    "@step\n",
    "def create_lightning_module(model: SimpleGCN) -> GraphLightningModule:\n",
    "    \"\"\"Step 4: Wrap model in PyTorch Lightning module.\n",
    "    \n",
    "    Adds training logic, loss function (BCE for multilabel classification),\n",
    "    and optimizer configuration.\n",
    "    \"\"\"\n",
    "    return GraphLightningModule(model, task=\"classification\", lr=5e-4)\n",
    "\n",
    "\n",
    "@step\n",
    "def train_model(\n",
    "    lightning_module: GraphLightningModule,\n",
    "    datamodule: GraphDataModule\n",
    ") -> GraphLightningModule:\n",
    "    \"\"\"Step 5: Execute training loop.\n",
    "    \n",
    "    Automatically detects available hardware (CPU/GPU) and runs for 5 epochs.\n",
    "    Returns the trained module in eval mode.\n",
    "    \"\"\"\n",
    "    import pytorch_lightning as pl\n",
    "\n",
    "    accelerator, devices = detect_available_accelerator()\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        max_epochs=5,\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    trainer.fit(lightning_module, datamodule=datamodule)\n",
    "    return lightning_module.eval()\n",
    "\n",
    "\n",
    "@pipeline\n",
    "def custom_model_pipeline():\n",
    "    \"\"\"Compose all steps into a complete training pipeline.\n",
    "    \n",
    "    ZenML automatically wires the outputs of one step to the inputs of the next\n",
    "    based on parameter names. For example, `create_datamodule(data)` receives\n",
    "    the output from `create_data()`.\n",
    "    \"\"\"\n",
    "    data = create_data()\n",
    "    datamodule = create_datamodule(data)\n",
    "    model = create_model()\n",
    "    lightning_module = create_lightning_module(model)\n",
    "    trained_module = train_model(lightning_module, datamodule)\n",
    "    return trained_module, datamodule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_pipeline",
   "metadata": {},
   "source": [
    "## Run the Pipeline\n",
    "\n",
    "Execute the pipeline and load the trained model. After the pipeline completes, we load\n",
    "the trained model and datamodule using `load_step_output`. These artifacts are stored\n",
    "by ZenML and can be reloaded anytime without re-running the pipeline.\n",
    "\n",
    "**Why use `enable_cache=False`?** This ensures the pipeline runs fresh each time,\n",
    "which is useful for tutorials. In production, you'd typically enable caching to\n",
    "skip re-running unchanged steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "run",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mInitiating a new run for the pipeline: \u001b[0m\u001b[38;5;105mcustom_model_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mRegistered new pipeline: \u001b[0m\u001b[38;5;105mcustom_model_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mCaching is disabled by default for \u001b[0m\u001b[38;5;105mcustom_model_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mUsing user: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mUsing stack: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  artifact_store: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  orchestrator: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  deployer: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mYou can visualize your pipeline runs in the \u001b[0m\u001b[38;5;105mZenML Dashboard\u001b[37m. In order to try it locally, please run \u001b[0m\u001b[38;5;105mzenml login --local\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_data\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_data\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.086s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_model\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.047s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_datamodule\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_datamodule\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.050s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_lightning_module\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_lightning_module\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.047s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_model\u001b[37m has started.\u001b[0m\n",
      "\u001b[37m[train_model] GPU available: True (cuda), used: True\u001b[0m\n",
      "\u001b[37m[train_model] TPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[37m[train_model] You are using a CUDA device ('NVIDIA GeForce RTX 3060 Ti') that has Tensor Cores. To properly utilize them, you should set \u001b[0m\u001b[38;5;105mtorch.set_float32_matmul_precision('medium' | 'high')\u001b[37m which will trade-off precision for performance. For more details, read \u001b[0m\u001b[34mhttps://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html\u001b[37m#torch.set_float32_matmul_precision\u001b[0m\n",
      "\u001b[37m[train_model] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
      "\u001b[37m[train_model] \n",
      "  | Name    | Type              | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model   | SimpleGCN         | 4.7 K  | train\n",
      "1 | loss_fn | BCEWithLogitsLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "4.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.7 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\u001b[0m\n",
      "\u001b[33m[train_model] /home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \u001b[0m\u001b[38;5;105mnum_workers\u001b[33m argument\u001b[0m\u001b[38;5;105m to \u001b[33mnum_workers=15\u001b[0m\u001b[38;5;105m in the \u001b[33mDataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "\u001b[33m[train_model] /home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \u001b[0m\u001b[38;5;105mnum_workers\u001b[33m argument\u001b[0m\u001b[38;5;105m to \u001b[33mnum_workers=15\u001b[0m\u001b[38;5;105m in the \u001b[33mDataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "\u001b[37m[train_model] \u001b[0m\u001b[38;5;105mTrainer.fit\u001b[37m stopped: \u001b[0m\u001b[38;5;105mmax_epochs=5\u001b[37m reached.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m1.233s\u001b[37m.\u001b[0m\n",
      "\u001b[37mPipeline run has finished in \u001b[0m\u001b[38;5;105m2.551s\u001b[37m.\u001b[0m\n",
      "Pipeline run status: completed\n",
      "Loaded artifacts from run custom_model_pipeline-2025_11_25-08_43_57_031350 (device=cpu)\n"
     ]
    }
   ],
   "source": [
    "run = custom_model_pipeline.with_options(enable_cache=False)()\n",
    "print(f\"Pipeline run status: {run.status}\")\n",
    "\n",
    "# Load artifacts from the run\n",
    "trained_module = load_step_output(run, \"train_model\")\n",
    "datamodule = load_step_output(run, \"create_datamodule\")\n",
    "custom_model = load_step_output(run, \"create_model\")\n",
    "\n",
    "if trained_module is None or datamodule is None or custom_model is None:\n",
    "    raise RuntimeError(\"Could not load artifacts from the custom_model_pipeline run.\")\n",
    "\n",
    "# Move model to best available device\n",
    "# Note: Models saved by ZenML may be on CPU. We move to GPU if available\n",
    "# to match the training device and speed up inference.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trained_module = trained_module.to(device).eval()\n",
    "datamodule.setup(stage=\"fit\")\n",
    "print(f\"Loaded artifacts from run {run.name} (device={device})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect_model",
   "metadata": {},
   "source": [
    "## Inspect the Custom Model\n",
    "\n",
    "Let's examine the trained model to understand its structure and verify it trained\n",
    "correctly. We'll check:\n",
    "\n",
    "- **Parameter count**: How many trainable parameters does our custom GCN have?\n",
    "- **Input/output shapes**: What dimensions does the model expect and produce?\n",
    "- **Device placement**: Where is the model running (CPU/GPU)?\n",
    "\n",
    "This helps validate that the model architecture is correct and that training completed\n",
    "successfully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom GCN Model Summary:\n",
      "- Run: custom_model_pipeline-2025_11_25-08_43_57_031350\n",
      "- Device: cpu\n",
      "- Total parameters: 4,739\n",
      "- Input node features: 5D (shape: (88, 5))\n",
      "- Number of nodes in batch: 88\n",
      "- Number of edges: 176\n",
      "- Output logits shape: (16, 3) (batch_size, num_classes)\n"
     ]
    }
   ],
   "source": [
    "device = next(trained_module.parameters()).device\n",
    "param_count = sum(p.numel() for p in trained_module.parameters())\n",
    "\n",
    "# Get a sample batch to inspect input shapes\n",
    "train_loader = datamodule.train_dataloader()\n",
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "print(\"Custom GCN Model Summary:\")\n",
    "print(f\"- Run: {run.name}\")\n",
    "print(f\"- Device: {device}\")\n",
    "print(f\"- Total parameters: {param_count:,}\")\n",
    "print(f\"- Input node features: {first_batch.x.shape[1]}D (shape: {tuple(first_batch.x.shape)})\")\n",
    "print(f\"- Number of nodes in batch: {first_batch.x.shape[0]}\")\n",
    "print(f\"- Number of edges: {first_batch.edge_index.shape[1]}\")\n",
    "\n",
    "# Test forward pass to verify output shape\n",
    "with torch.no_grad():\n",
    "    output = trained_module(first_batch.to(device))\n",
    "    print(f\"- Output logits shape: {tuple(output.shape)} (batch_size, num_classes)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "\n",
    "Finally, let's compute validation accuracy to confirm the custom model trained\n",
    "successfully. We'll run inference on the validation set and compare predictions\n",
    "to ground truth labels.\n",
    "\n",
    "**What we're measuring**: Classification accuracy - the percentage of graphs\n",
    "correctly classified into their true class (\u03c0, \u03bc, or e+).\n",
    "\n",
    "**Note on device placement**: The model was trained on GPU (as shown in the pipeline\n",
    "output), but when loaded from ZenML artifacts, it may be on CPU. We explicitly move\n",
    "it to the best available device (GPU if available) to match training conditions and\n",
    "speed up inference. This is why you see the device change from CPU to GPU (or vice versa)\n",
    "depending on your hardware.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accuracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> in &lt;module&gt;:26                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   </span>preds = torch.argmax(logits, dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Count correct predictions</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2771 </span>26 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   </span>correct += <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>((<span style=\"font-weight: bold; text-decoration: underline\">preds == labels</span>).sum().item())                                          <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   </span>total += <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(labels.numel())                                                            <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span>accuracy = correct / total <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> total &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.0</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>The size of tensor a <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">)</span> must match the size of tensor b <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span><span style=\"font-weight: bold\">)</span> at non-singleton dimension <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u256d\u2500\u001b[0m\u001b[31m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[31m\u2500\u256e\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m in <module>:26                                                                                   \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m\u2502   \u001b[0mpreds = torch.argmax(logits, dim=\u001b[94m1\u001b[0m)                                                     \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m24 \u001b[0m\u001b[2m\u2502   \u001b[0m                                                                                        \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m25 \u001b[0m\u001b[2m\u2502   \u001b[0m\u001b[2m# Count correct predictions\u001b[0m                                                             \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[31m\u2771 \u001b[0m26 \u001b[2m\u2502   \u001b[0mcorrect += \u001b[96mint\u001b[0m((\u001b[1;4mpreds == labels\u001b[0m).sum().item())                                          \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m27 \u001b[0m\u001b[2m\u2502   \u001b[0mtotal += \u001b[96mint\u001b[0m(labels.numel())                                                            \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m28 \u001b[0m                                                                                            \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m29 \u001b[0maccuracy = correct / total \u001b[94mif\u001b[0m total > \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m \u001b[94m0.0\u001b[0m                                            \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mThe size of tensor a \u001b[1m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m must match the size of tensor b \u001b[1m(\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1m)\u001b[0m at non-singleton dimension \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get validation loader (fallback to train if val is empty)\n",
    "val_loader = datamodule.val_dataloader()\n",
    "if isinstance(val_loader, list) and len(val_loader) == 0:\n",
    "    val_loader = datamodule.train_dataloader()\n",
    "\n",
    "# Compute accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "trained_module.eval()\n",
    "\n",
    "for batch in val_loader:\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = trained_module(batch)\n",
    "    \n",
    "    # Handle labels: PyTorch Geometric batches graph-level labels\n",
    "    # Each graph has y of shape (num_classes,), batched into (batch_size, num_classes)\n",
    "    labels = batch.y\n",
    "    \n",
    "    # Ensure labels are 2D: (batch_size, num_classes)\n",
    "    if labels.dim() == 1:\n",
    "        # If flattened, reshape assuming num_classes=3\n",
    "        if labels.shape[0] % 3 == 0:\n",
    "            labels = labels.view(-1, 3)\n",
    "        else:\n",
    "            # Single graph case: add batch dimension\n",
    "            labels = labels.unsqueeze(0)\n",
    "    \n",
    "    # Convert one-hot encoded labels to class indices\n",
    "    # Shape: (batch_size, num_classes) -> (batch_size,)\n",
    "    labels = torch.argmax(labels, dim=1)\n",
    "    \n",
    "    # Get predicted class (highest logit)\n",
    "    # Shape: (batch_size, num_classes) -> (batch_size,)\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    # Count correct predictions (both should be shape (batch_size,))\n",
    "    correct += int((preds == labels).sum().item())\n",
    "    total += int(labels.numel())\n",
    "\n",
    "accuracy = correct / total if total > 0 else 0.0\n",
    "print(f\"Validation accuracy: {accuracy:.1%} ({correct}/{total} correct)\")\n",
    "print(f\"\\nThe custom GCN successfully learned to classify graphs!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pioneerml",
   "language": "python",
   "name": "pioneerml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}