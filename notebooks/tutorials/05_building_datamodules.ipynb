{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51d00ac",
   "metadata": {},
   "source": [
    "# Tutorial 5: Building a Custom Lightning DataModule (Non-Graph)\n",
    "\n",
    "Learn how to implement your own `LightningDataModule`, plug it into a ZenML pipeline, and run it end-to-end.\n",
    "We'll build a simple tabular classifier using a custom DataModule, then execute a ZenML pipeline that trains\n",
    "and evaluates it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d6a80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ZenML repository root: /home/jack/python_projects/pioneerML\n",
      "Ensure this is the top-level of your repo (.zen must live here).\n",
      "ZenML initialized with stack: default\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from pioneerml.zenml import load_step_output\n",
    "from pioneerml.zenml import utils as zenml_utils\n",
    "from pioneerml.zenml.pipelines.tutorial_examples.tabular_datamodule_pipeline import (\n",
    "    TabularConfig,\n",
    "    TabularDataModule,\n",
    "    TabularClassifier,\n",
    "    tabular_datamodule_pipeline,\n",
    ")\n",
    "\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(use_in_memory=True)\n",
    "print(f\"ZenML initialized with stack: {zenml_client.active_stack_model.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d572e0c",
   "metadata": {},
   "source": [
    "## 1. The DataModule blueprint\n",
    "\n",
    "`TabularDataModule` inherits from `pytorch_lightning.LightningDataModule` and manages:\n",
    "- Synthetic tabular dataset creation (clustered features per class)\n",
    "- Train/val/test splits with deterministic seeds\n",
    "- Standard PyTorch DataLoaders\n",
    "\n",
    "It lives in `src/pioneerml/zenml/pipelines/tutorial_examples/tabular_datamodule_pipeline.py` so notebooks can import it directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcb12e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch shapes -> x: (32, 8) y: (32,) (32, 8) y: (32,)\n",
      "Val batch shapes   -> x: (32, 8) y: (32,) (32, 8) y: (32,)\n"
     ]
    }
   ],
   "source": [
    "config = TabularConfig(\n",
    "    num_samples=300,\n",
    "    num_features=8,\n",
    "    num_classes=3,\n",
    "    batch_size=32,\n",
    "    val_split=0.2,\n",
    "    test_split=0.1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "datamodule = TabularDataModule(config)\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n",
    "train_batch = next(iter(datamodule.train_dataloader()))\n",
    "print(\"Train batch shapes -> x:\", tuple(train_batch[0].shape), \"y:\", tuple(train_batch[1].shape))\n",
    "if datamodule.val_dataset:\n",
    "    val_batch = next(iter(datamodule.val_dataloader()))\n",
    "    print(\"Val batch shapes   -> x:\", tuple(val_batch[0].shape), \"y:\", tuple(val_batch[1].shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a265758",
   "metadata": {},
   "source": [
    "## 2. The LightningModule\n",
    "\n",
    "`TabularClassifier` is a tiny MLP with a cross-entropy objective. It logs train/val loss and accuracy during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8162e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: (32, 3) (32, 3)\n"
     ]
    }
   ],
   "source": [
    "model = TabularClassifier(config)\n",
    "with torch.no_grad():\n",
    "    sample_logits = model(train_batch[0])\n",
    "print(\"Logits shape:\", tuple(sample_logits.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770d062",
   "metadata": {},
   "source": [
    "## 3. Run the ZenML pipeline\n",
    "\n",
    "`tabular_datamodule_pipeline` wires together steps to build the DataModule, build the model, train, and collect predictions/targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343973c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mInitiating a new run for the pipeline: \u001b[0m\u001b[38;5;105mtabular_datamodule_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mCaching is disabled by default for \u001b[0m\u001b[38;5;105mtabular_datamodule_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mUsing user: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mUsing stack: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  deployer: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  orchestrator: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  artifact_store: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mYou can visualize your pipeline runs in the \u001b[0m\u001b[38;5;105mZenML Dashboard\u001b[37m. In order to try it locally, please run \u001b[0m\u001b[38;5;105mzenml login --local\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_tabular_datamodule\u001b[37m has started.\u001b[0m\n",
      "\u001b[33m[build_tabular_datamodule] No materializer is registered for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.zenml.pipelines.tutorial_examples.tabular_datamodule_pipeline.TabularDataModule'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.zenml.pipelines.tutorial_examples.tabular_datamodule_pipeline.TabularDataModule'>\u001b[33m according to the instructions at \u001b[0m\u001b[34mhttps://docs.zenml.io/concepts/artifacts/materializers\u001b[33m\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_tabular_datamodule\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.075s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_tabular_model\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_tabular_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.045s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_tabular_model\u001b[37m has started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | model | Sequential | 1.4 K  | train\n",
      "---------------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[train_tabular_model] /home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \u001b[0m\u001b[38;5;105mnum_workers\u001b[33m argument\u001b[0m\u001b[38;5;105m to \u001b[33mnum_workers=15\u001b[0m\u001b[38;5;105m in the \u001b[33mDataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "\u001b[33m[train_tabular_model] /home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \u001b[0m\u001b[38;5;105mnum_workers\u001b[33m argument\u001b[0m\u001b[38;5;105m to \u001b[33mnum_workers=15\u001b[0m\u001b[38;5;105m in the \u001b[33mDataLoader` to improve performance.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_tabular_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.546s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mevaluate_tabular_model\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mevaluate_tabular_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.638s\u001b[37m.\u001b[0m\n",
      "\u001b[37mPipeline run has finished in \u001b[0m\u001b[38;5;105m2.153s\u001b[37m.\u001b[0m\n",
      "Pipeline run status: completed\n",
      "Preds shape: (60, 3) (60, 3)\n",
      "Targets shape: (60,) (60,)\n"
     ]
    }
   ],
   "source": [
    "run = tabular_datamodule_pipeline.with_options(enable_cache=False)(config)\n",
    "print(f\"Pipeline run status: {run.status}\")\n",
    "\n",
    "trained_model = load_step_output(run, \"train_tabular_model\")\n",
    "datamodule_run = load_step_output(run, \"build_tabular_datamodule\")\n",
    "preds = load_step_output(run, \"evaluate_tabular_model\", output_name=\"output_0\", index=0)\n",
    "targets = load_step_output(run, \"evaluate_tabular_model\", output_name=\"output_1\", index=0)\n",
    "\n",
    "if preds is None or targets is None:\n",
    "    outputs = load_step_output(run, \"evaluate_tabular_model\")\n",
    "    if isinstance(outputs, (tuple, list)) and len(outputs) == 2:\n",
    "        preds, targets = outputs\n",
    "\n",
    "print(\"Preds shape:\", tuple(preds.shape) if preds is not None else None)\n",
    "print(\"Targets shape:\", tuple(targets.shape) if targets is not None else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2db26",
   "metadata": {},
   "source": [
    "## 4. Compute a quick accuracy\n",
    "\n",
    "Use the collected predictions/targets to verify the pipeline artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "221a5c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.800\n"
     ]
    }
   ],
   "source": [
    "def simple_accuracy(logits: torch.Tensor, labels: torch.Tensor) -> float:\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return float((preds == labels).float().mean().item())\n",
    "\n",
    "acc = simple_accuracy(preds, targets)\n",
    "print(f\"Validation accuracy: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d5877",
   "metadata": {},
   "source": [
    "## 5. Recap\n",
    "\n",
    "- Inherit from `LightningDataModule` to manage dataset creation and splits.\n",
    "- Keep configuration in a dataclass (`TabularConfig`) for easy reuse.\n",
    "- Wrap the DataModule/LightningModule in ZenML steps and run via a pipeline.\n",
    "- Load artifacts with `load_step_output` to inspect predictions and metrics.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pioneerml)",
   "language": "python",
   "name": "pioneerml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
