{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51d00ac",
   "metadata": {},
   "source": [
    "# Tutorial 5: Building a Custom Lightning DataModule (Non-Graph)\n",
    "\n",
    "Learn how to implement your own `LightningDataModule`, plug it into a ZenML pipeline, and run it end-to-end.\n",
    "We'll build a simple tabular classifier using a custom DataModule, then execute a ZenML pipeline that trains\n",
    "and evaluates it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d6a80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ZenML repository root: /workspace\n",
      "Ensure this is the top-level of your repo (.zen must live here).\n",
      "ZenML initialized with stack: default\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from pioneerml.common.zenml import load_step_output\n",
    "from pioneerml.common.zenml import utils as zenml_utils\n",
    "from pioneerml.pipelines.tutorial_examples.tabular_datamodule_pipeline import (\n",
    "    TabularConfig,\n",
    "    TabularDataModule,\n",
    "    TabularClassifier,\n",
    "    tabular_datamodule_pipeline,\n",
    ")\n",
    "\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(use_in_memory=True)\n",
    "print(f\"ZenML initialized with stack: {zenml_client.active_stack_model.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d572e0c",
   "metadata": {},
   "source": [
    "## 1. The DataModule blueprint\n",
    "\n",
    "`TabularDataModule` inherits from `pytorch_lightning.LightningDataModule` and manages:\n",
    "- Synthetic tabular dataset creation (clustered features per class)\n",
    "- Train/val/test splits with deterministic seeds\n",
    "- Standard PyTorch DataLoaders\n",
    "\n",
    "It lives in `src/pioneerml/zenml/pipelines/tutorial_examples/tabular_datamodule_pipeline.py` so notebooks can import it directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcb12e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch shapes -> x: (32, 8) y: (32,)\n",
      "Val batch shapes   -> x: (32, 8) y: (32,)\n"
     ]
    }
   ],
   "source": [
    "config = TabularConfig(\n",
    "    num_samples=300,\n",
    "    num_features=8,\n",
    "    num_classes=3,\n",
    "    batch_size=32,\n",
    "    val_split=0.2,\n",
    "    test_split=0.1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "datamodule = TabularDataModule(config)\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n",
    "train_batch = next(iter(datamodule.train_dataloader()))\n",
    "print(\"Train batch shapes -> x:\", tuple(train_batch[0].shape), \"y:\", tuple(train_batch[1].shape))\n",
    "if datamodule.val_dataset:\n",
    "    val_batch = next(iter(datamodule.val_dataloader()))\n",
    "    print(\"Val batch shapes   -> x:\", tuple(val_batch[0].shape), \"y:\", tuple(val_batch[1].shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a265758",
   "metadata": {},
   "source": [
    "## 2. The LightningModule\n",
    "\n",
    "`TabularClassifier` is a tiny MLP with a cross-entropy objective. It logs train/val loss and accuracy during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8162e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: (32, 3)\n"
     ]
    }
   ],
   "source": [
    "model = TabularClassifier(config)\n",
    "with torch.no_grad():\n",
    "    sample_logits = model(train_batch[0])\n",
    "print(\"Logits shape:\", tuple(sample_logits.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770d062",
   "metadata": {},
   "source": [
    "## 3. Run the ZenML pipeline\n",
    "\n",
    "`tabular_datamodule_pipeline` wires together steps to build the DataModule, build the model, train, and collect predictions/targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343973c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mInitiating a new run for the pipeline: \u001b[0m\u001b[38;5;105mtabular_datamodule_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mCaching is disabled by default for \u001b[0m\u001b[38;5;105mtabular_datamodule_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mUsing user: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mUsing stack: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  deployer: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  artifact_store: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  orchestrator: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mYou can visualize your pipeline runs in the \u001b[0m\u001b[38;5;105mZenML Dashboard\u001b[37m. In order to try it locally, please run \u001b[0m\u001b[38;5;105mzenml login --local\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_tabular_datamodule\u001b[37m has started.\u001b[0m\n",
      "\u001b[33m[build_tabular_datamodule] No materializer is registered for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.pipelines.tutorial_examples.tabular_datamodule_pipeline.TabularDataModule'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.pipelines.tutorial_examples.tabular_datamodule_pipeline.TabularDataModule'>\u001b[33m according to the instructions at \u001b[0m\u001b[34mhttps://docs.zenml.io/concepts/artifacts/materializers\u001b[33m\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_tabular_datamodule\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.423s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_tabular_model\u001b[37m has started.\u001b[0m\n",
      "\u001b[33m[build_tabular_model] No materializer is registered for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.pipelines.tutorial_examples.tabular_datamodule_pipeline.TabularClassifier'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.pipelines.tutorial_examples.tabular_datamodule_pipeline.TabularClassifier'>\u001b[33m according to the instructions at \u001b[0m\u001b[34mhttps://docs.zenml.io/concepts/artifacts/materializers\u001b[33m\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_tabular_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.082s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_tabular_model\u001b[37m has started.\u001b[0m\n",
      "\u001b[37m[train_tabular_model] GPU available: True (cuda), used: True\u001b[0m\n",
      "\u001b[37m[train_tabular_model] TPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[37m[train_tabular_model] ğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](\u001b[0m\u001b[34mhttps://pypi.org/project/litlogger/)\u001b[37m to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\u001b[0m\n",
      "\u001b[37m[train_tabular_model] You are using a CUDA device ('NVIDIA GeForce RTX 5070') that has Tensor Cores. To properly utilize them, you should set \u001b[0m\u001b[38;5;105mtorch.set_float32_matmul_precision('medium' | 'high')\u001b[37m which will trade-off precision for performance. For more details, read \u001b[0m\u001b[34mhttps://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html\u001b[37m#torch.set_float32_matmul_precision\u001b[0m\n",
      "\u001b[37m[train_tabular_model] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type       </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ model â”‚ Sequential â”‚  1.4 K â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType      \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ model â”‚ Sequential â”‚  1.4 K â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.4 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.4 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 6                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.4 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.4 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 6                                                                                           \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[train_tabular_model] /opt/conda/envs/pioneerml/lib/python3.10/site-packages/pytorch_lightning/utilities/_pytree.py:21: \u001b[0m\u001b[38;5;105misinstance(treespec, LeafSpec)\u001b[33m is deprecated, use \u001b[0m\u001b[38;5;105misinstance(treespec, TreeSpec) and treespec.is_leaf()\u001b[33m instead.\n",
      "\u001b[0m\n",
      "\u001b[33m[train_tabular_model] /opt/conda/envs/pioneerml/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \u001b[0m\u001b[38;5;105mnum_workers\u001b[33m argument\u001b[0m\u001b[38;5;105m to \u001b[33mnum_workers=11\u001b[0m\u001b[38;5;105m in the \u001b[33mDataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "\u001b[33m[train_tabular_model] /opt/conda/envs/pioneerml/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \u001b[0m\u001b[38;5;105mnum_workers\u001b[33m argument\u001b[0m\u001b[38;5;105m to \u001b[33mnum_workers=11\u001b[0m\u001b[38;5;105m in the \u001b[33mDataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "\u001b[37m[train_tabular_model] \u001b[0m\u001b[38;5;105mTrainer.fit\u001b[37m stopped: \u001b[0m\u001b[38;5;105mmax_epochs=10\u001b[37m reached.\u001b[0m\n",
      "\u001b[33m[train_tabular_model] No materializer is registered for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.pipelines.tutorial_examples.tabular_datamodule_pipeline.TabularClassifier'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.pipelines.tutorial_examples.tabular_datamodule_pipeline.TabularClassifier'>\u001b[33m according to the instructions at \u001b[0m\u001b[34mhttps://docs.zenml.io/concepts/artifacts/materializers\u001b[33m\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_tabular_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m1.286s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mevaluate_tabular_model\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mevaluate_tabular_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.518s\u001b[37m.\u001b[0m\n",
      "\u001b[37mPipeline run has finished in \u001b[0m\u001b[38;5;105m3.871s\u001b[37m.\u001b[0m\n",
      "Pipeline run status: completed\n",
      "Preds shape: (60, 3)\n",
      "Targets shape: (60,)\n"
     ]
    }
   ],
   "source": [
    "run = tabular_datamodule_pipeline.with_options(enable_cache=False)(config)\n",
    "print(f\"Pipeline run status: {run.status}\")\n",
    "\n",
    "trained_model = load_step_output(run, \"train_tabular_model\")\n",
    "datamodule_run = load_step_output(run, \"build_tabular_datamodule\")\n",
    "preds = load_step_output(run, \"evaluate_tabular_model\", output_name=\"output_0\", index=0)\n",
    "targets = load_step_output(run, \"evaluate_tabular_model\", output_name=\"output_1\", index=0)\n",
    "\n",
    "if preds is None or targets is None:\n",
    "    outputs = load_step_output(run, \"evaluate_tabular_model\")\n",
    "    if isinstance(outputs, (tuple, list)) and len(outputs) == 2:\n",
    "        preds, targets = outputs\n",
    "\n",
    "print(\"Preds shape:\", tuple(preds.shape) if preds is not None else None)\n",
    "print(\"Targets shape:\", tuple(targets.shape) if targets is not None else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2db26",
   "metadata": {},
   "source": [
    "## 4. Compute a quick accuracy\n",
    "\n",
    "Use the collected predictions/targets to verify the pipeline artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "221a5c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.800\n"
     ]
    }
   ],
   "source": [
    "def simple_accuracy(logits: torch.Tensor, labels: torch.Tensor) -> float:\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return float((preds == labels).float().mean().item())\n",
    "\n",
    "acc = simple_accuracy(preds, targets)\n",
    "print(f\"Validation accuracy: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d5877",
   "metadata": {},
   "source": [
    "## 5. Recap\n",
    "\n",
    "- Inherit from `LightningDataModule` to manage dataset creation and splits.\n",
    "- Keep configuration in a dataclass (`TabularConfig`) for easy reuse.\n",
    "- Wrap the DataModule/LightningModule in ZenML steps and run via a pipeline.\n",
    "- Load artifacts with `load_step_output` to inspect predictions and metrics.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pioneerml)",
   "language": "python",
   "name": "pioneerml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
