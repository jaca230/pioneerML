{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Groups (Standardized)\n",
    "\n",
    "Decisions:\n",
    "- Single-group samples; upstream code prefilters groups.\n",
    "- Node features: `[coord, z, energy, view, group_energy]` (5 dims).\n",
    "- Views use a single flag `view` (0=x-strip, 1=y-strip).\n",
    "- Fully connected graphs per sample, built in the dataset (not in the model).\n",
    "- Edge features always used: `[dx, dz, dE, same_view]` (4 dims).\n",
    "- Models read `data.x`, `data.edge_index`, `data.edge_attr` only (no graph construction in forward)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import TransformerConv, JumpingKnowledge\n",
    "from torch_geometric.nn.aggr import AttentionalAggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_edge_index(num_nodes: int, device=None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Build a fully connected directed edge_index (excluding self-loops)\n",
    "    for a single graph with `num_nodes` nodes.\n",
    "\n",
    "    Returns a LongTensor of shape [2, num_edges] with rows [src, dst].\n",
    "    \"\"\"\n",
    "    if num_nodes <= 1:\n",
    "        return torch.empty((2, 0), dtype=torch.long, device=device)\n",
    "\n",
    "    # Create all ordered pairs (i, j) for i != j.\n",
    "    src_index = torch.arange(num_nodes, device=device).repeat_interleave(num_nodes - 1)\n",
    "    dst_index = torch.stack([\n",
    "        torch.cat([torch.arange(0, i, device=device), torch.arange(i + 1, num_nodes, device=device)])\n",
    "        for i in range(num_nodes)\n",
    "    ], dim=0).reshape(-1)\n",
    "    return torch.stack([src_index, dst_index], dim=0)\n",
    "\n",
    "def build_edge_attr(node_features: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute edge features for each edge defined by `edge_index` using\n",
    "    the standardized node feature layout: [coord, z, energy, view, group_energy].\n",
    "\n",
    "    Returns a FloatTensor of shape [num_edges, 4] with columns:\n",
    "      [dx, dz, dE, same_view].\n",
    "    \"\"\"\n",
    "    if edge_index.numel() == 0:\n",
    "        return torch.zeros((0, 4), dtype=torch.float, device=node_features.device)\n",
    "\n",
    "    src_idx, dst_idx = edge_index[0], edge_index[1]\n",
    "    coord = node_features[:, 0]\n",
    "    z_pos = node_features[:, 1]\n",
    "    energy = node_features[:, 2]\n",
    "    view_flag = node_features[:, 3]\n",
    "\n",
    "    dx = (coord[dst_idx] - coord[src_idx]).unsqueeze(1)\n",
    "    dz = (z_pos[dst_idx] - z_pos[src_idx]).unsqueeze(1)\n",
    "    dE = (energy[dst_idx] - energy[src_idx]).unsqueeze(1)\n",
    "    same_view = (view_flag[dst_idx] == view_flag[src_idx]).float().unsqueeze(1)\n",
    "\n",
    "    return torch.cat([dx, dz, dE, same_view], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupClassificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for single-group samples. Assumes groups are prefiltered upstream.\n",
    "\n",
    "    Each item is a dict with keys:\n",
    "      - 'coord': 1D array-like (strip coordinate in mm; x or y depending on view)\n",
    "      - 'z': 1D array-like (z coordinate in mm)\n",
    "      - 'energy': 1D array-like (deposited energy per hit)\n",
    "      - 'view': 1D array-like (0 for x-strip, 1 for y-strip)\n",
    "      - 'label': int class label (optional)\n",
    "      - 'event_id': int identifier (optional)\n",
    "\n",
    "    Outputs torch_geometric.data.Data with:\n",
    "      - x: [num_hits, 5] node features [coord, z, energy, view, group_energy]\n",
    "      - edge_index: [2, num_edges] fully-connected directed edges (no self loops)\n",
    "      - edge_attr: [num_edges, 4] edge features [dx, dz, dE, same_view]\n",
    "      - y: optional class label\n",
    "      - event_id: optional graph-level identifier\n",
    "    \"\"\"\n",
    "    def __init__(self, groups: List[Dict[str, Any]]):\n",
    "        self.items = groups\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Data:\n",
    "        item = self.items[index]\n",
    "\n",
    "        # Convert inputs to numpy arrays with explicit dtypes\n",
    "        coord_mm = np.asarray(item['coord'], dtype=np.float32)\n",
    "        z_mm = np.asarray(item['z'], dtype=np.float32)\n",
    "        energy_dep = np.asarray(item['energy'], dtype=np.float32)\n",
    "        view_flag = np.asarray(item['view'], dtype=np.float32)  # 0=x-strip, 1=y-strip\n",
    "        num_hits = coord_mm.shape[0]\n",
    "\n",
    "        # Broadcast total group energy across all hits\n",
    "        total_group_energy = np.full(num_hits, energy_dep.sum(), dtype=np.float32)\n",
    "\n",
    "        # Stack node features: [coord, z, energy, view, group_energy]\n",
    "        node_features_np = np.stack([coord_mm, z_mm, energy_dep, view_flag, total_group_energy], axis=1)\n",
    "        node_features = torch.tensor(node_features_np, dtype=torch.float)\n",
    "\n",
    "        # Build fully-connected graph and corresponding edge features\n",
    "        edge_index = fully_connected_edge_index(num_hits, device=None)\n",
    "        edge_features = build_edge_attr(node_features, edge_index)\n",
    "\n",
    "        # Optional targets/ids\n",
    "        label_tensor = None\n",
    "        if 'label' in item and item['label'] is not None:\n",
    "            label_tensor = torch.tensor(item['label'], dtype=torch.long)\n",
    "\n",
    "        event_id_tensor = None\n",
    "        if 'event_id' in item and item['event_id'] is not None:\n",
    "            event_id_tensor = torch.tensor(item['event_id'], dtype=torch.long)\n",
    "\n",
    "        data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features, y=label_tensor)\n",
    "        if event_id_tensor is not None:\n",
    "            data.event_id = event_id_tensor\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullTransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A transformer-style graph block:\n",
    "      - Multi-head attention via TransformerConv (uses edge_attr)\n",
    "      - Residual + LayerNorm\n",
    "      - Position-wise FFN + Residual + LayerNorm\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden: int = 200, heads: int = 4, edge_dim: int = 4, dropout: float = 0.05):\n",
    "        super().__init__()\n",
    "        # With concat=True, out_channels * heads = hidden => per-head = hidden // heads\n",
    "        self.attn = TransformerConv(hidden, hidden // heads, heads=heads, concat=True, edge_dim=edge_dim, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(hidden)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden * 4, hidden)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(hidden)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, node_features: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        # Attention over edges (uses edge_attr), then residual + LayerNorm\n",
    "        attn_out = self.attn(node_features, edge_index, edge_attr)\n",
    "        node_features = self.norm1(node_features + self.drop(attn_out))\n",
    "        # Position-wise FFN, residual, and LayerNorm\n",
    "        ff_out = self.ff(node_features)\n",
    "        node_features = self.norm2(node_features + self.drop(ff_out))\n",
    "        return node_features\n",
    "\n",
    "class GroupClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph-level classifier using stacked FullTransformerBlocks, JumpingKnowledge\n",
    "    (concatenation) across blocks, and AttentionalAggregation for pooling.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int = 5, edge_dim: int = 4, hidden: int = 200, num_blocks: int = 2, heads: int = 4, dropout: float = 0.0, num_classes: int = 3):\n",
    "        super().__init__()\n",
    "        self.input_embed = nn.Linear(in_dim, hidden)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            FullTransformerBlock(hidden=hidden, heads=heads, edge_dim=edge_dim, dropout=dropout)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.jk_layer = JumpingKnowledge(mode='cat')\n",
    "        concatenated_dim = hidden * num_blocks\n",
    "        self.attn_pool = AttentionalAggregation(\n",
    "            gate_nn=nn.Sequential(\n",
    "                nn.Linear(concatenated_dim, concatenated_dim // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(concatenated_dim // 2, 1)\n",
    "            )\n",
    "        )\n",
    "        self.classifier_head = nn.Sequential(\n",
    "            nn.Linear(concatenated_dim, concatenated_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(concatenated_dim // 2, num_classes) # Number of classes is just the number of possible particle types\n",
    "        )\n",
    "\n",
    "    def forward(self, data: Data) -> torch.Tensor:\n",
    "        # Unpack batched graph inputs\n",
    "        node_features, edge_index, edge_attr, batch_index = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        # Initial node embedding\n",
    "        node_features = self.input_embed(node_features)\n",
    "\n",
    "        # Run stacked transformer blocks, collect outputs for JK concatenation\n",
    "        block_outputs = []\n",
    "        for block in self.blocks:\n",
    "            node_features = block(node_features, edge_index, edge_attr)\n",
    "            block_outputs.append(node_features)\n",
    "\n",
    "        # Concatenate per-block outputs (JumpingKnowledge)\n",
    "        concatenated = self.jk_layer(block_outputs)\n",
    "\n",
    "        # Attention-based graph pooling to get one vector per graph in the batch\n",
    "        pooled_graph_embeddings = self.attn_pool(concatenated, index=batch_index)\n",
    "\n",
    "        # Final classifier head\n",
    "        logits = self.classifier_head(pooled_graph_embeddings)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cabd977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (replace with your real prefiltered groups):\n",
    "# groups = [{\n",
    "#     'coord': np.random.randn(32),\n",
    "#     'z': np.random.randn(32),\n",
    "#     'energy': np.abs(np.random.randn(32)),\n",
    "#     'view': np.random.randint(0, 2, size=32),\n",
    "#     'label': np.random.randint(0, 3),\n",
    "#     'event_id': 123\n",
    "# } for _ in range(100)]\n",
    "# ds = GroupClassificationDataset(groups)\n",
    "# loader = DataLoader(ds, batch_size=16, shuffle=True)\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# model = GroupClassifier(num_classes=3).to(device)\n",
    "# opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# for epoch in range(5):\n",
    "#     model.train()\n",
    "#     for batch in loader:\n",
    "#         batch = batch.to(device)\n",
    "#         logits = model(batch)\n",
    "#         loss = F.cross_entropy(logits, batch.y)\n",
    "#         opt.zero_grad(); loss.backward(); opt.step()\n",
    "#     print('epoch', epoch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
