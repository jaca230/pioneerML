{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {},
 "cells": [
  {
   "id": "f5a52fc5",
   "cell_type": "markdown",
   "source": "# Validate Group Splitter",
   "metadata": {}
  },
  {
   "id": "2b453dee",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "import json\nfrom pathlib import Path\nfrom datetime import datetime\n\nimport torch\n\nfrom pioneerml.zenml import utils as zenml_utils\nfrom pioneerml.training.lightning import GraphLightningModule\n\nfrom pioneerml.models.classifiers import GroupSplitter\nfrom pioneerml.data.loaders import load_splitter_groups\nfrom pioneerml.training.datamodules import SplitterDataModule\nfrom pioneerml.evaluation import (\n    plot_multilabel_confusion_matrix,\n    plot_roc_curves,\n    plot_precision_recall_curves,\n    plot_probability_distributions,\n    plot_confidence_analysis,\n)\nfrom pioneerml.data import NODE_LABEL_TO_NAME, NUM_NODE_CLASSES\n\nPROJECT_ROOT = zenml_utils.find_project_root()\ncheckpoints_dir = Path(PROJECT_ROOT) / 'trained_models' / 'group_splitter'\ncheckpoints_dir.mkdir(parents=True, exist_ok=True)\nprint(f'Project root: {PROJECT_ROOT}')\nprint(f'Checkpoints directory: {checkpoints_dir}')\n",
   "outputs": []
  },
  {
   "id": "739c7515",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Load latest checkpoint\ncheckpoint_files = sorted(checkpoints_dir.glob('group_splitter_*.pt'), reverse=True)\nif not checkpoint_files:\n    raise ValueError('No group_splitter checkpoints found')\nselected_checkpoint = checkpoint_files[0]\nstate_dict = torch.load(selected_checkpoint, map_location='cpu')\nmodel = GroupSplitter()\nmodel.load_state_dict(state_dict)\nmodel.eval()\nprint(f'Loaded checkpoint: {selected_checkpoint.name}')\n",
   "outputs": []
  },
  {
   "id": "dcb572c4",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Load validation data\nfile_pattern = str(Path(PROJECT_ROOT) / 'data' / 'splitterGroups_*.npy')\nrecords = load_splitter_groups(file_pattern, max_files=None, verbose=True)\ndatamodule = SplitterDataModule(records=records, batch_size=128, num_workers=0, val_split=0.0)\ndatamodule.setup('fit')\nval_dataset = datamodule.val_dataset or datamodule.train_dataset\nprint(f'Validation size: {len(val_dataset)}')\n",
   "outputs": []
  },
  {
   "id": "cee75e07",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Predict\nfrom torch_geometric.loader import DataLoader\nloader = DataLoader(val_dataset, batch_size=128, shuffle=False)\nall_preds, all_targets = [], []\nwith torch.no_grad():\n    for batch in loader:\n        preds = model(batch)\n        all_preds.append(preds.cpu())\n        all_targets.append(batch.y.cpu())\npredictions = torch.cat(all_preds, dim=0)\ntargets = torch.cat(all_targets, dim=0)\nprint(predictions.shape, targets.shape)\n",
   "outputs": []
  },
  {
   "id": "574f1e4b",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Plots\nclass_names = list(NODE_LABEL_TO_NAME.values())\nplot_multilabel_confusion_matrix(predictions=predictions, targets=targets, class_names=class_names, threshold=0.5, normalize=True, show=True)\nplot_roc_curves(predictions=predictions, targets=targets, class_names=class_names, show=True)\nplot_precision_recall_curves(predictions=predictions, targets=targets, class_names=class_names, show=True)\nplot_probability_distributions(predictions=predictions, targets=targets, class_names=class_names, show=True)\nplot_confidence_analysis(predictions=predictions, targets=targets, class_names=class_names, show=True)\n",
   "outputs": []
  }
 ]
}