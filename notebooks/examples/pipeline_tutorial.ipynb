{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca49c149",
   "metadata": {},
   "source": [
    "# PIONEER ML Tutorial\n",
    "\n",
    "Quick walkthrough of the pipeline framework, Lightning utilities, and how to plug in a model. This notebook builds a tiny synthetic dataset, wraps it in a DataModule, trains a model with the Lightning pipeline stage, and inspects results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad40f0fc",
   "metadata": {},
   "source": [
    "## 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ac4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pioneerml.data import GraphGroupDataset\n",
    "from pioneerml.models import GroupClassifier\n",
    "from pioneerml.pipelines import Pipeline, Context, StageConfig\n",
    "from pioneerml.pipelines.stages import LightningTrainStage\n",
    "from pioneerml.training import GraphDataModule, GraphLightningModule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b41dc3",
   "metadata": {},
   "source": [
    "## 2) Create a synthetic dataset\n",
    "We generate a few fake time-group records with the standardized per-hit fields expected by `GraphGroupDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccf8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_record(num_hits: int, event_id: int) -> dict:\n",
    "    coord = np.random.randn(num_hits).astype(np.float32)\n",
    "    z = np.random.randn(num_hits).astype(np.float32)\n",
    "    energy = np.abs(np.random.randn(num_hits)).astype(np.float32)\n",
    "    view = np.random.randint(0, 2, num_hits).astype(np.float32)\n",
    "\n",
    "    # Multi-label targets: [pion, muon, mip]\n",
    "    labels = [int(energy.mean() > 0.5), int(num_hits % 2 == 0)]\n",
    "    if len(labels) < 3:\n",
    "        labels.append(0)\n",
    "\n",
    "    return {\n",
    "        \"coord\": coord,\n",
    "        \"z\": z,\n",
    "        \"energy\": energy,\n",
    "        \"view\": view,\n",
    "        \"labels\": labels,\n",
    "        \"event_id\": event_id,\n",
    "        \"group_id\": event_id,\n",
    "    }\n",
    "\n",
    "records = [make_record(num_hits=8 + i, event_id=i) for i in range(20)]\n",
    "dataset = GraphGroupDataset(records, num_classes=3)\n",
    "dataset[0]  # trigger a build and inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a5ed79",
   "metadata": {},
   "source": [
    "## 3) Wrap data with a Lightning DataModule\n",
    "Splits the dataset and prepares PyG loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = GraphDataModule(dataset=dataset, batch_size=4, val_split=0.2, test_split=0.0)\n",
    "datamodule.setup()\n",
    "datamodule.train_dataloader(), datamodule.val_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e2f222",
   "metadata": {},
   "source": [
    "## 4) Build the model and Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GroupClassifier(num_classes=3, hidden=64, num_blocks=2)\n",
    "lightning_module = GraphLightningModule(model, task=\"classification\", lr=1e-3)\n",
    "lightning_module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d8425",
   "metadata": {},
   "source": [
    "## 5) Compose a pipeline with the Lightning training stage\n",
    "The `LightningTrainStage` fits the module using any provided DataModule and records the trainer + trained module back into the shared `Context`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b2d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stage = LightningTrainStage(\n",
    "    config=StageConfig(\n",
    "        name=\"train\",\n",
    "        params={\n",
    "            \"module\": lightning_module,\n",
    "            \"datamodule\": datamodule,\n",
    "            \"trainer_params\": {\n",
    "                \"max_epochs\": 2,\n",
    "                \"limit_train_batches\": 2,\n",
    "                \"limit_val_batches\": 1,\n",
    "                \"logger\": False,\n",
    "                \"enable_checkpointing\": False,\n",
    "            },\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([train_stage], name=\"tutorial_pipeline\")\n",
    "ctx = pipeline.run(Context())\n",
    "ctx.summary()\n",
    "ctx.get(\"metrics\", {})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603cee97",
   "metadata": {},
   "source": [
    "## 6) Next steps\n",
    "- Swap in your own datasets or DataModules.\n",
    "- Add stages for preprocessing, evaluation, and checkpointing.\n",
    "- Integrate experiment tracking (e.g., Weights & Biases) by configuring the Lightning Trainer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
