{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Tutorial 3: Hyperparameter Tuning with Optuna\n",
    "\n",
    "This tutorial shows how to run Optuna sweeps inside a ZenML pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ZenML repository root: /home/jack/python_projects/pioneerML\n",
      "Ensure this is the top-level of your repo (.zen must live here).\n",
      "ZenML initialized with stack: default\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import io\n",
    "import warnings\n",
    "import torch\n",
    "import optuna\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.data import Data\n",
    "from zenml import pipeline, step\n",
    "\n",
    "from pioneerml.models import GroupClassifier\n",
    "from pioneerml.training import GraphDataModule, GraphLightningModule\n",
    "from pioneerml.zenml.materializers import (\n",
    "    GraphDataModuleMaterializer,\n",
    "    PyGDataListMaterializer,\n",
    ")\n",
    "from pioneerml.zenml import load_step_output\n",
    "from pioneerml.zenml import utils as zenml_utils\n",
    "from pioneerml.zenml.utils import detect_available_accelerator\n",
    "\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(use_in_memory=True)\n",
    "print(f\"ZenML initialized with stack: {zenml_client.active_stack_model.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-overview",
   "metadata": {},
   "source": [
    "## Build the Tuning Pipeline\n",
    "\n",
    "The pipeline mirrors the structure from earlier tutorials and adds an Optuna step:\n",
    "\n",
    "1. `create_data`: synthetic graph classification dataset\n",
    "2. `create_datamodule`: wraps the dataset with train/val splits\n",
    "3. `run_hyperparameter_search`: Optuna study that picks hidden size, learning rate, dropout\n",
    "4. `train_best_model`: trains one final model with the best parameters\n",
    "\n",
    "Optuna runs entirely inside the pipeline, making the sweep reproducible and tracked in ZenML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pipeline-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_synthetic_tuning_data(num_samples: int = 400) -> list[Data]:\n",
    "    \"\"\"Generate a deliberately tricky dataset so Optuna can't hit 100% accuracy.\"\"\"\n",
    "    data: list[Data] = []\n",
    "\n",
    "    class_means = torch.tensor([\n",
    "        [0.7, -0.3, 0.2, 0.1, -0.1],\n",
    "        [-0.1, 0.8, -0.2, 0.3, 0.15],\n",
    "        [-0.6, -0.4, 0.4, -0.2, 0.25],\n",
    "    ])\n",
    "    class_drift = torch.tensor([\n",
    "        [0.4, 0.3, -0.1, 0.0, 0.2],\n",
    "        [-0.3, 0.2, 0.25, -0.15, -0.1],\n",
    "        [0.2, -0.4, 0.15, 0.25, -0.05],\n",
    "    ])\n",
    "    feature_scales = torch.tensor([\n",
    "        [1.0, 0.9, 1.1, 0.95, 1.05],\n",
    "        [0.95, 1.05, 0.85, 1.1, 0.9],\n",
    "        [1.1, 0.95, 0.9, 1.0, 1.0],\n",
    "    ])\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        label = torch.randint(0, 3, (1,)).item()\n",
    "        num_nodes = torch.randint(7, 18, (1,)).item()\n",
    "\n",
    "        mix_label = (label + torch.randint(1, 3, (1,)).item()) % 3\n",
    "        mix_ratio = torch.rand(1).item() * 0.6 + 0.2\n",
    "        prototype = mix_ratio * class_means[label] + (1 - mix_ratio) * class_means[mix_label]\n",
    "\n",
    "        t = torch.linspace(0, 1, steps=num_nodes).unsqueeze(1)\n",
    "        wiggles = torch.cat([\n",
    "            torch.sin(2.0 * torch.pi * t + label * 0.3),\n",
    "            torch.cos(3.0 * torch.pi * t + mix_ratio),\n",
    "            torch.sin(4.0 * torch.pi * t - mix_ratio * 0.5),\n",
    "            torch.cos(5.0 * torch.pi * t + label * 0.2),\n",
    "            torch.sin(6.0 * torch.pi * t - 0.1),\n",
    "        ], dim=1)\n",
    "\n",
    "        x = prototype + 0.4 * wiggles\n",
    "        x = x * feature_scales[label]\n",
    "\n",
    "        noise = torch.randn(num_nodes, 5)\n",
    "        correlated = noise + 0.35 * torch.matmul(noise, torch.ones(5, 5) * 0.1)\n",
    "        drift = class_drift[label] * torch.randn(num_nodes, 1)\n",
    "        x = x + 0.25 * correlated + drift\n",
    "\n",
    "        projection = torch.randn(5, 5) * 0.2 + torch.eye(5)\n",
    "        x = x @ projection\n",
    "\n",
    "        if label == 0:\n",
    "            ring = torch.stack([\n",
    "                torch.arange(num_nodes),\n",
    "                (torch.arange(num_nodes) + 1) % num_nodes,\n",
    "            ])\n",
    "            random_edges = torch.randint(0, num_nodes, (2, num_nodes * 2))\n",
    "            edge_index = torch.cat([ring, random_edges], dim=1)\n",
    "        elif label == 1:\n",
    "            cluster = max(3, num_nodes // 2)\n",
    "            src = torch.randint(0, cluster, (num_nodes * 3,))\n",
    "            dst = torch.randint(0, cluster, (num_nodes * 3,))\n",
    "            long_jump = torch.randint(0, num_nodes, (2, num_nodes))\n",
    "            edge_index = torch.cat([torch.stack([src, dst], dim=0), long_jump], dim=1)\n",
    "        else:\n",
    "            src = torch.randint(0, num_nodes, (num_nodes * 2,))\n",
    "            dst = (src + torch.randint(2, 7, (num_nodes * 2,))) % num_nodes\n",
    "            extra = torch.randint(0, num_nodes, (2, num_nodes))\n",
    "            edge_index = torch.cat([torch.stack([src, dst], dim=0), extra], dim=1)\n",
    "\n",
    "        edge_attr = torch.randn(edge_index.shape[1], 4) * 0.15 + label * 0.04\n",
    "\n",
    "        noisy_label = label\n",
    "        if torch.rand(1).item() < 0.1:\n",
    "            noisy_label = torch.randint(0, 3, (1,)).item()\n",
    "\n",
    "        y = torch.zeros(3)\n",
    "        y[noisy_label] = 1.0\n",
    "\n",
    "        data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n",
    "\n",
    "    return data\n",
    "\n",
    "def run_silently(fn):\n",
    "    \"\"\"Run a Lightning call with stdout/stderr, warnings, and PL logs disabled.\"\"\"\n",
    "    # Disable python warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        # Disable Lightning logs globally\n",
    "        pl._logger.setLevel(\"ERROR\")\n",
    "\n",
    "        # Silence stdout and stderr\n",
    "        buffer_out = io.StringIO()\n",
    "        buffer_err = io.StringIO()\n",
    "        with contextlib.redirect_stdout(buffer_out), contextlib.redirect_stderr(buffer_err):\n",
    "            return fn()\n",
    "\n",
    "\n",
    "\n",
    "@step(output_materializers=PyGDataListMaterializer, enable_cache=False)\n",
    "def create_data() -> list[Data]:\n",
    "    \"\"\"Step 1: Generate synthetic graphs for tuning.\"\"\"\n",
    "    return create_synthetic_tuning_data()\n",
    "\n",
    "\n",
    "@step(output_materializers=GraphDataModuleMaterializer, enable_cache=False)\n",
    "def create_datamodule(data: list[Data]) -> GraphDataModule:\n",
    "    \"\"\"Step 2: Wrap the dataset in a Lightning DataModule.\"\"\"\n",
    "    return GraphDataModule(dataset=data, val_split=0.25, batch_size=32, num_workers=0)\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def run_hyperparameter_search(datamodule: GraphDataModule, n_trials: int = 4) -> dict:\n",
    "    \"\"\"Step 3: Perform an Optuna search over hidden size, dropout, and learning rate.\"\"\"\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
    "        lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "\n",
    "        model = GroupClassifier(num_classes=3, hidden=hidden_dim, dropout=dropout)\n",
    "        lightning_module = GraphLightningModule(model, task=\"classification\", lr=lr)\n",
    "        accelerator, devices = detect_available_accelerator()\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator=accelerator,\n",
    "            devices=devices,\n",
    "            max_epochs=2,\n",
    "            logger=False,\n",
    "            enable_checkpointing=False,\n",
    "            enable_progress_bar=False,\n",
    "        )\n",
    "\n",
    "        datamodule.setup(stage=\"fit\")\n",
    "\n",
    "        def fit():\n",
    "            trainer.fit(lightning_module, datamodule=datamodule)\n",
    "\n",
    "        def validate():\n",
    "            return trainer.validate(lightning_module, datamodule=datamodule, verbose=False)\n",
    "\n",
    "        run_silently(fit)\n",
    "        val_metrics = run_silently(validate)\n",
    "\n",
    "        if val_metrics and isinstance(val_metrics[0], dict):\n",
    "            accuracy = val_metrics[0].get(\"val_accuracy\")\n",
    "            if accuracy is not None:\n",
    "                return float(accuracy)\n",
    "            loss = val_metrics[0].get(\"val_loss\")\n",
    "            if loss is not None:\n",
    "                return 1.0 / (1.0 + float(loss))\n",
    "        return 0.0\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    return {\n",
    "        \"best_hidden_dim\": study.best_params[\"hidden_dim\"],\n",
    "        \"best_dropout\": study.best_params[\"dropout\"],\n",
    "        \"best_lr\": study.best_params[\"lr\"],\n",
    "        \"best_accuracy\": study.best_value,\n",
    "        \"n_trials\": len(study.trials),\n",
    "    }\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def train_best_model(best_params: dict, datamodule: GraphDataModule) -> GraphLightningModule:\n",
    "    \"\"\"Step 4: Train a final model with the best Optuna parameters.\"\"\"\n",
    "    model = GroupClassifier(\n",
    "        num_classes=3,\n",
    "        hidden=best_params[\"best_hidden_dim\"],\n",
    "        dropout=best_params[\"best_dropout\"],\n",
    "    )\n",
    "    lightning_module = GraphLightningModule(\n",
    "        model,\n",
    "        task=\"classification\",\n",
    "        lr=best_params[\"best_lr\"],\n",
    "    )\n",
    "\n",
    "    accelerator, devices = detect_available_accelerator()\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        max_epochs=5,\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    datamodule.setup(stage=\"fit\")\n",
    "\n",
    "    def fit():\n",
    "        trainer.fit(lightning_module, datamodule=datamodule)\n",
    "\n",
    "    run_silently(fit)\n",
    "    return lightning_module.eval()\n",
    "\n",
    "\n",
    "@pipeline\n",
    "def tuning_pipeline(n_trials: int = 4):\n",
    "    data = create_data()\n",
    "    datamodule = create_datamodule(data)\n",
    "    best_params = run_hyperparameter_search(datamodule, n_trials=n_trials)\n",
    "    tuned_model = train_best_model(best_params, datamodule)\n",
    "    return tuned_model, datamodule, best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-section",
   "metadata": {},
   "source": [
    "## Run the Optuna Sweep\n",
    "\n",
    "Execute the pipeline with a small number of trials (increase `n_trials` for real sweeps).\n",
    "The pipeline stores all runs and best parameters in ZenML so you can reproduce the sweep later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "run-pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mInitiating a new run for the pipeline: \u001b[0m\u001b[38;5;105mtuning_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mCaching is disabled by default for \u001b[0m\u001b[38;5;105mtuning_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mUsing user: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mUsing stack: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  deployer: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  orchestrator: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  artifact_store: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mYou can visualize your pipeline runs in the \u001b[0m\u001b[38;5;105mZenML Dashboard\u001b[37m. In order to try it locally, please run \u001b[0m\u001b[38;5;105mzenml login --local\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_data\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_data\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.153s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_datamodule\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_datamodule\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.074s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mrun_hyperparameter_search\u001b[37m has started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-25 19:11:20,284] A new study created in memory with name: no-name-1dc8e1d5-c88f-42c7-af90-b51aa93570d6\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "[I 2025-11-25 19:11:21,101] Trial 0 finished with value: 0.699999988079071 and parameters: {'hidden_dim': 256, 'dropout': 0.1917318643571018, 'lr': 0.00022081801915407043}. Best is trial 0 with value: 0.699999988079071.\n",
      "[I 2025-11-25 19:11:21,394] Trial 1 finished with value: 0.8333333730697632 and parameters: {'hidden_dim': 256, 'dropout': 0.04549340117110281, 'lr': 0.00045642066793705655}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:21,671] Trial 2 finished with value: 0.8133333325386047 and parameters: {'hidden_dim': 128, 'dropout': 0.14228022583255323, 'lr': 0.0033759559542362047}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:21,965] Trial 3 finished with value: 0.7966667413711548 and parameters: {'hidden_dim': 256, 'dropout': 0.20629699836440032, 'lr': 0.0017703743448726074}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:22,232] Trial 4 finished with value: 0.6666666269302368 and parameters: {'hidden_dim': 64, 'dropout': 0.2787392669970705, 'lr': 0.0006870071279323353}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:22,479] Trial 5 finished with value: 0.6666666269302368 and parameters: {'hidden_dim': 64, 'dropout': 0.09477145042790897, 'lr': 0.000227992911334632}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:22,754] Trial 6 finished with value: 0.7300000190734863 and parameters: {'hidden_dim': 128, 'dropout': 0.23439656377627605, 'lr': 0.004931611664866639}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:23,015] Trial 7 finished with value: 0.7600000500679016 and parameters: {'hidden_dim': 128, 'dropout': 0.006453329831086784, 'lr': 0.0008240553161389622}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:23,277] Trial 8 finished with value: 0.7333333492279053 and parameters: {'hidden_dim': 64, 'dropout': 0.1797164248814635, 'lr': 0.0019064007768473405}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:23,567] Trial 9 finished with value: 0.7933333516120911 and parameters: {'hidden_dim': 256, 'dropout': 0.22875865042871765, 'lr': 0.0004989860230335421}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:23,852] Trial 10 finished with value: 0.690000057220459 and parameters: {'hidden_dim': 256, 'dropout': 0.002283995450554077, 'lr': 0.00010555550738920503}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:24,131] Trial 11 finished with value: 0.7266666293144226 and parameters: {'hidden_dim': 128, 'dropout': 0.11218931264488916, 'lr': 0.004557758077104984}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:24,640] Trial 12 finished with value: 0.7433333396911621 and parameters: {'hidden_dim': 128, 'dropout': 0.0770097486175974, 'lr': 0.0015373094392718873}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:24,915] Trial 13 finished with value: 0.7833333611488342 and parameters: {'hidden_dim': 256, 'dropout': 0.05902570065453176, 'lr': 0.00038853781176773164}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:25,184] Trial 14 finished with value: 0.7600000500679016 and parameters: {'hidden_dim': 128, 'dropout': 0.1389714175290397, 'lr': 0.00278175623229572}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:25,494] Trial 15 finished with value: 0.7233333587646484 and parameters: {'hidden_dim': 256, 'dropout': 0.038225382677431474, 'lr': 0.0009462553759503207}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:25,767] Trial 16 finished with value: 0.690000057220459 and parameters: {'hidden_dim': 128, 'dropout': 0.1382472332081852, 'lr': 0.0002624613089027327}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:26,031] Trial 17 finished with value: 0.65666663646698 and parameters: {'hidden_dim': 128, 'dropout': 0.03749461276997977, 'lr': 0.00011539133873173146}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:26,302] Trial 18 finished with value: 0.7900000810623169 and parameters: {'hidden_dim': 256, 'dropout': 0.16240230686765816, 'lr': 0.001038737193307782}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:26,555] Trial 19 finished with value: 0.7166666984558105 and parameters: {'hidden_dim': 64, 'dropout': 0.1170973697289229, 'lr': 0.003002331735287689}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:26,832] Trial 20 finished with value: 0.7800000905990601 and parameters: {'hidden_dim': 256, 'dropout': 0.2939577365122773, 'lr': 0.0003941449732556028}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:27,138] Trial 21 finished with value: 0.7099999785423279 and parameters: {'hidden_dim': 256, 'dropout': 0.2229061161317638, 'lr': 0.001563679571807597}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:27,423] Trial 22 finished with value: 0.8166666626930237 and parameters: {'hidden_dim': 256, 'dropout': 0.1984339676169402, 'lr': 0.002531253597771137}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:27,707] Trial 23 finished with value: 0.7900000810623169 and parameters: {'hidden_dim': 256, 'dropout': 0.2579058033054071, 'lr': 0.0037573107597235105}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:27,986] Trial 24 finished with value: 0.7900000810623169 and parameters: {'hidden_dim': 256, 'dropout': 0.16834911579146464, 'lr': 0.002984829390614665}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:28,247] Trial 25 finished with value: 0.7933333516120911 and parameters: {'hidden_dim': 128, 'dropout': 0.19949522514856022, 'lr': 0.0022767909889706444}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:28,535] Trial 26 finished with value: 0.8100000023841858 and parameters: {'hidden_dim': 256, 'dropout': 0.12103714676380677, 'lr': 0.0012826576869271026}. Best is trial 1 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 19:11:28,818] Trial 27 finished with value: 0.846666693687439 and parameters: {'hidden_dim': 256, 'dropout': 0.08196706282398299, 'lr': 0.0005439883955058748}. Best is trial 27 with value: 0.846666693687439.\n",
      "[I 2025-11-25 19:11:29,094] Trial 28 finished with value: 0.7866666913032532 and parameters: {'hidden_dim': 256, 'dropout': 0.06824177510291123, 'lr': 0.0005862191766749211}. Best is trial 27 with value: 0.846666693687439.\n",
      "[I 2025-11-25 19:11:29,383] Trial 29 finished with value: 0.7866666316986084 and parameters: {'hidden_dim': 256, 'dropout': 0.028202886995833454, 'lr': 0.0003218719160992277}. Best is trial 27 with value: 0.846666693687439.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mrun_hyperparameter_search\u001b[37m has finished in \u001b[0m\u001b[38;5;105m9.167s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_best_model\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_best_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m1.160s\u001b[37m.\u001b[0m\n",
      "\u001b[37mPipeline run has finished in \u001b[0m\u001b[38;5;105m12.384s\u001b[37m.\u001b[0m\n",
      "Pipeline run status: completed\n",
      "Best hyperparameters:\n",
      "- best_hidden_dim: 256\n",
      "- best_dropout: 0.08196706282398299\n",
      "- best_lr: 0.0005439883955058748\n",
      "- best_accuracy: 0.846666693687439\n",
      "- n_trials: 30\n"
     ]
    }
   ],
   "source": [
    "run = tuning_pipeline.with_options(enable_cache=False)(n_trials=30)\n",
    "print(f\"Pipeline run status: {run.status}\")\n",
    "\n",
    "tuned_module = load_step_output(run, \"train_best_model\")\n",
    "datamodule = load_step_output(run, \"create_datamodule\")\n",
    "best_params = load_step_output(run, \"run_hyperparameter_search\")\n",
    "\n",
    "if tuned_module is None or datamodule is None or best_params is None:\n",
    "    raise RuntimeError(\"Failed to load artifacts from the tuning pipeline.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tuned_module = tuned_module.to(device).eval()\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"- {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect",
   "metadata": {},
   "source": [
    "## Inspect the Tuned Model\n",
    "\n",
    "Check that the tuned model has the expected shape, parameter count, and device placement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inspect-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model Summary:\n",
      "- Run: tuning_pipeline-2025_11_26-00_11_19_389987\n",
      "- Device: cuda:0\n",
      "- Parameters: 1,848,324\n",
      "- Nodes per batch: 370 | Features: 5\n",
      "- Edges: 1218\n",
      "- Output logits shape: (32, 3)\n"
     ]
    }
   ],
   "source": [
    "device = next(tuned_module.parameters()).device\n",
    "param_count = sum(p.numel() for p in tuned_module.parameters())\n",
    "\n",
    "train_loader = datamodule.train_dataloader()\n",
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "print(\"Tuned Model Summary:\")\n",
    "print(f\"- Run: {run.name}\")\n",
    "print(f\"- Device: {device}\")\n",
    "print(f\"- Parameters: {param_count:,}\")\n",
    "print(f\"- Nodes per batch: {first_batch.x.shape[0]} | Features: {first_batch.x.shape[1]}\")\n",
    "print(f\"- Edges: {first_batch.edge_index.shape[1]}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = tuned_module(first_batch.to(device))\n",
    "    print(f\"- Output logits shape: {tuple(logits.shape)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accuracy-intro",
   "metadata": {},
   "source": [
    "## Evaluate Validation Accuracy\n",
    "\n",
    "Run the tuned model on the validation split. We handle label shapes explicitly because\n",
    "PyG batches graph-level labels into `(batch_size, num_classes)` tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accuracy-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 77.0% (77/100)\n"
     ]
    }
   ],
   "source": [
    "val_loader = datamodule.val_dataloader()\n",
    "if isinstance(val_loader, list) and len(val_loader) == 0:\n",
    "    val_loader = datamodule.train_dataloader()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "tuned_module.eval()\n",
    "\n",
    "for batch in val_loader:\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = tuned_module(batch)\n",
    "\n",
    "    labels = batch.y\n",
    "    if labels.dim() == 1:\n",
    "        if labels.shape[0] % 3 == 0:\n",
    "            labels = labels.view(-1, 3)\n",
    "        else:\n",
    "            labels = labels.unsqueeze(0)\n",
    "    labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    correct += int((preds == labels).sum().item())\n",
    "    total += int(labels.numel())\n",
    "\n",
    "accuracy = correct / total if total > 0 else 0.0\n",
    "print(f\"Validation accuracy: {accuracy:.1%} ({correct}/{total})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pioneerml)",
   "language": "python",
   "name": "pioneerml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
