{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b1537d",
   "metadata": {},
   "source": [
    "# Tutorial 0: ZenML Quickstart\n",
    "\n",
    "This tutorial demonstrates the complete workflow for training a model with ZenML\n",
    "and visualizing the results. You'll learn how to:\n",
    "\n",
    "- Set up ZenML in notebook-friendly mode (auto-detects project root, uses in-memory storage)\n",
    "- Run a complete training pipeline on synthetic graph data\n",
    "- Load trained models and predictions from ZenML artifacts\n",
    "- Generate and interpret diagnostic plots inline in the notebook\n",
    "\n",
    "**Why ZenML?** ZenML manages the entire ML pipeline lifecycle - it tracks\n",
    "experiments, caches step outputs, and ensures reproducibility. By storing\n",
    "artifacts (models, data, predictions) in ZenML, we can re-run training once\n",
    "and then quickly iterate on analysis and visualization without re-training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5345adea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mCreating database tables\u001b[0m\n",
      "\u001b[37mCreating default project 'default' ...\u001b[0m\n",
      "\u001b[37mCreating default stack...\u001b[0m\n",
      "\u001b[33mThe current repo active project is no longer available.\u001b[0m\n",
      "\u001b[37mSetting the repo active project to 'default'.\u001b[0m\n",
      "\u001b[33mThe current repo active stack is no longer available. Resetting the active stack to default.\u001b[0m\n",
      "\u001b[33mThe current global active project is no longer available.\u001b[0m\n",
      "\u001b[37mSetting the global active project to 'default'.\u001b[0m\n",
      "\u001b[33mThe current global active stack is no longer available. Resetting the active stack to default.\u001b[0m\n",
      "\u001b[37mReloading configuration file /home/jack/python_projects/pioneerML/.zen/config.yaml\u001b[0m\n",
      "\u001b[37mSetting the repo active project to 'default'.\u001b[0m\n",
      "\u001b[33mSetting the repo active stack to default.\u001b[0m\n",
      "ZenML initialized with stack: default\n"
     ]
    }
   ],
   "source": [
    "run = zenml_training_pipeline.with_options(enable_cache=False)()\n",
    "print(f\"Pipeline run status: {run.status}\")\n",
    "\n",
    "trained_module = load_step_output(run, \"train_module\")\n",
    "datamodule = load_step_output(run, \"build_datamodule\")\n",
    "# For tuple outputs, ZenML creates separate outputs named output_0, output_1, etc.\n",
    "predictions = load_step_output(run, \"collect_predictions\", output_name=\"output_0\")\n",
    "targets = load_step_output(run, \"collect_predictions\", output_name=\"output_1\")\n",
    "\n",
    "if trained_module is None or datamodule is None or predictions is None or targets is None:\n",
    "    raise RuntimeError(\"Could not load artifacts from the zenml_training_pipeline run.\")\n",
    "\n",
    "trained_module.eval()\n",
    "datamodule.setup(stage=\"fit\")\n",
    "device = next(trained_module.parameters()).device\n",
    "print(f\"Loaded artifacts from run {run.name} (device={device})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c85e3",
   "metadata": {},
   "source": [
    "## Run the Training Pipeline\n",
    "\n",
    "Here we execute the complete ZenML training pipeline. The pipeline consists of\n",
    "several steps:\n",
    "\n",
    "1. **build_datamodule**: Creates synthetic graph data and splits it into train/val sets\n",
    "2. **build_module**: Instantiates the GroupClassifier model wrapped in a Lightning module\n",
    "3. **train_module**: Trains the model using PyTorch Lightning (auto-detects CPU/GPU)\n",
    "4. **collect_predictions**: Runs inference on the validation set to get predictions and targets\n",
    "\n",
    "**Why use `enable_cache=False`?** This ensures the pipeline runs fresh each time,\n",
    "which is useful for tutorials. In production, you'd typically enable caching to\n",
    "skip re-running unchanged steps.\n",
    "\n",
    "After the pipeline completes, we load the artifacts (trained model, datamodule,\n",
    "predictions, targets) using `load_step_output`. These artifacts are stored by\n",
    "ZenML and can be reloaded anytime without re-running the pipeline - this makes\n",
    "notebooks fast and interactive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0696cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mInitiating a new run for the pipeline: \u001b[0m\u001b[38;5;105mzenml_training_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mRegistered new pipeline: \u001b[0m\u001b[38;5;105mzenml_training_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mCaching is disabled by default for \u001b[0m\u001b[38;5;105mzenml_training_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mUsing user: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mUsing stack: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  artifact_store: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  orchestrator: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  deployer: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mYou can visualize your pipeline runs in the \u001b[0m\u001b[38;5;105mZenML Dashboard\u001b[37m. In order to try it locally, please run \u001b[0m\u001b[38;5;105mzenml login --local\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_datamodule\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_datamodule\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.094s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_module\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_module\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.085s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_module\u001b[37m has started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model   | GroupClassifier   | 1.1 M  | train\n",
      "1 | loss_fn | BCEWithLogitsLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.522     Total estimated model params size (MB)\n",
      "47        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c438934a84a48109ab60c1da19304a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[train_module] /home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \u001b[0m\u001b[38;5;105mnum_workers\u001b[33m argument\u001b[0m\u001b[38;5;105m to \u001b[33mnum_workers=15\u001b[0m\u001b[38;5;105m in the \u001b[33mDataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "\u001b[33m[train_module] /home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \u001b[0m\u001b[38;5;105mnum_workers\u001b[33m argument\u001b[0m\u001b[38;5;105m to \u001b[33mnum_workers=15\u001b[0m\u001b[38;5;105m in the \u001b[33mDataLoader` to improve performance.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3442f15525045828a3f9285b8c3b6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd042c2aaef47f09a535bc4150e20ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009a762b3d484ef681b77bde4a8d6d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d42c7813484f3786e0bf22b82fd312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b167c0ae75464d9daa15e7f34e55640f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09551cb69d0342f7b8891ca59ee4b02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_module\u001b[37m has finished in \u001b[0m\u001b[38;5;105m1.341s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcollect_predictions\u001b[37m has started.\u001b[0m\n",
      "\u001b[33m[collect_predictions] No materializer is registered for type \u001b[0m\u001b[38;5;105m<class 'torch.Tensor'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[38;5;105m<class 'torch.Tensor'>\u001b[33m according to the instructions at \u001b[0m\u001b[34mhttps://docs.zenml.io/concepts/artifacts/materializers\u001b[33m\u001b[0m\n",
      "\u001b[33m[collect_predictions] No materializer is registered for type \u001b[0m\u001b[38;5;105m<class 'torch.Tensor'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[38;5;105m<class 'torch.Tensor'>\u001b[33m according to the instructions at \u001b[0m\u001b[34mhttps://docs.zenml.io/concepts/artifacts/materializers\u001b[33m\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcollect_predictions\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.672s\u001b[37m.\u001b[0m\n",
      "\u001b[37mPipeline run has finished in \u001b[0m\u001b[38;5;105m3.109s\u001b[37m.\u001b[0m\n",
      "Pipeline run status: completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in &lt;module&gt;:6                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>trained_module = load_step_output(run, <span style=\"color: #808000; text-decoration-color: #808000\">\"train_module\"</span>)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>datamodule = load_step_output(run, <span style=\"color: #808000; text-decoration-color: #808000\">\"build_datamodule\"</span>)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 6 predictions = <span style=\"font-weight: bold; text-decoration: underline\">load_step_output(run, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"collect_predictions\"</span><span style=\"font-weight: bold; text-decoration: underline\">)[</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">0</span><span style=\"font-weight: bold; text-decoration: underline\">]</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>targets = load_step_output(run, <span style=\"color: #808000; text-decoration-color: #808000\">\"collect_predictions\"</span>)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> trained_module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> datamodule <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'NoneType'</span> object is not subscriptable\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in <module>:6                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0mtrained_module = load_step_output(run, \u001b[33m\"\u001b[0m\u001b[33mtrain_module\u001b[0m\u001b[33m\"\u001b[0m)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0mdatamodule = load_step_output(run, \u001b[33m\"\u001b[0m\u001b[33mbuild_datamodule\u001b[0m\u001b[33m\"\u001b[0m)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 6 predictions = \u001b[1;4mload_step_output(run, \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mcollect_predictions\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m)[\u001b[0m\u001b[1;4;94m0\u001b[0m\u001b[1;4m]\u001b[0m                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0mtargets = load_step_output(run, \u001b[33m\"\u001b[0m\u001b[33mcollect_predictions\u001b[0m\u001b[33m\"\u001b[0m)[\u001b[94m1\u001b[0m]                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[94mif\u001b[0m trained_module \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m datamodule \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[32m'NoneType'\u001b[0m object is not subscriptable\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = zenml_training_pipeline.with_options(enable_cache=False)()\n",
    "print(f\"Pipeline run status: {run.status}\")\n",
    "\n",
    "trained_module = load_step_output(run, \"train_module\")\n",
    "datamodule = load_step_output(run, \"build_datamodule\")\n",
    "predictions = load_step_output(run, \"collect_predictions\")[0]\n",
    "targets = load_step_output(run, \"collect_predictions\")[1]\n",
    "\n",
    "if trained_module is None or datamodule is None:\n",
    "    raise RuntimeError(\"Could not load artifacts from the zenml_training_pipeline run.\")\n",
    "\n",
    "trained_module.eval()\n",
    "datamodule.setup(stage=\"fit\")\n",
    "device = next(trained_module.parameters()).device\n",
    "print(f\"Loaded artifacts from run {run.name} (device={device})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b9fba9",
   "metadata": {},
   "source": [
    "## Verify Predictions Were Collected\n",
    "\n",
    "The `collect_predictions` step in the pipeline has already run inference and\n",
    "collected predictions and targets. This cell simply verifies how many samples\n",
    "were processed. The predictions are raw logits (before sigmoid), and targets\n",
    "are one-hot encoded class labels - both ready for evaluation metrics and plots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Collected predictions for {len(targets)} samples via pipeline step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274faf19",
   "metadata": {},
   "source": [
    "## Visualize Training Diagnostics\n",
    "\n",
    "We generate four diagnostic plots to understand model performance. All plots are\n",
    "displayed inline in the notebook (no files saved) by setting `show=True` and\n",
    "`save_path=None`. This makes the notebook self-contained and easy to share.\n",
    "\n",
    "**1. Loss Curves** - Shows training and validation loss over epochs\n",
    "- **What it shows**: How well the model is learning during training\n",
    "- **Good signs**: Both curves decrease steadily and stay close together\n",
    "- **Warning signs**: Large gap between train/val (overfitting), or flat lines (not learning)\n",
    "\n",
    "**2. Confusion Matrices** - Per-class classification accuracy\n",
    "- **What it shows**: For each class (π, μ, e+), how many true positives, false positives,\n",
    "  true negatives, and false negatives\n",
    "- **Good signs**: Dark diagonal (correct predictions), light off-diagonal (few errors)\n",
    "- **Why normalized**: Makes it easy to compare classes with different sample sizes\n",
    "\n",
    "**3. ROC Curves** - Ranking quality across all possible thresholds\n",
    "- **What it shows**: True Positive Rate vs False Positive Rate as we vary the\n",
    "  classification threshold\n",
    "- **AUC score**: Area under curve - higher is better (1.0 = perfect, 0.5 = random)\n",
    "- **Good signs**: Curves in top-left corner, AUC > 0.8\n",
    "\n",
    "**4. Precision-Recall Curves** - Performance on imbalanced data\n",
    "- **What it shows**: Precision vs Recall trade-off as we vary the threshold\n",
    "- **Average Precision**: Summarizes performance, especially important for imbalanced classes\n",
    "- **Good signs**: High curves that maintain precision even at high recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(trained_module, title=\"Quickstart: Loss Curves\", show=True)\n",
    "\n",
    "plot_multilabel_confusion_matrix(\n",
    "    predictions=predictions,\n",
    "    targets=targets,\n",
    "    class_names=[\"pi\", \"mu\", \"e+\"],\n",
    "    threshold=0.5,\n",
    "    normalize=True,\n",
    "    save_path=None,\n",
    "    show=True,\n",
    ")\n",
    "\n",
    "plot_roc_curves(\n",
    "    predictions=predictions,\n",
    "    targets=targets,\n",
    "    class_names=[\"pi\", \"mu\", \"e+\"],\n",
    "    save_path=None,\n",
    "    show=True,\n",
    ")\n",
    "\n",
    "plot_precision_recall_curves(\n",
    "    predictions=predictions,\n",
    "    targets=targets,\n",
    "    class_names=[\"pi\", \"mu\", \"e+\"],\n",
    "    save_path=None,\n",
    "    show=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
