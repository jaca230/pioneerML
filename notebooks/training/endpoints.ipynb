{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a689703",
   "metadata": {},
   "source": [
    "# Endpoint Regressor (ZenML)\n",
    "\n",
    "Train the `EndpointRegressor` (stereo, quantile endpoints) on raw hit graphs. Mirrors the group classifier notebook: configure ZenML, set up Optuna, run the pipeline, inspect best params, save model/metadata, and run quick diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6557550d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ZenML repository root: /home/jack/python_projects/pioneerML\n",
      "Ensure this is the top-level of your repo (.zen must live here).\n",
      "ZenML ready with stack: default\n"
     ]
    }
   ],
   "source": [
    "from pioneerml.zenml import utils as zenml_utils\n",
    "\n",
    "PROJECT_ROOT = zenml_utils.find_project_root()\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(root_path=PROJECT_ROOT, use_in_memory=True)\n",
    "print(f\"ZenML ready with stack: {zenml_client.active_stack_model.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2508d1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Optuna storage: sqlite:////home/jack/python_projects/pioneerML/.optuna/endpoint_regressor.db\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from pathlib import Path\n",
    "from pioneerml.zenml import load_step_output\n",
    "from pioneerml.zenml.pipelines.training import endpoint_optuna_pipeline\n",
    "from pioneerml.optuna import OptunaStudyManager\n",
    "\n",
    "# Set up Optuna storage\n",
    "optuna_manager = OptunaStudyManager(\n",
    "    project_root=PROJECT_ROOT,\n",
    "    study_name=\"endpoint_regressor\",\n",
    ")\n",
    "optuna_storage = optuna_manager.resolve_storage()\n",
    "print(f\"Using Optuna storage: {optuna_storage}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e60842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using group_probs pattern: /home/jack/python_projects/pioneerML/data/upstream_preds/group_probs_batch_*.npz\n",
      "\u001b[37mInitiating a new run for the pipeline: \u001b[0m\u001b[38;5;105mendpoint_optuna_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mCaching is disabled by default for \u001b[0m\u001b[38;5;105mendpoint_optuna_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mUsing user: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mUsing stack: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  artifact_store: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  deployer: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  orchestrator: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mYou can visualize your pipeline runs in the \u001b[0m\u001b[38;5;105mZenML Dashboard\u001b[37m. In order to try it locally, please run \u001b[0m\u001b[38;5;105mzenml login --local\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_endpoint_datamodule\u001b[37m has started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[build_endpoint_datamodule] Auto-detected num_workers: 11 (from 12 CPU cores, using cores-1)\n",
      "[build_endpoint_datamodule] Starting to load data from: hits=/home/jack/python_projects/pioneerML/data/raw_hits_info/hits_batch_*.npy, info=/home/jack/python_projects/pioneerML/data/raw_hits_info/group_info_batch_*.npy\n",
      "[build_endpoint_datamodule] Limiting to 11 files (from 11 total files found, max_files=20)\n",
      "[build_endpoint_datamodule] Limiting to 11 files (from 11 total files found, max_files=20)\n",
      "[build_endpoint_datamodule] Loaded 109817 groups from 11 file pairs\n",
      "[build_endpoint_datamodule] Loaded 109817 groups. Building datamodule...\n",
      "[build_endpoint_datamodule] Setup complete. Train: 93345, Val: 16472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mbuild_endpoint_datamodule\u001b[37m has finished in \u001b[0m\u001b[38;5;105m25.431s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mrun_endpoint_hparam_search\u001b[37m has started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 04:29:20,866] Using an existing study with name 'endpoint_regressor' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22859fc91a0044d09f9c849cb31335ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 5070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model   │ OrthogonalEndpointRegressor │  1.2 M │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ loss_fn │ MSELoss                     │      0 │ train │     0 │\n",
       "└───┴─────────┴─────────────────────────────┴────────┴───────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                       \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model   │ OrthogonalEndpointRegressor │  1.2 M │ train │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ loss_fn │ MSELoss                     │      0 │ train │     0 │\n",
       "└───┴─────────┴─────────────────────────────┴────────┴───────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.2 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.2 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 4                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 71                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.2 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.2 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 4                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 71                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08d47af173c46309e3d56c26ea13ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2026-01-04 04:29:24,640] Trial 6 failed with parameters: {'batch_size': 64, 'hidden': 160, 'heads': 2, 'layers': 3, 'dropout': 0.06001435441815274, 'lr': 0.004995134115523524, 'weight_decay': 9.74486608633666e-06} because of the following error: KeyError(Caught KeyError in DataLoader worker process 9.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py\", line 27, in __call__\n",
      "    return Batch.from_data_list(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/batch.py\", line 97, in from_data_list\n",
      "    batch, slice_dict, inc_dict = collate(\n",
      "                                  ^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/collate.py\", line 95, in collate\n",
      "    values = [store[attr] for store in stores]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/collate.py\", line 95, in <listcomp>\n",
      "    values = [store[attr] for store in stores]\n",
      "              ~~~~~^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/storage.py\", line 118, in __getitem__\n",
      "    return self._mapping[key]\n",
      "           ~~~~~~~~~~~~~^^^^^\n",
      "KeyError: 'group_probs'\n",
      ").\n",
      "Traceback (most recent call last):\n",
      "[run_endpoint_hparam_search] Traceback (most recent call last):\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/zenml/pipelines/training/endpoint_pipeline.py\", line 171, in objective\n",
      "    trainer.fit(lightning_module, datamodule=datamodule)\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/python_projects/pioneerML/src/pioneerml/zenml/pipelines/training/endpoint_pipeline.py\", line 171, in objective\n",
      "    trainer.fit(lightning_module, datamodule=datamodule)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 584, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 584, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 630, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 630, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1079, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1079, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1123, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1123, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in run\n",
      "    self.advance()\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in run\n",
      "    self.advance()\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 465, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 465, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 153, in run\n",
      "    self.advance(data_fetcher)\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 153, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 311, in advance\n",
      "    batch, _, __ = next(data_fetcher)\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 311, in advance\n",
      "    batch, _, __ = next(data_fetcher)\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py\", line 134, in __next__\n",
      "    batch = super().__next__()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py\", line 134, in __next__\n",
      "    batch = super().__next__()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py\", line 61, in __next__\n",
      "    batch = next(self.iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py\", line 61, in __next__\n",
      "    batch = next(self.iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 78, in __next__\n",
      "    out[i] = next(self.iterators[i])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 78, in __next__\n",
      "    out[i] = next(self.iterators[i])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1479, in _next_data\n",
      "    return self._process_data(data, worker_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1479, in _next_data\n",
      "    return self._process_data(data, worker_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1541, in _process_data\n",
      "    data.reraise()\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1541, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/_utils.py\", line 769, in reraise\n",
      "    raise exception\n",
      "[run_endpoint_hparam_search]   File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/_utils.py\", line 769, in reraise\n",
      "    raise exception\n",
      "KeyError: Caught KeyError in DataLoader worker process 9.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py\", line 27, in __call__\n",
      "    return Batch.from_data_list(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/batch.py\", line 97, in from_data_list\n",
      "    batch, slice_dict, inc_dict = collate(\n",
      "                                  ^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/collate.py\", line 95, in collate\n",
      "    values = [store[attr] for store in stores]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/collate.py\", line 95, in <listcomp>\n",
      "    values = [store[attr] for store in stores]\n",
      "              ~~~~~^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/storage.py\", line 118, in __getitem__\n",
      "    return self._mapping[key]\n",
      "           ~~~~~~~~~~~~~^^^^^\n",
      "KeyError: 'group_probs'\n",
      "\n",
      "[run_endpoint_hparam_search] KeyError: Caught KeyError in DataLoader worker process 9.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py\", line 27, in __call__\n",
      "    return Batch.from_data_list(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/batch.py\", line 97, in from_data_list\n",
      "    batch, slice_dict, inc_dict = collate(\n",
      "                                  ^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/collate.py\", line 95, in collate\n",
      "    values = [store[attr] for store in stores]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/collate.py\", line 95, in <listcomp>\n",
      "    values = [store[attr] for store in stores]\n",
      "              ~~~~~^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/storage.py\", line 118, in __getitem__\n",
      "    return self._mapping[key]\n",
      "           ~~~~~~~~~~~~~^^^^^\n",
      "KeyError: 'group_probs'\n",
      "\n",
      "[W 2026-01-04 04:29:24,651] Trial 6 failed with value None.\n",
      "\u001b[31mFailed to run step \u001b[0m\u001b[38;5;105mrun_endpoint_hparam_search\u001b[31m: Caught KeyError in DataLoader worker process 9.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py\", line 27, in __call__\n",
      "    return Batch.from_data_list(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/batch.py\", line 97, in from_data_list\n",
      "    batch, slice_dict, inc_dict = collate(\n",
      "                                  ^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/collate.py\", line 95, in collate\n",
      "    values = [store[attr] for store in stores]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/collate.py\", line 95, in <listcomp>\n",
      "    values = [store[attr] for store in stores]\n",
      "              ~~~~~^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/storage.py\", line 118, in __getitem__\n",
      "    return self._mapping[key]\n",
      "           ~~~~~~~~~~~~~^^^^^\n",
      "KeyError: 'group_probs'\n",
      "\u001b[0m\n",
      "\u001b[31mStep run_endpoint_hparam_search failed.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/local/local_orchestrator.py\", line 160, in submit_pipeline\n",
      "    self.run_step(step=step)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/local/local_orchestrator.py\", line 160, in submit_pipeline\n",
      "    self.run_step(step=step)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/base_orchestrator.py\", line 445, in run_step\n",
      "    launch_step(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/base_orchestrator.py\", line 445, in run_step\n",
      "    launch_step(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/execution/step/utils.py\", line 78, in launch_step\n",
      "    step_run = _launch_without_retry()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/execution/step/utils.py\", line 78, in launch_step\n",
      "    step_run = _launch_without_retry()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/execution/step/utils.py\", line 65, in _launch_without_retry\n",
      "    return launcher.launch()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/execution/step/utils.py\", line 65, in _launch_without_retry\n",
      "    return launcher.launch()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py\", line 356, in launch\n",
      "    self._run_step(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py\", line 356, in launch\n",
      "    self._run_step(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py\", line 467, in _run_step\n",
      "    self._run_step_in_current_thread(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py\", line 467, in _run_step\n",
      "    self._run_step_in_current_thread(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py\", line 612, in _run_step_in_current_thread\n",
      "    runner.run(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py\", line 612, in _run_step_in_current_thread\n",
      "    runner.run(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_runner.py\", line 294, in run\n",
      "    raise step_exception\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_runner.py\", line 294, in run\n",
      "    raise step_exception\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_runner.py\", line 249, in run\n",
      "    return_values = step_instance.call_entrypoint(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_runner.py\", line 249, in run\n",
      "    return_values = step_instance.call_entrypoint(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/steps/base_step.py\", line 645, in call_entrypoint\n",
      "    return self.entrypoint(**validated_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/steps/base_step.py\", line 645, in call_entrypoint\n",
      "    return self.entrypoint(**validated_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/zenml/pipelines/training/endpoint_pipeline.py\", line 177, in run_endpoint_hparam_search\n",
      "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/zenml/pipelines/training/endpoint_pipeline.py\", line 177, in run_endpoint_hparam_search\n",
      "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/study.py\", line 490, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/study.py\", line 490, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 67, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 67, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 164, in _optimize_sequential\n",
      "    frozen_trial_id = _run_trial(study, func, catch)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 164, in _optimize_sequential\n",
      "    frozen_trial_id = _run_trial(study, func, catch)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 262, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 262, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/zenml/pipelines/training/endpoint_pipeline.py\", line 171, in objective\n",
      "    trainer.fit(lightning_module, datamodule=datamodule)\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/zenml/pipelines/training/endpoint_pipeline.py\", line 171, in objective\n",
      "    trainer.fit(lightning_module, datamodule=datamodule)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 584, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 584, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 630, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 630, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1079, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1079, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1123, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1123, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in run\n",
      "    self.advance()\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in run\n",
      "    self.advance()\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 465, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 465, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 153, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 153, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 311, in advance\n",
      "    batch, _, __ = next(data_fetcher)\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 311, in advance\n",
      "    batch, _, __ = next(data_fetcher)\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py\", line 134, in __next__\n",
      "    batch = super().__next__()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py\", line 134, in __next__\n",
      "    batch = super().__next__()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py\", line 61, in __next__\n",
      "    batch = next(self.iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py\", line 61, in __next__\n",
      "    batch = next(self.iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 78, in __next__\n",
      "    out[i] = next(self.iterators[i])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 78, in __next__\n",
      "    out[i] = next(self.iterators[i])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1479, in _next_data\n",
      "    return self._process_data(data, worker_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1479, in _next_data\n",
      "    return self._process_data(data, worker_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1541, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1541, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/_utils.py\", line 769, in reraise\n",
      "    raise exception\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/_utils.py\", line 769, in reraise\n",
      "    raise exception\n",
      "KeyError: Caught KeyError in DataLoader worker process 9.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py\", line 27, in __call__\n",
      "    return Batch.from_data_list(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/batch.py\", line 97, in from_data_list\n",
      "    batch, slice_dict, inc_dict = collate(\n",
      "                                  ^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/collate.py\", line 95, in collate\n",
      "    values = [store[attr] for store in stores]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/collate.py\", line 95, in <listcomp>\n",
      "    values = [store[attr] for store in stores]\n",
      "              ~~~~~^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/storage.py\", line 118, in __getitem__\n",
      "    return self._mapping[key]\n",
      "           ~~~~~~~~~~~~~^^^^^\n",
      "KeyError: 'group_probs'\n",
      "\n",
      "KeyError: Caught KeyError in DataLoader worker process 9.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py\", line 27, in __call__\n",
      "    return Batch.from_data_list(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/batch.py\", line 97, in from_data_list\n",
      "    batch, slice_dict, inc_dict = collate(\n",
      "                                  ^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/collate.py\", line 95, in collate\n",
      "    values = [store[attr] for store in stores]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/collate.py\", line 95, in <listcomp>\n",
      "    values = [store[attr] for store in stores]\n",
      "              ~~~~~^^^^^^\n",
      "  File \"/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch_geometric/data/storage.py\", line 118, in __getitem__\n",
      "    return self._mapping[key]\n",
      "           ~~~~~~~~~~~~~^^^^^\n",
      "KeyError: 'group_probs'\n",
      "\n",
      "\u001b[33mSkipping step train_best_endpoint due to failure in upstream step(s): run_endpoint_hparam_search (Execution mode continue_on_failure)\u001b[0m\n",
      "\u001b[33mSkipping step collect_endpoint_predictions due to the skipped upstream step(s) train_best_endpoint (Execution mode continue_on_failure)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in &lt;module&gt;:10                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>probs_pattern = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(Path(PROJECT_ROOT) / <span style=\"color: #808000; text-decoration-color: #808000\">\"data\"</span> / <span style=\"color: #808000; text-decoration-color: #808000\">\"upstream_preds\"</span> / <span style=\"color: #808000; text-decoration-color: #808000\">\"group_probs_batch_</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Using group_probs pattern: {</span>probs_pattern<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>10 run = <span style=\"font-weight: bold; text-decoration: underline\">endpoint_optuna_pipeline.with_options(enable_cache=</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">False</span><span style=\"font-weight: bold; text-decoration: underline\">)(</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"font-weight: bold; text-decoration: underline\">build_datamodule_params={</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"hits_pattern\"</span><span style=\"font-weight: bold; text-decoration: underline\">: hits_pattern,</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"info_pattern\"</span><span style=\"font-weight: bold; text-decoration: underline\">: info_pattern,</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/pipelines/</span><span style=\"font-weight: bold\">pipeline_defin</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"font-weight: bold\">ition.py</span>:1628 in __call__                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1625 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.entrypoint(*args, **kwargs)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[no-any-return]</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1626 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1627 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prepare(*args, **kwargs)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1628 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">._run()</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1629 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1630 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_entrypoint</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args: Any, **kwargs: Any) -&gt; Any:                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1631 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Calls the pipeline entrypoint function with the given arguments.</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/pipelines/</span><span style=\"font-weight: bold\">pipeline_defin</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"font-weight: bold\">ition.py</span>:1102 in _run                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1099 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"`zenml login --local`.\"</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1100 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1101 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1102 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">submit_pipeline(</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1103 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">snapshot=snapshot, stack=stack, placeholder_run=run</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1104 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1105 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/execution/pipeline/</span><span style=\"font-weight: bold\">utils</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"font-weight: bold\">.py</span>:115 in submit_pipeline                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># the run as failed if it's still in an unfinished state.</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>publish_failed_pipeline_run(placeholder_run.id)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">raise</span><span style=\"font-weight: bold; text-decoration: underline\"> e</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/execution/pipeline/</span><span style=\"font-weight: bold\">utils</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"font-weight: bold\">.py</span>:96 in submit_pipeline                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 93 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> prevent_pipeline_execution():                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 94 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 95 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>stack.prepare_pipeline_submission(snapshot=snapshot)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 96 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>stack.submit_pipeline(                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 97 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>snapshot=snapshot,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>placeholder_run=placeholder_run,                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/stack/</span><span style=\"font-weight: bold\">stack.py</span>:880 in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> submit_pipeline                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 877 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">snapshot: The pipeline snapshot.</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 878 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">placeholder_run: An optional placeholder run for the snapshot.</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 879 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 880 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">.orchestrator.run(</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 881 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">snapshot=snapshot, stack=</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">, placeholder_run=placeholder_run</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 882 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 883 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/</span><span style=\"font-weight: bold\">base_orche</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"font-weight: bold\">strator.py</span>:369 in run                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">366 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>combined_environment.update(step_environment)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">367 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>step_environments[invocation_id] = combined_environment            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">368 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>369 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>submission_result = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.submit_pipeline(                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">370 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>snapshot=snapshot,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">371 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>stack=stack,                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">372 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>base_environment=base_environment,                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/local/</span><span style=\"font-weight: bold\">loca</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"font-weight: bold\">l_orchestrator.py</span>:176 in submit_pipeline                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> step_exception                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> failed_steps:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>176 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">raise</span><span style=\"font-weight: bold; text-decoration: underline\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">RuntimeError</span><span style=\"font-weight: bold; text-decoration: underline\">(</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"Pipeline run has failed due to failure in step(s): \"</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">f\"{', '</span><span style=\"font-weight: bold; text-decoration: underline\">.join(failed_steps)</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">}\"</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Pipeline run has failed due to failure in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">step</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span>: run_endpoint_hparam_search\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in <module>:10                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0mprobs_pattern = \u001b[96mstr\u001b[0m(Path(PROJECT_ROOT) / \u001b[33m\"\u001b[0m\u001b[33mdata\u001b[0m\u001b[33m\"\u001b[0m / \u001b[33m\"\u001b[0m\u001b[33mupstream_preds\u001b[0m\u001b[33m\"\u001b[0m / \u001b[33m\"\u001b[0m\u001b[33mgroup_probs_batch_\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mUsing group_probs pattern: \u001b[0m\u001b[33m{\u001b[0mprobs_pattern\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m10 run = \u001b[1;4mendpoint_optuna_pipeline.with_options(enable_cache=\u001b[0m\u001b[1;4;94mFalse\u001b[0m\u001b[1;4m)(\u001b[0m                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;4mbuild_datamodule_params={\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mhits_pattern\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m: hits_pattern,\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33minfo_pattern\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m: info_pattern,\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2m/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/pipelines/\u001b[0m\u001b[1mpipeline_defin\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1mition.py\u001b[0m:1628 in __call__                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1625 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.entrypoint(*args, **kwargs)  \u001b[2m# type: ignore[no-any-return]\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1626 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1627 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.prepare(*args, **kwargs)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1628 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4;96mself\u001b[0m\u001b[1;4m._run()\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1629 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1630 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m_call_entrypoint\u001b[0m(\u001b[96mself\u001b[0m, *args: Any, **kwargs: Any) -> Any:                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1631 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Calls the pipeline entrypoint function with the given arguments.\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2m/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/pipelines/\u001b[0m\u001b[1mpipeline_defin\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1mition.py\u001b[0m:1102 in _run                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1099 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m`zenml login --local`.\u001b[0m\u001b[33m\"\u001b[0m                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1100 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m)                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1101 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1102 \u001b[2m│   │   │   │   \u001b[0m\u001b[1;4msubmit_pipeline(\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1103 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[1;4msnapshot=snapshot, stack=stack, placeholder_run=run\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1104 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4m)\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1105 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2m/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/execution/pipeline/\u001b[0m\u001b[1mutils\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1m.py\u001b[0m:115 in submit_pipeline                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# the run as failed if it's still in an unfinished state.\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpublish_failed_pipeline_run(placeholder_run.id)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m115 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m e\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2m/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/execution/pipeline/\u001b[0m\u001b[1mutils\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1m.py\u001b[0m:96 in submit_pipeline                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m prevent_pipeline_execution():                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   │   │   \u001b[0mstack.prepare_pipeline_submission(snapshot=snapshot)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 96 \u001b[2m│   │   │   \u001b[0mstack.submit_pipeline(                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 97 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msnapshot=snapshot,                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mplaceholder_run=placeholder_run,                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2m/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/stack/\u001b[0m\u001b[1mstack.py\u001b[0m:880 in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m submit_pipeline                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 877 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33msnapshot: The pipeline snapshot.\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 878 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mplaceholder_run: An optional placeholder run for the snapshot.\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 879 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 880 \u001b[2m│   │   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.orchestrator.run(\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 881 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4msnapshot=snapshot, stack=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m, placeholder_run=placeholder_run\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 882 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4m)\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 883 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2m/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/\u001b[0m\u001b[1mbase_orche\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1mstrator.py\u001b[0m:369 in run                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m366 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mcombined_environment.update(step_environment)                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mstep_environments[invocation_id] = combined_environment            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m369 \u001b[2m│   │   │   │   │   \u001b[0msubmission_result = \u001b[96mself\u001b[0m.submit_pipeline(                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m370 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0msnapshot=snapshot,                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m371 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mstack=stack,                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m372 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mbase_environment=base_environment,                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2m/home/jack/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/local/\u001b[0m\u001b[1mloca\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1ml_orchestrator.py\u001b[0m:176 in submit_pipeline                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m step_exception                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m failed_steps:                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m176 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;96mRuntimeError\u001b[0m\u001b[1;4m(\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mPipeline run has failed due to failure in step(s): \u001b[0m\u001b[1;4;33m\"\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4;33mf\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33m{\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m, \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4m.join(failed_steps)\u001b[0m\u001b[1;4;33m}\u001b[0m\u001b[1;4;33m\"\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m179 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4m)\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mPipeline run has failed due to failure in \u001b[1;35mstep\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m: run_endpoint_hparam_search\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run (or reuse) the Optuna + training pipeline\n",
    "\n",
    "hits_pattern = str(Path(PROJECT_ROOT) / \"data\" / \"raw_hits_info\" / \"hits_batch_*.npy\")\n",
    "info_pattern = str(Path(PROJECT_ROOT) / \"data\" / \"raw_hits_info\" / \"group_info_batch_*.npy\")\n",
    "\n",
    "# Optional: attach group probabilities from upstream classifier (batched files)\n",
    "probs_pattern = str(Path(PROJECT_ROOT) / \"data\" / \"upstream_preds\" / \"group_probs_batch_*.npz\")\n",
    "print(f\"Using group_probs pattern: {probs_pattern}\")\n",
    "\n",
    "run = endpoint_optuna_pipeline.with_options(enable_cache=False)(\n",
    "    build_datamodule_params={\n",
    "        \"hits_pattern\": hits_pattern,\n",
    "        \"info_pattern\": info_pattern,\n",
    "        \"group_probs_pattern\": probs_pattern,  # batched NPZs, aligned to hits/info batches\n",
    "        \"max_files\": 20,\n",
    "        \"limit_groups\": 1_000_000,\n",
    "        \"min_hits\": 2,\n",
    "        \"batch_size\": 64,\n",
    "        \"val_split\": 0.15,\n",
    "        \"seed\": 42,\n",
    "    },\n",
    "    run_hparam_search_params={\n",
    "        \"n_trials\": 1,\n",
    "        \"max_epochs\": 1,\n",
    "        \"limit_train_batches\": 0.8,\n",
    "        \"limit_val_batches\": 1.0,\n",
    "        \"storage\": optuna_storage,\n",
    "        \"study_name\": \"endpoint_regressor\",\n",
    "    },\n",
    "    train_best_model_params={\n",
    "        \"max_epochs\": 1,\n",
    "        \"early_stopping\": True,\n",
    "        \"early_stopping_patience\": 4,\n",
    "    },\n",
    ")\n",
    "print(f\"Run name: {run.name}\")\n",
    "print(f\"Run status: {run.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef421012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load artifacts and best params\n",
    "trained_module = load_step_output(run, \"train_best_endpoint\")\n",
    "datamodule = load_step_output(run, \"build_endpoint_datamodule\")\n",
    "predictions = load_step_output(run, \"collect_endpoint_predictions\", index=0)\n",
    "targets = load_step_output(run, \"collect_endpoint_predictions\", index=1)\n",
    "best_params = load_step_output(run, \"run_endpoint_hparam_search\")\n",
    "\n",
    "if trained_module is None or datamodule is None:\n",
    "    raise RuntimeError(\"Could not load artifacts from the optuna pipeline run.\")\n",
    "\n",
    "datamodule.setup(stage=\"fit\")\n",
    "trained_module.eval()\n",
    "device = next(trained_module.parameters()).device\n",
    "val_size = len(datamodule.val_dataset) if datamodule.val_dataset is not None else len(datamodule.train_dataset)\n",
    "print(f\"Loaded module on {device}; validation samples: {val_size}\")\n",
    "\n",
    "best_params_display = {k: v for k, v in best_params.items() if k != \"trial_history\"} if isinstance(best_params, dict) else best_params\n",
    "print(\"Best params from Optuna:\", best_params_display)\n",
    "print(\"Epochs actually run:\", getattr(trained_module, \"final_epochs_run\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick validation plots\n",
    "from pioneerml.evaluation.plots import plot_loss_curves, plot_regression_diagnostics\n",
    "\n",
    "plot_loss_curves(trained_module, title=\"Endpoint regressor: loss\", show=True)\n",
    "plot_regression_diagnostics(predictions=predictions, targets=targets, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model + metadata\n",
    "from pioneerml.metadata import TrainingMetadata, save_model_and_metadata, timestamp_now\n",
    "\n",
    "save_ts = timestamp_now()\n",
    "\n",
    "meta = TrainingMetadata(\n",
    "    model_type=\"EndpointRegressor\",\n",
    "    timestamp=save_ts,\n",
    "    run_name=run.name if 'run' in locals() else None,\n",
    "    best_hyperparameters=best_params,\n",
    "    best_score=best_params.get('best_score') if isinstance(best_params, dict) else None,\n",
    "    n_trials=best_params.get('n_trials') if isinstance(best_params, dict) else None,\n",
    "    training_config=getattr(trained_module, 'training_config', {}),\n",
    "    epochs_run=getattr(trained_module, 'final_epochs_run', None),\n",
    "    dataset_info={\n",
    "        'train_size': len(datamodule.train_dataset) if datamodule.train_dataset else 0,\n",
    "        'val_size': len(datamodule.val_dataset) if datamodule.val_dataset else 0,\n",
    "    },\n",
    "    model_architecture={\n",
    "        'hidden': best_params.get('hidden') if isinstance(best_params, dict) else None,\n",
    "        'heads': best_params.get('heads') if isinstance(best_params, dict) else None,\n",
    "        'layers': best_params.get('layers') if isinstance(best_params, dict) else None,\n",
    "        'dropout': best_params.get('dropout') if isinstance(best_params, dict) else None,\n",
    "    },\n",
    "    optuna_storage=optuna_storage,\n",
    "    optuna_study_name=optuna_manager.study_name,\n",
    ")\n",
    "\n",
    "paths = save_model_and_metadata(\n",
    "    model=trained_module.model,\n",
    "    metadata=meta,\n",
    "    state_dict_only=True,\n",
    ")\n",
    "\n",
    "print(\"Saved artifacts:\")\n",
    "for k, v in paths.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pioneerml)",
   "language": "python",
   "name": "pioneerml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
