{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Tutorial 3: Hyperparameter Tuning with Optuna\n",
    "\n",
    "This tutorial shows how to run Optuna sweeps inside a ZenML pipeline. You'll learn how to:\n",
    "\n",
    "- Generate synthetic graph data for tuning\n",
    "- Define a ZenML pipeline that includes an Optuna search step\n",
    "- Inspect the best hyperparameters and the tuned model\n",
    "- Evaluate the tuned model on the validation split\n",
    "\n",
    "Unlike earlier versions, the full pipeline now lives in the notebook so you can modify\n",
    "every step. We assume Optuna is installed (see `requirements.txt`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZenML initialized with stack: default\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import io\n",
    "import torch\n",
    "import optuna\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.data import Data\n",
    "from zenml import pipeline, step\n",
    "\n",
    "from pioneerml.models import GroupClassifier\n",
    "from pioneerml.training import GraphDataModule, GraphLightningModule\n",
    "from pioneerml.zenml.materializers import (\n",
    "    GraphDataModuleMaterializer,\n",
    "    PyGDataListMaterializer,\n",
    ")\n",
    "from pioneerml.zenml import load_step_output\n",
    "from pioneerml.zenml import utils as zenml_utils\n",
    "from pioneerml.zenml.utils import detect_available_accelerator\n",
    "\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(use_in_memory=True)\n",
    "print(f\"ZenML initialized with stack: {zenml_client.active_stack_model.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-overview",
   "metadata": {},
   "source": [
    "## Build the Tuning Pipeline\n",
    "\n",
    "The pipeline mirrors the structure from earlier tutorials and adds an Optuna step:\n",
    "\n",
    "1. `create_data`: synthetic graph classification dataset\n",
    "2. `create_datamodule`: wraps the dataset with train/val splits\n",
    "3. `run_hyperparameter_search`: Optuna study that picks hidden size, learning rate, dropout\n",
    "4. `train_best_model`: trains one final model with the best parameters\n",
    "\n",
    "Optuna runs entirely inside the pipeline, making the sweep reproducible and tracked in ZenML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pipeline-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_synthetic_tuning_data(num_samples: int = 400) -> list[Data]:\n",
    "    \"\"\"Generate a deliberately tricky dataset so Optuna can't hit 100% accuracy.\"\"\"\n",
    "    data: list[Data] = []\n",
    "\n",
    "    class_means = torch.tensor([\n",
    "        [0.7, -0.3, 0.2, 0.1, -0.1],\n",
    "        [-0.1, 0.8, -0.2, 0.3, 0.15],\n",
    "        [-0.6, -0.4, 0.4, -0.2, 0.25],\n",
    "    ])\n",
    "    class_drift = torch.tensor([\n",
    "        [0.4, 0.3, -0.1, 0.0, 0.2],\n",
    "        [-0.3, 0.2, 0.25, -0.15, -0.1],\n",
    "        [0.2, -0.4, 0.15, 0.25, -0.05],\n",
    "    ])\n",
    "    feature_scales = torch.tensor([\n",
    "        [1.0, 0.9, 1.1, 0.95, 1.05],\n",
    "        [0.95, 1.05, 0.85, 1.1, 0.9],\n",
    "        [1.1, 0.95, 0.9, 1.0, 1.0],\n",
    "    ])\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        label = torch.randint(0, 3, (1,)).item()\n",
    "        num_nodes = torch.randint(7, 18, (1,)).item()\n",
    "\n",
    "        mix_label = (label + torch.randint(1, 3, (1,)).item()) % 3\n",
    "        mix_ratio = torch.rand(1).item() * 0.6 + 0.2\n",
    "        prototype = mix_ratio * class_means[label] + (1 - mix_ratio) * class_means[mix_label]\n",
    "\n",
    "        t = torch.linspace(0, 1, steps=num_nodes).unsqueeze(1)\n",
    "        wiggles = torch.cat([\n",
    "            torch.sin(2.0 * torch.pi * t + label * 0.3),\n",
    "            torch.cos(3.0 * torch.pi * t + mix_ratio),\n",
    "            torch.sin(4.0 * torch.pi * t - mix_ratio * 0.5),\n",
    "            torch.cos(5.0 * torch.pi * t + label * 0.2),\n",
    "            torch.sin(6.0 * torch.pi * t - 0.1),\n",
    "        ], dim=1)\n",
    "\n",
    "        x = prototype + 0.4 * wiggles\n",
    "        x = x * feature_scales[label]\n",
    "\n",
    "        noise = torch.randn(num_nodes, 5)\n",
    "        correlated = noise + 0.35 * torch.matmul(noise, torch.ones(5, 5) * 0.1)\n",
    "        drift = class_drift[label] * torch.randn(num_nodes, 1)\n",
    "        x = x + 0.25 * correlated + drift\n",
    "\n",
    "        projection = torch.randn(5, 5) * 0.2 + torch.eye(5)\n",
    "        x = x @ projection\n",
    "\n",
    "        if label == 0:\n",
    "            ring = torch.stack([\n",
    "                torch.arange(num_nodes),\n",
    "                (torch.arange(num_nodes) + 1) % num_nodes,\n",
    "            ])\n",
    "            random_edges = torch.randint(0, num_nodes, (2, num_nodes * 2))\n",
    "            edge_index = torch.cat([ring, random_edges], dim=1)\n",
    "        elif label == 1:\n",
    "            cluster = max(3, num_nodes // 2)\n",
    "            src = torch.randint(0, cluster, (num_nodes * 3,))\n",
    "            dst = torch.randint(0, cluster, (num_nodes * 3,))\n",
    "            long_jump = torch.randint(0, num_nodes, (2, num_nodes))\n",
    "            edge_index = torch.cat([torch.stack([src, dst], dim=0), long_jump], dim=1)\n",
    "        else:\n",
    "            src = torch.randint(0, num_nodes, (num_nodes * 2,))\n",
    "            dst = (src + torch.randint(2, 7, (num_nodes * 2,))) % num_nodes\n",
    "            extra = torch.randint(0, num_nodes, (2, num_nodes))\n",
    "            edge_index = torch.cat([torch.stack([src, dst], dim=0), extra], dim=1)\n",
    "\n",
    "        edge_attr = torch.randn(edge_index.shape[1], 4) * 0.15 + label * 0.04\n",
    "\n",
    "        noisy_label = label\n",
    "        if torch.rand(1).item() < 0.1:\n",
    "            noisy_label = torch.randint(0, 3, (1,)).item()\n",
    "\n",
    "        y = torch.zeros(3)\n",
    "        y[noisy_label] = 1.0\n",
    "\n",
    "        data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def _run_quietly(fn):\n",
    "    \"\"\"Suppress Lightning/stdout noise while preserving Optuna logs.\"\"\"\n",
    "    buffer_out = io.StringIO()\n",
    "    buffer_err = io.StringIO()\n",
    "    with contextlib.redirect_stdout(buffer_out), contextlib.redirect_stderr(buffer_err):\n",
    "        return fn()\n",
    "\n",
    "\n",
    "@step(output_materializers=PyGDataListMaterializer, enable_cache=False)\n",
    "def create_data() -> list[Data]:\n",
    "    \"\"\"Step 1: Generate synthetic graphs for tuning.\"\"\"\n",
    "    return create_synthetic_tuning_data()\n",
    "\n",
    "\n",
    "@step(output_materializers=GraphDataModuleMaterializer, enable_cache=False)\n",
    "def create_datamodule(data: list[Data]) -> GraphDataModule:\n",
    "    \"\"\"Step 2: Wrap the dataset in a Lightning DataModule.\"\"\"\n",
    "    return GraphDataModule(dataset=data, val_split=0.25, batch_size=32, num_workers=0)\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def run_hyperparameter_search(datamodule: GraphDataModule, n_trials: int = 4) -> dict:\n",
    "    \"\"\"Step 3: Perform an Optuna search over hidden size, dropout, and learning rate.\"\"\"\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
    "        lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "\n",
    "        model = GroupClassifier(num_classes=3, hidden=hidden_dim, dropout=dropout)\n",
    "        lightning_module = GraphLightningModule(model, task=\"classification\", lr=lr)\n",
    "        accelerator, devices = detect_available_accelerator()\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator=accelerator,\n",
    "            devices=devices,\n",
    "            max_epochs=2,\n",
    "            logger=False,\n",
    "            enable_checkpointing=False,\n",
    "            enable_progress_bar=False,\n",
    "        )\n",
    "\n",
    "        datamodule.setup(stage=\"fit\")\n",
    "\n",
    "        def fit():\n",
    "            trainer.fit(lightning_module, datamodule=datamodule)\n",
    "\n",
    "        def validate():\n",
    "            return trainer.validate(lightning_module, datamodule=datamodule, verbose=False)\n",
    "\n",
    "        _run_quietly(fit)\n",
    "        val_metrics = _run_quietly(validate)\n",
    "\n",
    "        if val_metrics and isinstance(val_metrics[0], dict):\n",
    "            accuracy = val_metrics[0].get(\"val_accuracy\")\n",
    "            if accuracy is not None:\n",
    "                return float(accuracy)\n",
    "            loss = val_metrics[0].get(\"val_loss\")\n",
    "            if loss is not None:\n",
    "                return 1.0 / (1.0 + float(loss))\n",
    "        return 0.0\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    return {\n",
    "        \"best_hidden_dim\": study.best_params[\"hidden_dim\"],\n",
    "        \"best_dropout\": study.best_params[\"dropout\"],\n",
    "        \"best_lr\": study.best_params[\"lr\"],\n",
    "        \"best_accuracy\": study.best_value,\n",
    "        \"n_trials\": len(study.trials),\n",
    "    }\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def train_best_model(best_params: dict, datamodule: GraphDataModule) -> GraphLightningModule:\n",
    "    \"\"\"Step 4: Train a final model with the best Optuna parameters.\"\"\"\n",
    "    model = GroupClassifier(\n",
    "        num_classes=3,\n",
    "        hidden=best_params[\"best_hidden_dim\"],\n",
    "        dropout=best_params[\"best_dropout\"],\n",
    "    )\n",
    "    lightning_module = GraphLightningModule(\n",
    "        model,\n",
    "        task=\"classification\",\n",
    "        lr=best_params[\"best_lr\"],\n",
    "    )\n",
    "\n",
    "    accelerator, devices = detect_available_accelerator()\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        max_epochs=5,\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    datamodule.setup(stage=\"fit\")\n",
    "\n",
    "    def fit():\n",
    "        trainer.fit(lightning_module, datamodule=datamodule)\n",
    "\n",
    "    _run_quietly(fit)\n",
    "    return lightning_module.eval()\n",
    "\n",
    "\n",
    "@pipeline\n",
    "def tuning_pipeline(n_trials: int = 4):\n",
    "    data = create_data()\n",
    "    datamodule = create_datamodule(data)\n",
    "    best_params = run_hyperparameter_search(datamodule, n_trials=n_trials)\n",
    "    tuned_model = train_best_model(best_params, datamodule)\n",
    "    return tuned_model, datamodule, best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-section",
   "metadata": {},
   "source": [
    "## Run the Optuna Sweep\n",
    "\n",
    "Execute the pipeline with a small number of trials (increase `n_trials` for real sweeps).\n",
    "The pipeline stores all runs and best parameters in ZenML so you can reproduce the sweep later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "run-pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mInitiating a new run for the pipeline: \u001b[0m\u001b[38;5;105mtuning_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mCaching is disabled by default for \u001b[0m\u001b[38;5;105mtuning_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mUsing user: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mUsing stack: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  artifact_store: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  orchestrator: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  deployer: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mYou can visualize your pipeline runs in the \u001b[0m\u001b[38;5;105mZenML Dashboard\u001b[37m. In order to try it locally, please run \u001b[0m\u001b[38;5;105mzenml login --local\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_data\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_data\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.117s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_datamodule\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_datamodule\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.065s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mrun_hyperparameter_search\u001b[37m has started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-25 04:12:55,129] A new study created in memory with name: no-name-325d2f6e-ce2d-4d3b-8a5c-4fba5c15cd97\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model   | GroupClassifier   | 118 K  | train\n",
      "1 | loss_fn | BCEWithLogitsLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "118 K     Trainable params\n",
      "0         Non-trainable params\n",
      "118 K     Total params\n",
      "0.472     Total estimated model params size (MB)\n",
      "47        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[run_hyperparameter_search] /home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \u001b[0m\u001b[38;5;105mnum_workers\u001b[33m argument\u001b[0m\u001b[38;5;105m to \u001b[33mnum_workers=15\u001b[0m\u001b[38;5;105m in the \u001b[33mDataLoader` to improve performance.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-11-25 04:12:55,356] Trial 0 failed with parameters: {'hidden_dim': 64, 'dropout': 0.08534222827635905, 'lr': 0.00010689969563242122} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (326x6 and 5x64)').\n",
      "Traceback (most recent call last):\n",
      "[run_hyperparameter_search] Traceback (most recent call last):\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_78200/663702664.py\", line 128, in objective\n",
      "    trainer.fit(lightning_module, datamodule=datamodule)\n",
      "[run_hyperparameter_search]   File \"/tmp/ipykernel_78200/663702664.py\", line 128, in objective\n",
      "    trainer.fit(lightning_module, datamodule=datamodule)\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 560, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 560, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 598, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 598, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1011, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1011, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1053, in _run_stage\n",
      "    self._run_sanity_check()\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1053, in _run_stage\n",
      "    self._run_sanity_check()\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1082, in _run_sanity_check\n",
      "    val_loop.run()\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1082, in _run_sanity_check\n",
      "    val_loop.run()\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py\", line 179, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py\", line 179, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 145, in run\n",
      "    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 145, in run\n",
      "    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 437, in _evaluation_step\n",
      "    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 437, in _evaluation_step\n",
      "    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 329, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 329, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 412, in validation_step\n",
      "    return self.lightning_module.validation_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 412, in validation_step\n",
      "    return self.lightning_module.validation_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/training/lightning.py\", line 77, in validation_step\n",
      "    preds, target = self._shared_step(batch)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/python_projects/pioneerML/src/pioneerml/training/lightning.py\", line 77, in validation_step\n",
      "    preds, target = self._shared_step(batch)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/training/lightning.py\", line 109, in _shared_step\n",
      "    preds = self(batch)\n",
      "            ^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/python_projects/pioneerML/src/pioneerml/training/lightning.py\", line 109, in _shared_step\n",
      "    preds = self(batch)\n",
      "            ^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/training/lightning.py\", line 61, in forward\n",
      "    return self.model(batch)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/python_projects/pioneerML/src/pioneerml/training/lightning.py\", line 61, in forward\n",
      "    return self.model(batch)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/models/classifiers/group_classifier.py\", line 110, in forward\n",
      "    x = self.input_embed(data.x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/python_projects/pioneerML/src/pioneerml/models/classifiers/group_classifier.py\", line 110, in forward\n",
      "    x = self.input_embed(data.x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 134, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[run_hyperparameter_search]   File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 134, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (326x6 and 5x64)\n",
      "[run_hyperparameter_search] RuntimeError: mat1 and mat2 shapes cannot be multiplied (326x6 and 5x64)\n",
      "[W 2025-11-25 04:12:55,360] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mFailed to run step \u001b[0m\u001b[38;5;105mrun_hyperparameter_search\u001b[31m: mat1 and mat2 shapes cannot be multiplied (326x6 and 5x64)\u001b[0m\n",
      "\u001b[31mStep run_hyperparameter_search failed.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/local/local_orchestrator.py\", line 160, in submit_pipeline\n",
      "    self.run_step(step=step)\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/local/local_orchestrator.py\", line 160, in submit_pipeline\n",
      "    self.run_step(step=step)\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/base_orchestrator.py\", line 445, in run_step\n",
      "    launch_step(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/base_orchestrator.py\", line 445, in run_step\n",
      "    launch_step(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/execution/step/utils.py\", line 78, in launch_step\n",
      "    step_run = _launch_without_retry()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/execution/step/utils.py\", line 78, in launch_step\n",
      "    step_run = _launch_without_retry()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/execution/step/utils.py\", line 65, in _launch_without_retry\n",
      "    return launcher.launch()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/execution/step/utils.py\", line 65, in _launch_without_retry\n",
      "    return launcher.launch()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py\", line 360, in launch\n",
      "    self._run_step(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py\", line 360, in launch\n",
      "    self._run_step(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py\", line 487, in _run_step\n",
      "    self._run_step_in_current_thread(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py\", line 487, in _run_step\n",
      "    self._run_step_in_current_thread(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py\", line 642, in _run_step_in_current_thread\n",
      "    runner.run(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py\", line 642, in _run_step_in_current_thread\n",
      "    runner.run(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_runner.py\", line 229, in run\n",
      "    return_values = step_instance.call_entrypoint(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orchestrators/step_runner.py\", line 229, in run\n",
      "    return_values = step_instance.call_entrypoint(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/steps/base_step.py\", line 630, in call_entrypoint\n",
      "    return self.entrypoint(**validated_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/steps/base_step.py\", line 630, in call_entrypoint\n",
      "    return self.entrypoint(**validated_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_78200/663702664.py\", line 140, in run_hyperparameter_search\n",
      "    study.optimize(objective, n_trials=n_trials)\n",
      "  File \"/tmp/ipykernel_78200/663702664.py\", line 140, in run_hyperparameter_search\n",
      "    study.optimize(objective, n_trials=n_trials)\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/study.py\", line 490, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/study.py\", line 490, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 67, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 67, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 164, in _optimize_sequential\n",
      "    frozen_trial_id = _run_trial(study, func, catch)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 164, in _optimize_sequential\n",
      "    frozen_trial_id = _run_trial(study, func, catch)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 262, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 262, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_78200/663702664.py\", line 128, in objective\n",
      "    trainer.fit(lightning_module, datamodule=datamodule)\n",
      "  File \"/tmp/ipykernel_78200/663702664.py\", line 128, in objective\n",
      "    trainer.fit(lightning_module, datamodule=datamodule)\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 560, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 560, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 598, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 598, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1011, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1011, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1053, in _run_stage\n",
      "    self._run_sanity_check()\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1053, in _run_stage\n",
      "    self._run_sanity_check()\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1082, in _run_sanity_check\n",
      "    val_loop.run()\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1082, in _run_sanity_check\n",
      "    val_loop.run()\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py\", line 179, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py\", line 179, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 145, in run\n",
      "    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 145, in run\n",
      "    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 437, in _evaluation_step\n",
      "    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 437, in _evaluation_step\n",
      "    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 329, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 329, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 412, in validation_step\n",
      "    return self.lightning_module.validation_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 412, in validation_step\n",
      "    return self.lightning_module.validation_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/training/lightning.py\", line 77, in validation_step\n",
      "    preds, target = self._shared_step(batch)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/training/lightning.py\", line 77, in validation_step\n",
      "    preds, target = self._shared_step(batch)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/training/lightning.py\", line 109, in _shared_step\n",
      "    preds = self(batch)\n",
      "            ^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/training/lightning.py\", line 109, in _shared_step\n",
      "    preds = self(batch)\n",
      "            ^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/training/lightning.py\", line 61, in forward\n",
      "    return self.model(batch)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/training/lightning.py\", line 61, in forward\n",
      "    return self.model(batch)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/models/classifiers/group_classifier.py\", line 110, in forward\n",
      "    x = self.input_embed(data.x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/python_projects/pioneerML/src/pioneerml/models/classifiers/group_classifier.py\", line 110, in forward\n",
      "    x = self.input_embed(data.x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 134, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 134, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (326x6 and 5x64)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (326x6 and 5x64)\n",
      "\u001b[33mSkipping step train_best_model due to failure in upstream step(s): run_hyperparameter_search (Execution mode continue_on_failure)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> in &lt;module&gt;:1                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2771 </span> 1 run = <span style=\"font-weight: bold; text-decoration: underline\">tuning_pipeline.with_options(enable_cache=</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">False</span><span style=\"font-weight: bold; text-decoration: underline\">)(n_trials=</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">4</span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Pipeline run status: {</span>run.status<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>tuned_module = load_step_output(run, <span style=\"color: #808000; text-decoration-color: #808000\">\"train_best_model\"</span>)                                    <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/pip</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">elines/</span><span style=\"font-weight: bold\">pipeline_definition.py</span>:1627 in __call__                                                   <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1624 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.entrypoint(*args, **kwargs)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[no-any-return]</span>        <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1625 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1626 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prepare(*args, **kwargs)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2771 </span>1627 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">._run()</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1628 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1629 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_entrypoint</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args: Any, **kwargs: Any) -&gt; Any:                         <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1630 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">\u2502   \u2502   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Calls the pipeline entrypoint function with the given arguments.</span>               <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/pip</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">elines/</span><span style=\"font-weight: bold\">pipeline_definition.py</span>:1102 in _run                                                       <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1099 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"`zenml login --local`.\"</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1100 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1101 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2771 </span>1102 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   </span><span style=\"font-weight: bold; text-decoration: underline\">submit_pipeline(</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1103 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span style=\"font-weight: bold; text-decoration: underline\">snapshot=snapshot, stack=stack, placeholder_run=run</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1104 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   </span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1105 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/exe</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cution/pipeline/</span><span style=\"font-weight: bold\">utils.py</span>:115 in submit_pipeline                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># the run as failed if it's still in an unfinished state.</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   </span>publish_failed_pipeline_run(placeholder_run.id)                            <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2771 </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">raise</span><span style=\"font-weight: bold; text-decoration: underline\"> e</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/exe</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cution/pipeline/</span><span style=\"font-weight: bold\">utils.py</span>:96 in submit_pipeline                                                   <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 93 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> prevent_pipeline_execution():                                                     <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 94 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 95 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   </span>stack.prepare_pipeline_submission(snapshot=snapshot)                           <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2771 </span> 96 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   </span>stack.submit_pipeline(                                                         <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 97 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   </span>snapshot=snapshot,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   </span>placeholder_run=placeholder_run,                                           <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/sta</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ck/</span><span style=\"font-weight: bold\">stack.py</span>:880 in submit_pipeline                                                               <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 877 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">\u2502   \u2502   \u2502   </span><span style=\"color: #808000; text-decoration-color: #808000\">snapshot: The pipeline snapshot.</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 878 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">\u2502   \u2502   \u2502   </span><span style=\"color: #808000; text-decoration-color: #808000\">placeholder_run: An optional placeholder run for the snapshot.</span>                <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 879 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">\u2502   \u2502   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2771 </span> 880 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">.orchestrator.run(</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 881 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   </span><span style=\"font-weight: bold; text-decoration: underline\">snapshot=snapshot, stack=</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">, placeholder_run=placeholder_run</span>                <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 882 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   </span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 883 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orc</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">hestrators/</span><span style=\"font-weight: bold\">base_orchestrator.py</span>:369 in run                                                       <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">366 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>combined_environment.update(step_environment)                      <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">367 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>step_environments[invocation_id] = combined_environment            <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">368 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2771 </span>369 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>submission_result = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.submit_pipeline(                              <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">370 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>snapshot=snapshot,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">371 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>stack=stack,                                                       <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">372 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>base_environment=base_environment,                                 <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orc</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">hestrators/local/</span><span style=\"font-weight: bold\">local_orchestrator.py</span>:176 in submit_pipeline                                    <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> step_exception                                                           <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> failed_steps:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span> <span style=\"color: #800000; text-decoration-color: #800000\">\u2771 </span>176 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">raise</span><span style=\"font-weight: bold; text-decoration: underline\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">RuntimeError</span><span style=\"font-weight: bold; text-decoration: underline\">(</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"Pipeline run has failed due to failure in step(s): \"</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   \u2502   </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">f\"{', '</span><span style=\"font-weight: bold; text-decoration: underline\">.join(failed_steps)</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">}\"</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\u2502   \u2502   \u2502   </span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">\u2502</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Pipeline run has failed due to failure in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">step</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span>: run_hyperparameter_search\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u256d\u2500\u001b[0m\u001b[31m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[31m\u2500\u256e\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m in <module>:1                                                                                    \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[31m\u2771 \u001b[0m 1 run = \u001b[1;4mtuning_pipeline.with_options(enable_cache=\u001b[0m\u001b[1;4;94mFalse\u001b[0m\u001b[1;4m)(n_trials=\u001b[0m\u001b[1;4;94m4\u001b[0m\u001b[1;4m)\u001b[0m                          \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mPipeline run status: \u001b[0m\u001b[33m{\u001b[0mrun.status\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                                                 \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 3 \u001b[0m                                                                                            \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 4 \u001b[0mtuned_module = load_step_output(run, \u001b[33m\"\u001b[0m\u001b[33mtrain_best_model\u001b[0m\u001b[33m\"\u001b[0m)                                    \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2m/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/pip\u001b[0m \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2melines/\u001b[0m\u001b[1mpipeline_definition.py\u001b[0m:1627 in __call__                                                   \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m1624 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.entrypoint(*args, **kwargs)  \u001b[2m# type: ignore[no-any-return]\u001b[0m        \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m1625 \u001b[0m\u001b[2m\u2502   \u2502   \u001b[0m                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m1626 \u001b[0m\u001b[2m\u2502   \u2502   \u001b[0m\u001b[96mself\u001b[0m.prepare(*args, **kwargs)                                                     \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[31m\u2771 \u001b[0m1627 \u001b[2m\u2502   \u2502   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4;96mself\u001b[0m\u001b[1;4m._run()\u001b[0m                                                                \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m1628 \u001b[0m\u001b[2m\u2502   \u001b[0m                                                                                      \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m1629 \u001b[0m\u001b[2m\u2502   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m_call_entrypoint\u001b[0m(\u001b[96mself\u001b[0m, *args: Any, **kwargs: Any) -> Any:                         \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m1630 \u001b[0m\u001b[2;90m\u2502   \u2502   \u001b[0m\u001b[33m\"\"\"Calls the pipeline entrypoint function with the given arguments.\u001b[0m               \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2m/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/pip\u001b[0m \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2melines/\u001b[0m\u001b[1mpipeline_definition.py\u001b[0m:1102 in _run                                                       \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m1099 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m`zenml login --local`.\u001b[0m\u001b[33m\"\u001b[0m                                      \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m1100 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u001b[0m)                                                                 \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m1101 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u001b[0m                                                                          \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[31m\u2771 \u001b[0m1102 \u001b[2m\u2502   \u2502   \u2502   \u2502   \u001b[0m\u001b[1;4msubmit_pipeline(\u001b[0m                                                          \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m1103 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u2502   \u001b[0m\u001b[1;4msnapshot=snapshot, stack=stack, placeholder_run=run\u001b[0m                   \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m1104 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u001b[0m\u001b[1;4m)\u001b[0m                                                                         \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m1105 \u001b[0m                                                                                          \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2m/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/exe\u001b[0m \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2mcution/pipeline/\u001b[0m\u001b[1mutils.py\u001b[0m:115 in submit_pipeline                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u001b[0m\u001b[2m# the run as failed if it's still in an unfinished state.\u001b[0m                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u001b[0mpublish_failed_pipeline_run(placeholder_run.id)                            \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u001b[0m                                                                               \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[31m\u2771 \u001b[0m115 \u001b[2m\u2502   \u2502   \u2502   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m e\u001b[0m                                                                        \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m116 \u001b[0m                                                                                           \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2m/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/exe\u001b[0m \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2mcution/pipeline/\u001b[0m\u001b[1mutils.py\u001b[0m:96 in submit_pipeline                                                   \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2m\u2502   \u001b[0m\u001b[94mwith\u001b[0m prevent_pipeline_execution():                                                     \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m\u2502   \u2502   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u001b[0mstack.prepare_pipeline_submission(snapshot=snapshot)                           \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[31m\u2771 \u001b[0m 96 \u001b[2m\u2502   \u2502   \u2502   \u001b[0mstack.submit_pipeline(                                                         \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 97 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u001b[0msnapshot=snapshot,                                                         \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u001b[0mplaceholder_run=placeholder_run,                                           \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u001b[0m)                                                                              \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2m/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/sta\u001b[0m \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2mck/\u001b[0m\u001b[1mstack.py\u001b[0m:880 in submit_pipeline                                                               \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 877 \u001b[0m\u001b[2;33m\u2502   \u2502   \u2502   \u001b[0m\u001b[33msnapshot: The pipeline snapshot.\u001b[0m                                              \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 878 \u001b[0m\u001b[2;33m\u2502   \u2502   \u2502   \u001b[0m\u001b[33mplaceholder_run: An optional placeholder run for the snapshot.\u001b[0m                \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 879 \u001b[0m\u001b[2;33m\u2502   \u2502   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[31m\u2771 \u001b[0m 880 \u001b[2m\u2502   \u2502   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.orchestrator.run(\u001b[0m                                                            \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 881 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u001b[0m\u001b[1;4msnapshot=snapshot, stack=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m, placeholder_run=placeholder_run\u001b[0m                \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 882 \u001b[0m\u001b[2m\u2502   \u2502   \u001b[0m\u001b[1;4m)\u001b[0m                                                                                 \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m 883 \u001b[0m                                                                                          \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2m/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orc\u001b[0m \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2mhestrators/\u001b[0m\u001b[1mbase_orchestrator.py\u001b[0m:369 in run                                                       \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m366 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u001b[0mcombined_environment.update(step_environment)                      \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u001b[0mstep_environments[invocation_id] = combined_environment            \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u2502   \u001b[0m                                                                       \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[31m\u2771 \u001b[0m369 \u001b[2m\u2502   \u2502   \u2502   \u2502   \u2502   \u001b[0msubmission_result = \u001b[96mself\u001b[0m.submit_pipeline(                              \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m370 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u001b[0msnapshot=snapshot,                                                 \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m371 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u001b[0mstack=stack,                                                       \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m372 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u001b[0mbase_environment=base_environment,                                 \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2m/home/jack/virtual_environments/miniconda3/envs/pioneerml/lib/python3.11/site-packages/zenml/orc\u001b[0m \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[2mhestrators/local/\u001b[0m\u001b[1mlocal_orchestrator.py\u001b[0m:176 in submit_pipeline                                    \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m                                                                                                  \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u001b[0m\u001b[94mraise\u001b[0m step_exception                                                           \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m\u2502   \u2502   \u001b[0m                                                                                   \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m\u2502   \u2502   \u001b[0m\u001b[94mif\u001b[0m failed_steps:                                                                   \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m \u001b[31m\u2771 \u001b[0m176 \u001b[2m\u2502   \u2502   \u2502   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;96mRuntimeError\u001b[0m\u001b[1;4m(\u001b[0m                                                            \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mPipeline run has failed due to failure in step(s): \u001b[0m\u001b[1;4;33m\"\u001b[0m                      \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u2502   \u001b[0m\u001b[1;4;33mf\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33m{\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m, \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4m.join(failed_steps)\u001b[0m\u001b[1;4;33m}\u001b[0m\u001b[1;4;33m\"\u001b[0m                                               \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2502\u001b[0m   \u001b[2m179 \u001b[0m\u001b[2m\u2502   \u2502   \u2502   \u001b[0m\u001b[1;4m)\u001b[0m                                                                              \u001b[31m\u2502\u001b[0m\n",
       "\u001b[31m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mPipeline run has failed due to failure in \u001b[1;35mstep\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m: run_hyperparameter_search\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = tuning_pipeline.with_options(enable_cache=False)(n_trials=4)\n",
    "print(f\"Pipeline run status: {run.status}\")\n",
    "\n",
    "tuned_module = load_step_output(run, \"train_best_model\")\n",
    "datamodule = load_step_output(run, \"create_datamodule\")\n",
    "best_params = load_step_output(run, \"run_hyperparameter_search\")\n",
    "\n",
    "if tuned_module is None or datamodule is None or best_params is None:\n",
    "    raise RuntimeError(\"Failed to load artifacts from the tuning pipeline.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tuned_module = tuned_module.to(device).eval()\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"- {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect",
   "metadata": {},
   "source": [
    "## Inspect the Tuned Model\n",
    "\n",
    "Check that the tuned model has the expected shape, parameter count, and device placement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inspect-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = next(tuned_module.parameters()).device\n",
    "param_count = sum(p.numel() for p in tuned_module.parameters())\n",
    "\n",
    "train_loader = datamodule.train_dataloader()\n",
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "print(\"Tuned Model Summary:\")\n",
    "print(f\"- Run: {run.name}\")\n",
    "print(f\"- Device: {device}\")\n",
    "print(f\"- Parameters: {param_count:,}\")\n",
    "print(f\"- Nodes per batch: {first_batch.x.shape[0]} | Features: {first_batch.x.shape[1]}\")\n",
    "print(f\"- Edges: {first_batch.edge_index.shape[1]}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = tuned_module(first_batch.to(device))\n",
    "    print(f\"- Output logits shape: {tuple(logits.shape)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accuracy-intro",
   "metadata": {},
   "source": [
    "## Evaluate Validation Accuracy\n",
    "\n",
    "Run the tuned model on the validation split. We handle label shapes explicitly because\n",
    "PyG batches graph-level labels into `(batch_size, num_classes)` tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accuracy-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = datamodule.val_dataloader()\n",
    "if isinstance(val_loader, list) and len(val_loader) == 0:\n",
    "    val_loader = datamodule.train_dataloader()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "tuned_module.eval()\n",
    "\n",
    "for batch in val_loader:\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = tuned_module(batch)\n",
    "\n",
    "    labels = batch.y\n",
    "    if labels.dim() == 1:\n",
    "        if labels.shape[0] % 3 == 0:\n",
    "            labels = labels.view(-1, 3)\n",
    "        else:\n",
    "            labels = labels.unsqueeze(0)\n",
    "    labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    correct += int((preds == labels).sum().item())\n",
    "    total += int(labels.numel())\n",
    "\n",
    "accuracy = correct / total if total > 0 else 0.0\n",
    "print(f\"Validation accuracy: {accuracy:.1%} ({correct}/{total})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pioneerml)",
   "language": "python",
   "name": "pioneerml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}