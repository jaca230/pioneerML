{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Tutorial 2: Custom Models and Training\n",
    "\n",
    "This tutorial demonstrates how to define a custom Graph Convolutional Network (GCN)\n",
    "and integrate it into a ZenML pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ZenML repository root: /workspace\n",
      "Ensure this is the top-level of your repo (.zen must live here).\n",
      "ZenML initialized with stack: default\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from zenml import pipeline, step\n",
    "\n",
    "from pioneerml.common.models.base import GraphModel\n",
    "from pioneerml.common.pipeline.services.training.utils import GraphLightningModule\n",
    "from pioneerml.pipelines.tutorial_examples.graph_datamodule import GraphDataModule\n",
    "from pioneerml.common.zenml.materializers import (\n",
    "    PyGDataListMaterializer,\n",
    ")\n",
    "from pioneerml.common.zenml import load_step_output\n",
    "from pioneerml.common.zenml import utils as zenml_utils\n",
    "from pioneerml.common.zenml.utils import detect_available_accelerator\n",
    "\n",
    "# Initialize ZenML for notebook use\n",
    "# setup_zenml_for_notebook automatically finds the project root by searching\n",
    "# upward for .zen or .zenml directories, ensuring we use the root configuration.\n",
    "# use_in_memory=True creates a temporary in-memory SQLite store, perfect for\n",
    "# tutorials where we don't need persistent artifact storage.\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(use_in_memory=True)\n",
    "print(f\"ZenML initialized with stack: {zenml_client.active_stack_model.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_explanation",
   "metadata": {},
   "source": [
    "## Define a Custom Graph Convolutional Network\n",
    "\n",
    "We'll create a simple but effective GCN model for graph classification. The architecture\n",
    "consists of:\n",
    "\n",
    "1. **Two GCN layers**: Each layer aggregates information from neighboring nodes\n",
    "   - First layer: Projects 5D node features â†’ hidden dimension (64)\n",
    "   - Second layer: Further refines node representations within the hidden space\n",
    "\n",
    "2. **Global mean pooling**: Aggregates all node features into a single graph-level\n",
    "   representation by taking the mean across all nodes\n",
    "\n",
    "3. **Classifier head**: A linear layer that maps the graph representation to class\n",
    "   logits (3 classes: Ï€, Î¼, e+)\n",
    "\n",
    "**Why this architecture?** GCNs are excellent for learning from graph-structured data\n",
    "because they respect the graph topology - nodes learn representations based on their\n",
    "neighbors. Global pooling allows us to make graph-level predictions from node features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "custom_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom GCN model created: 4,739 parameters\n"
     ]
    }
   ],
   "source": [
    "class SimpleGCN(GraphModel):\n",
    "    \"\"\"A simple custom Graph Convolutional Network for graph classification.\n",
    "    \n",
    "    This model demonstrates the core components of a GCN:\n",
    "    - Graph convolution layers that aggregate neighbor information\n",
    "    - Global pooling to create graph-level representations\n",
    "    - A classifier head for final predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes: int = 3, hidden_dim: int = 64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First GCN layer: projects 5D node features to hidden dimension\n",
    "        # GCNConv learns to aggregate information from each node's neighbors\n",
    "        self.conv1 = GCNConv(5, hidden_dim)\n",
    "        \n",
    "        # Second GCN layer: refines node representations within hidden space\n",
    "        # This allows the model to learn more complex patterns in the graph structure\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Classifier head: maps graph-level representation to class logits\n",
    "        # Output size matches number of classes (3 for Ï€, Î¼, e+)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Forward pass through the GCN.\n",
    "        \n",
    "        Args:\n",
    "            batch: PyTorch Geometric Batch object containing:\n",
    "                - x: Node features [num_nodes, 5]\n",
    "                - edge_index: Edge connectivity [2, num_edges]\n",
    "                - batch: Batch assignment vector [num_nodes]\n",
    "        \n",
    "        Returns:\n",
    "            Logits for each graph in the batch [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        # Extract graph components from the batch\n",
    "        x, edge_index, batch_indices = batch.x, batch.edge_index, batch.batch\n",
    "\n",
    "        # First graph convolution: aggregate neighbor features\n",
    "        # ReLU activation introduces non-linearity\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        \n",
    "        # Second graph convolution: further refine node representations\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "\n",
    "        # Global mean pooling: aggregate all node features into a single vector\n",
    "        # This creates one representation per graph in the batch\n",
    "        # Shape: [batch_size, hidden_dim]\n",
    "        x = global_mean_pool(x, batch_indices)\n",
    "\n",
    "        # Final classification: map graph representation to class logits\n",
    "        # Shape: [batch_size, num_classes]\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "    def export_torchscript(self, path=None, *, strict: bool = False):\n",
    "        \"\"\"Export a TorchScript module for this model.\"\"\"\n",
    "        scripted = torch.jit.script(self.eval().cpu())\n",
    "        if path is not None:\n",
    "            scripted.save(str(path))\n",
    "        return scripted\n",
    "\n",
    "\n",
    "# Verify the model can be instantiated\n",
    "model = SimpleGCN(num_classes=3, hidden_dim=64)\n",
    "print(f\"Custom GCN model created: {model.num_parameters:,} parameters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline_explanation",
   "metadata": {},
   "source": [
    "## Build the Training Pipeline\n",
    "\n",
    "Now we'll create a complete ZenML pipeline that uses our custom GCN model. The pipeline\n",
    "follows the same structure as Tutorial 1:\n",
    "\n",
    "1. **`create_data`**: Generates synthetic graph data with class labels\n",
    "2. **`create_datamodule`**: Splits data into train/validation sets\n",
    "3. **`create_model`**: Instantiates our custom SimpleGCN\n",
    "4. **`create_lightning_module`**: Wraps the model in PyTorch Lightning\n",
    "5. **`train_model`**: Executes the training loop\n",
    "\n",
    "**Key difference from Tutorial 1**: Here we use our custom `SimpleGCN` instead of the\n",
    "pre-built `GroupClassifier`. Everything else works exactly the same - this demonstrates\n",
    "the flexibility of the ZenML + GraphModel architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pipeline_definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_synthetic_data(num_samples: int = 150) -> list[Data]:\n",
    "    \"\"\"\n",
    "    Generate synthetic graph data with learnable structure.\n",
    "    \n",
    "    Each class has:\n",
    "      - different mean patterns in feature space\n",
    "      - slightly different edge density\n",
    "      - noise added so the classifier must generalize\n",
    "    \"\"\"\n",
    "    # Define distinct class centers for the 5D node features\n",
    "    class_centers = torch.tensor([\n",
    "        [ 1.0, -1.0,  0.5,  0.0,  2.0],   # Class 0 (Ï€)\n",
    "        [-1.0,  0.5,  1.5,  1.0, -1.0],   # Class 1 (Î¼)\n",
    "        [ 0.0,  1.0, -1.0, -0.5,  1.5],   # Class 2 (e+)\n",
    "    ])\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        num_nodes = torch.randint(4, 9, (1,)).item()\n",
    "\n",
    "        # Choose class label\n",
    "        label = torch.randint(0, 3, (1,)).item()\n",
    "        y = torch.zeros(3)\n",
    "        y[label] = 1.0\n",
    "\n",
    "        # Create node features centered around class-specific mean\n",
    "        # Add moderate noise so the model must learn to separate distributions\n",
    "        center = class_centers[label]\n",
    "        x = center + 0.3 * torch.randn(num_nodes, 5)\n",
    "\n",
    "        # Class-dependent graph density (optional structure signal)\n",
    "        edge_factor = {0: 1.0, 1: 1.3, 2: 0.7}[label]\n",
    "        num_edges = int(num_nodes * edge_factor * 2)\n",
    "\n",
    "        edge_index = torch.randint(0, num_nodes, (2, num_edges))\n",
    "        edge_attr = torch.randn(num_edges, 4)\n",
    "\n",
    "        data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "@step(output_materializers=PyGDataListMaterializer, enable_cache=False)\n",
    "def create_data() -> list[Data]:\n",
    "    \"\"\"Step 1: Generate synthetic graph data.\n",
    "    \n",
    "    The PyGDataListMaterializer ensures efficient serialization of PyTorch Geometric\n",
    "    Data objects, avoiding pickle warnings.\n",
    "    \"\"\"\n",
    "    return create_simple_synthetic_data()\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def create_datamodule(data: list[Data]) -> GraphDataModule:\n",
    "    \"\"\"Step 2: Create data module with train/val split.\n",
    "    \n",
    "    - val_split=0.3: 70% train, 30% validation\n",
    "    - batch_size=16: smaller batches for the custom model\n",
    "    \"\"\"\n",
    "    return GraphDataModule(dataset=data, val_split=0.3, batch_size=16, num_workers=0)\n",
    "\n",
    "\n",
    "@step\n",
    "def create_model(num_classes: int = 3, hidden_dim: int = 64) -> SimpleGCN:\n",
    "    \"\"\"Step 3: Instantiate our custom GCN model.\n",
    "    \n",
    "    This step creates the SimpleGCN we defined above with the specified\n",
    "    number of classes and hidden dimension.\n",
    "    \"\"\"\n",
    "    return SimpleGCN(num_classes=num_classes, hidden_dim=hidden_dim)\n",
    "\n",
    "\n",
    "@step\n",
    "def create_lightning_module(model: SimpleGCN) -> GraphLightningModule:\n",
    "    \"\"\"Step 4: Wrap model in PyTorch Lightning module.\n",
    "    \n",
    "    Adds training logic, loss function (BCE for multilabel classification),\n",
    "    and optimizer configuration.\n",
    "    \"\"\"\n",
    "    return GraphLightningModule(model, task=\"classification\", lr=5e-4)\n",
    "\n",
    "\n",
    "@step\n",
    "def train_model(\n",
    "    lightning_module: GraphLightningModule,\n",
    "    datamodule: GraphDataModule\n",
    ") -> GraphLightningModule:\n",
    "    \"\"\"Step 5: Execute training loop.\n",
    "    \n",
    "    Automatically detects available hardware (CPU/GPU) and runs for 5 epochs.\n",
    "    Returns the trained module in eval mode.\n",
    "    \"\"\"\n",
    "    import pytorch_lightning as pl\n",
    "\n",
    "    accelerator, devices = detect_available_accelerator()\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        max_epochs=5,\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    trainer.fit(lightning_module, datamodule=datamodule)\n",
    "    return lightning_module.eval()\n",
    "\n",
    "\n",
    "@pipeline\n",
    "def custom_model_pipeline():\n",
    "    \"\"\"Compose all steps into a complete training pipeline.\n",
    "    \n",
    "    ZenML automatically wires the outputs of one step to the inputs of the next\n",
    "    based on parameter names. For example, `create_datamodule(data)` receives\n",
    "    the output from `create_data()`.\n",
    "    \"\"\"\n",
    "    data = create_data()\n",
    "    datamodule = create_datamodule(data)\n",
    "    model = create_model()\n",
    "    lightning_module = create_lightning_module(model)\n",
    "    trained_module = train_model(lightning_module, datamodule)\n",
    "    return trained_module, datamodule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_pipeline",
   "metadata": {},
   "source": [
    "## Run the Pipeline\n",
    "\n",
    "Execute the pipeline and load the trained model. After the pipeline completes, we load\n",
    "the trained model and datamodule using `load_step_output`. These artifacts are stored\n",
    "by ZenML and can be reloaded anytime without re-running the pipeline.\n",
    "\n",
    "**Why use `enable_cache=False`?** This ensures the pipeline runs fresh each time,\n",
    "which is useful for tutorials. In production, you'd typically enable caching to\n",
    "skip re-running unchanged steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "run",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mInitiating a new run for the pipeline: \u001b[0m\u001b[38;5;105mcustom_model_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mCaching is disabled by default for \u001b[0m\u001b[38;5;105mcustom_model_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mUsing user: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mUsing stack: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  deployer: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  artifact_store: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  orchestrator: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mYou can visualize your pipeline runs in the \u001b[0m\u001b[38;5;105mZenML Dashboard\u001b[37m. In order to try it locally, please run \u001b[0m\u001b[38;5;105mzenml login --local\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_data\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_data\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.471s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_model\u001b[37m has started.\u001b[0m\n",
      "\u001b[33m[create_model] No materializer is registered for type \u001b[0m\u001b[38;5;105m<class '__main__.SimpleGCN'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[38;5;105m<class '__main__.SimpleGCN'>\u001b[33m according to the instructions at \u001b[0m\u001b[34mhttps://docs.zenml.io/concepts/artifacts/materializers\u001b[33m\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.080s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_datamodule\u001b[37m has started.\u001b[0m\n",
      "\u001b[33m[create_datamodule] No materializer is registered for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.pipelines.tutorial_examples.graph_datamodule.GraphDataModule'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.pipelines.tutorial_examples.graph_datamodule.GraphDataModule'>\u001b[33m according to the instructions at \u001b[0m\u001b[34mhttps://docs.zenml.io/concepts/artifacts/materializers\u001b[33m\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_datamodule\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.127s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_lightning_module\u001b[37m has started.\u001b[0m\n",
      "\u001b[33m[create_lightning_module] No materializer is registered for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.common.pipeline.services.training.utils.graph_lightning_module.GraphLightningModule'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.common.pipeline.services.training.utils.graph_lightning_module.GraphLightningModule'>\u001b[33m according to the instructions at \u001b[0m\u001b[34mhttps://docs.zenml.io/concepts/artifacts/materializers\u001b[33m\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_lightning_module\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.089s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_model\u001b[37m has started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 5070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ model   â”‚ SimpleGCN         â”‚  4.7 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ loss_fn â”‚ BCEWithLogitsLoss â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ model   â”‚ SimpleGCN         â”‚  4.7 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ loss_fn â”‚ BCEWithLogitsLoss â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.7 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.7 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 9                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.7 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.7 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 9                                                                                           \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[train_model] /opt/conda/envs/pioneerml/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \u001b[0m\u001b[38;5;105mnum_workers\u001b[33m argument\u001b[0m\u001b[38;5;105m to \u001b[33mnum_workers=11\u001b[0m\u001b[38;5;105m in the \u001b[33mDataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "\u001b[33m[train_model] /opt/conda/envs/pioneerml/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \u001b[0m\u001b[38;5;105mnum_workers\u001b[33m argument\u001b[0m\u001b[38;5;105m to \u001b[33mnum_workers=11\u001b[0m\u001b[38;5;105m in the \u001b[33mDataLoader` to improve performance.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[train_model] No materializer is registered for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.common.pipeline.services.training.utils.graph_lightning_module.GraphLightningModule'>\u001b[33m, so the default Pickle materializer was used. Pickle is not production ready and should only be used for prototyping as the artifacts cannot be loaded when running with a different Python version. Please consider implementing a custom materializer for type \u001b[0m\u001b[38;5;105m<class 'pioneerml.common.pipeline.services.training.utils.graph_lightning_module.GraphLightningModule'>\u001b[33m according to the instructions at \u001b[0m\u001b[34mhttps://docs.zenml.io/concepts/artifacts/materializers\u001b[33m\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m2.320s\u001b[37m.\u001b[0m\n",
      "\u001b[37mPipeline run has finished in \u001b[0m\u001b[38;5;105m5.167s\u001b[37m.\u001b[0m\n",
      "Pipeline run status: completed\n",
      "Loaded artifacts from run custom_model_pipeline-2026_02_19-19_11_24_478206 (device=cuda)\n"
     ]
    }
   ],
   "source": [
    "run = custom_model_pipeline.with_options(enable_cache=False)()\n",
    "print(f\"Pipeline run status: {run.status}\")\n",
    "\n",
    "# Load artifacts from the run\n",
    "trained_module = load_step_output(run, \"train_model\")\n",
    "datamodule = load_step_output(run, \"create_datamodule\")\n",
    "custom_model = load_step_output(run, \"create_model\")\n",
    "\n",
    "if trained_module is None or datamodule is None or custom_model is None:\n",
    "    raise RuntimeError(\"Could not load artifacts from the custom_model_pipeline run.\")\n",
    "\n",
    "# Move model to best available device\n",
    "# Note: Models saved by ZenML may be on CPU. We move to GPU if available\n",
    "# to match the training device and speed up inference.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trained_module = trained_module.to(device).eval()\n",
    "datamodule.setup(stage=\"fit\")\n",
    "print(f\"Loaded artifacts from run {run.name} (device={device})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect_model",
   "metadata": {},
   "source": [
    "## Inspect the Custom Model\n",
    "\n",
    "Let's examine the trained model to understand its structure and verify it trained\n",
    "correctly. We'll check:\n",
    "\n",
    "- **Parameter count**: How many trainable parameters does our custom GCN have?\n",
    "- **Input/output shapes**: What dimensions does the model expect and produce?\n",
    "- **Device placement**: Where is the model running (CPU/GPU)?\n",
    "\n",
    "This helps validate that the model architecture is correct and that training completed\n",
    "successfully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom GCN Model Summary:\n",
      "- Run: custom_model_pipeline-2026_02_19-19_11_24_478206\n",
      "- Device: cuda:0\n",
      "- Total parameters: 4,739\n",
      "- Input node features: 5D (shape: (104, 5))\n",
      "- Number of nodes in batch: 104\n",
      "- Number of edges: 191\n",
      "- Output logits shape: (16, 3) (batch_size, num_classes)\n"
     ]
    }
   ],
   "source": [
    "device = next(trained_module.parameters()).device\n",
    "param_count = sum(p.numel() for p in trained_module.parameters())\n",
    "\n",
    "# Get a sample batch to inspect input shapes\n",
    "train_loader = datamodule.train_dataloader()\n",
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "print(\"Custom GCN Model Summary:\")\n",
    "print(f\"- Run: {run.name}\")\n",
    "print(f\"- Device: {device}\")\n",
    "print(f\"- Total parameters: {param_count:,}\")\n",
    "print(f\"- Input node features: {first_batch.x.shape[1]}D (shape: {tuple(first_batch.x.shape)})\")\n",
    "print(f\"- Number of nodes in batch: {first_batch.x.shape[0]}\")\n",
    "print(f\"- Number of edges: {first_batch.edge_index.shape[1]}\")\n",
    "\n",
    "# Test forward pass to verify output shape\n",
    "with torch.no_grad():\n",
    "    output = trained_module(first_batch.to(device))\n",
    "    print(f\"- Output logits shape: {tuple(output.shape)} (batch_size, num_classes)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "\n",
    "Finally, let's compute validation accuracy to confirm the custom model trained\n",
    "successfully. We'll run inference on the validation set and compare predictions\n",
    "to ground truth labels.\n",
    "\n",
    "**What we're measuring**: Classification accuracy - the percentage of graphs\n",
    "correctly classified into their true class (Ï€, Î¼, or e+).\n",
    "\n",
    "**Note on device placement**: The model was trained on GPU (as shown in the pipeline\n",
    "output), but when loaded from ZenML artifacts, it may be on CPU. We explicitly move\n",
    "it to the best available device (GPU if available) to match training conditions and\n",
    "speed up inference. This is why you see the device change from CPU to GPU (or vice versa)\n",
    "depending on your hardware.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 93.3% (42/45 correct)\n"
     ]
    }
   ],
   "source": [
    "# Get validation loader (fallback to train if val is empty)\n",
    "val_loader = datamodule.val_dataloader()\n",
    "if isinstance(val_loader, list) and len(val_loader) == 0:\n",
    "    val_loader = datamodule.train_dataloader()\n",
    "\n",
    "# Compute accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "trained_module.eval()\n",
    "\n",
    "for batch in val_loader:\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = trained_module(batch)\n",
    "    \n",
    "    # Handle labels: PyTorch Geometric batches graph-level labels\n",
    "    # Each graph has y of shape (num_classes,), batched into (batch_size, num_classes)\n",
    "    labels = batch.y\n",
    "    \n",
    "    # Ensure labels are 2D: (batch_size, num_classes)\n",
    "    if labels.dim() == 1:\n",
    "        # If flattened, reshape assuming num_classes=3\n",
    "        if labels.shape[0] % 3 == 0:\n",
    "            labels = labels.view(-1, 3)\n",
    "        else:\n",
    "            # Single graph case: add batch dimension\n",
    "            labels = labels.unsqueeze(0)\n",
    "    \n",
    "    # Convert one-hot encoded labels to class indices\n",
    "    # Shape: (batch_size, num_classes) -> (batch_size,)\n",
    "    labels = torch.argmax(labels, dim=1)\n",
    "    \n",
    "    # Get predicted class (highest logit)\n",
    "    # Shape: (batch_size, num_classes) -> (batch_size,)\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    # Count correct predictions (both should be shape (batch_size,))\n",
    "    correct += int((preds == labels).sum().item())\n",
    "    total += int(labels.numel())\n",
    "\n",
    "accuracy = correct / total if total > 0 else 0.0\n",
    "print(f\"Validation accuracy: {accuracy:.1%} ({correct}/{total} correct)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pioneerml)",
   "language": "python",
   "name": "pioneerml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
