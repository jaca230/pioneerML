{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c4d929",
   "metadata": {},
   "source": [
    "# Tutorial 0: ZenML Quickstart\n",
    "\n",
    "Run the smallest end-to-end ZenML pipeline in this repository, load the\n",
    "trained model and data module from the ZenML artifacts, and generate a few\n",
    "quick diagnostic plots.\n",
    "\n",
    "What you'll see (with detailed interpretation guidance):\n",
    "- How to spin up ZenML in in-memory mode (no server, minimal local state).\n",
    "- A minimal training run on synthetic data using our `GroupClassifier`.\n",
    "- How to pull artifacts back out of ZenML and compute plots.\n",
    "- How to interpret each plot (axes, computation, and what “good” looks like).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5fa33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from pioneerml.evaluation.plots import (\n",
    "    plot_multilabel_confusion_matrix,\n",
    "    plot_precision_recall_curves,\n",
    "    plot_roc_curves,\n",
    ")\n",
    "from pioneerml.training import plot_loss_curves\n",
    "from pioneerml.zenml import load_step_output\n",
    "from pioneerml.zenml import utils as zenml_utils\n",
    "from pioneerml.zenml.pipelines import zenml_training_pipeline\n",
    "\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    \"\"\"Walk upward to locate the repo root (pyproject or .git).\"\"\"\n",
    "    start = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd().resolve()\n",
    "    for path in [start] + list(start.parents):\n",
    "        if (path / \"pyproject.toml\").exists() or (path / \".git\").exists():\n",
    "            return path\n",
    "    return start\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(root_path=PROJECT_ROOT, use_in_memory=True)\n",
    "print(f\"ZenML initialized with stack: {zenml_client.active_stack_model.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcfe6bc",
   "metadata": {},
   "source": [
    "## Run the quickstart pipeline\n",
    "Execute the ZenML pipeline and load the trained Lightning module plus the\n",
    "synthetic data module from the run artifacts. ZenML stores step outputs as\n",
    "artifacts; `load_step_output` pulls them back so we can keep working in pure\n",
    "Python without re-running training.\n",
    "\n",
    "Why this matters:\n",
    "- Running once, reloading many times keeps notebooks fast.\n",
    "- You can switch between CPU/GPU here; the stored artifact is device-agnostic\n",
    "  and will load onto whatever is available now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = zenml_training_pipeline.with_options(enable_cache=False)()\n",
    "print(f\"Pipeline run status: {run.status}\")\n",
    "\n",
    "trained_module = load_step_output(run, \"train_module\")\n",
    "datamodule = load_step_output(run, \"build_datamodule\")\n",
    "\n",
    "if trained_module is None or datamodule is None:\n",
    "    raise RuntimeError(\"Could not load artifacts from the zenml_training_pipeline run.\")\n",
    "\n",
    "trained_module.eval()\n",
    "datamodule.setup(stage=\"fit\")\n",
    "device = next(trained_module.parameters()).device\n",
    "print(f\"Loaded artifacts from run {run.name} (device={device})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd00f8",
   "metadata": {},
   "source": [
    "## Collect predictions and targets\n",
    "Use the validation split (or training split if validation is missing) to\n",
    "gather predictions and targets for plotting.\n",
    "\n",
    "We switch the module to eval mode (disables dropout/batch norm updates),\n",
    "iterate over the validation loader, and collect logits and labels on CPU so\n",
    "plotting stays lightweight. Predictions are *logits* (unnormalized scores);\n",
    "we’ll convert them inside each plotting function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6220cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = datamodule.val_dataloader()\n",
    "if isinstance(val_loader, list) and len(val_loader) == 0:\n",
    "    val_loader = datamodule.train_dataloader()\n",
    "\n",
    "preds, targets = [], []\n",
    "for batch in val_loader:\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds.append(trained_module(batch).detach().cpu())\n",
    "        targets.append(batch.y.detach().cpu())\n",
    "\n",
    "predictions = torch.cat(preds)\n",
    "targets = torch.cat(targets)\n",
    "print(f\"Collected predictions for {len(targets)} samples.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5254bb",
   "metadata": {},
   "source": [
    "## Plot training diagnostics\n",
    "Four key diagnostics rendered inline (no files written):\n",
    "\n",
    "1) Loss curves (`plot_loss_curves`)\n",
    "   - X-axis: epoch index. Y-axis: loss value.\n",
    "   - Computation: stored `train_epoch_loss_history` / `val_epoch_loss_history`\n",
    "     tracked during Lightning training.\n",
    "   - Interpretation: steady downward trend on both curves → learning. If\n",
    "     train decreases while val increases, you're overfitting. Flat lines mean\n",
    "     the model is stuck.\n",
    "\n",
    "2) Confusion matrices (`plot_multilabel_confusion_matrix`)\n",
    "   - One small matrix per class: rows are true (negative/positive), columns\n",
    "     are predicted (negative/positive). Normalized so values sum to 1.\n",
    "   - Computation: logits → sigmoid → threshold at 0.5 → binary prediction per\n",
    "     class, compared against one-hot labels.\n",
    "   - Interpretation: dark diagonal = correct predictions. Off-diagonal mass\n",
    "     indicates false positives/negatives for that class.\n",
    "\n",
    "3) ROC curves (`plot_roc_curves`)\n",
    "   - X-axis: False Positive Rate. Y-axis: True Positive Rate.\n",
    "   - Computation: sweep thresholds over the sigmoid probabilities and measure\n",
    "     TPR/FPR for each class; area under curve (AUC) summarizes ranking quality.\n",
    "   - Interpretation: curves near the top-left and higher AUC are better. A\n",
    "     diagonal line means random guessing.\n",
    "\n",
    "4) Precision-Recall curves (`plot_precision_recall_curves`)\n",
    "   - X-axis: Recall. Y-axis: Precision.\n",
    "   - Computation: sweep thresholds over sigmoid probabilities and compute\n",
    "     precision/recall for each class; area under curve (Average Precision)\n",
    "     summarizes performance on imbalanced data.\n",
    "   - Interpretation: higher curves mean better precision while retrieving most\n",
    "     positives. If precision crashes at higher recall, the model struggles to\n",
    "     find positives without many false alarms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(trained_module, title=\"Quickstart: Loss Curves\", show=True)\n",
    "\n",
    "plot_multilabel_confusion_matrix(\n",
    "    predictions=predictions,\n",
    "    targets=targets,\n",
    "    class_names=[\"pi\", \"mu\", \"e+\"],\n",
    "    threshold=0.5,\n",
    "    normalize=True,\n",
    "    save_path=None,\n",
    "    show=True,\n",
    ")\n",
    "\n",
    "plot_roc_curves(\n",
    "    predictions=predictions,\n",
    "    targets=targets,\n",
    "    class_names=[\"pi\", \"mu\", \"e+\"],\n",
    "    save_path=None,\n",
    "    show=True,\n",
    ")\n",
    "\n",
    "plot_precision_recall_curves(\n",
    "    predictions=predictions,\n",
    "    targets=targets,\n",
    "    class_names=[\"pi\", \"mu\", \"e+\"],\n",
    "    save_path=None,\n",
    "    show=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}