{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Tutorial 3: Hyperparameter Tuning with Optuna\n",
    "\n",
    "This tutorial shows how to run Optuna sweeps inside a ZenML pipeline. You'll learn how to:\n",
    "\n",
    "- Generate synthetic graph data for tuning\n",
    "- Define a ZenML pipeline that includes an Optuna search step\n",
    "- Inspect the best hyperparameters and the tuned model\n",
    "- Evaluate the tuned model on the validation split\n",
    "\n",
    "Unlike earlier versions, the full pipeline now lives in the notebook so you can modify\n",
    "every step. We assume Optuna is installed (see `requirements.txt`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import optuna\n",
    "from torch_geometric.data import Data\n",
    "from zenml import pipeline, step\n",
    "\n",
    "from pioneerml.models import GroupClassifier\n",
    "from pioneerml.training import GraphDataModule, GraphLightningModule\n",
    "from pioneerml.zenml.materializers import (\n",
    "    GraphDataModuleMaterializer,\n",
    "    PyGDataListMaterializer,\n",
    ")\n",
    "from pioneerml.zenml import load_step_output\n",
    "from pioneerml.zenml import utils as zenml_utils\n",
    "from pioneerml.zenml.utils import detect_available_accelerator\n",
    "\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(use_in_memory=True)\n",
    "print(f\"ZenML initialized with stack: {zenml_client.active_stack_model.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-overview",
   "metadata": {},
   "source": [
    "## Build the Tuning Pipeline\n",
    "\n",
    "The pipeline mirrors the structure from earlier tutorials and adds an Optuna step:\n",
    "\n",
    "1. `create_data`: synthetic graph classification dataset\n",
    "2. `create_datamodule`: wraps the dataset with train/val splits\n",
    "3. `run_hyperparameter_search`: Optuna study that picks hidden size, learning rate, dropout\n",
    "4. `train_best_model`: trains one final model with the best parameters\n",
    "\n",
    "Optuna runs entirely inside the pipeline, making the sweep reproducible and tracked in ZenML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_tuning_data(num_samples: int = 200) -> list[Data]:\n",
    "    \"\"\"Generate clustered graphs for a 3-class classification task.\"\"\"\n",
    "    class_offsets = torch.tensor([\n",
    "        [2.0, 0.0, 0.5, 0.0, 0.0],\n",
    "        [0.0, 2.0, 0.0, 0.5, 0.0],\n",
    "        [-2.0, -2.0, -0.5, 0.0, 0.5],\n",
    "    ])\n",
    "    data: list[Data] = []\n",
    "    for _ in range(num_samples):\n",
    "        label = torch.randint(0, 3, (1,)).item()\n",
    "        num_nodes = torch.randint(5, 10, (1,)).item()\n",
    "        x = torch.randn(num_nodes, 5) * 0.4 + class_offsets[label]\n",
    "        edge_index = torch.randint(0, num_nodes, (2, num_nodes * 3))\n",
    "        edge_attr = torch.randn(edge_index.shape[1], 4) * 0.3\n",
    "        y = torch.zeros(3)\n",
    "        y[label] = 1.0\n",
    "        data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n",
    "    return data\n",
    "\n",
    "\n",
    "@step(output_materializers=PyGDataListMaterializer, enable_cache=False)\n",
    "def create_data() -> list[Data]:\n",
    "    \"\"\"Step 1: Generate synthetic graphs for tuning.\"\"\"\n",
    "    return create_synthetic_tuning_data()\n",
    "\n",
    "\n",
    "@step(output_materializers=GraphDataModuleMaterializer, enable_cache=False)\n",
    "def create_datamodule(data: list[Data]) -> GraphDataModule:\n",
    "    \"\"\"Step 2: Wrap the dataset in a Lightning DataModule.\"\"\"\n",
    "    return GraphDataModule(dataset=data, val_split=0.25, batch_size=32, num_workers=0)\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def run_hyperparameter_search(datamodule: GraphDataModule, n_trials: int = 4) -> dict:\n",
    "    \"\"\"Step 3: Perform an Optuna search over hidden size, dropout, and learning rate.\"\"\"\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
    "        lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "\n",
    "        model = GroupClassifier(num_classes=3, hidden=hidden_dim, dropout=dropout)\n",
    "        lightning_module = GraphLightningModule(model, task=\"classification\", lr=lr)\n",
    "        accelerator, devices = detect_available_accelerator()\n",
    "\n",
    "        import pytorch_lightning as pl\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator=accelerator,\n",
    "            devices=devices,\n",
    "            max_epochs=2,\n",
    "            logger=False,\n",
    "            enable_checkpointing=False,\n",
    "            enable_progress_bar=False,\n",
    "        )\n",
    "\n",
    "        datamodule.setup(stage=\"fit\")\n",
    "        trainer.fit(lightning_module, datamodule=datamodule)\n",
    "        val_metrics = trainer.validate(lightning_module, datamodule=datamodule, verbose=False)\n",
    "        if val_metrics and isinstance(val_metrics[0], dict):\n",
    "            accuracy = val_metrics[0].get(\"val_accuracy\")\n",
    "            if accuracy is not None:\n",
    "                return float(accuracy)\n",
    "            loss = val_metrics[0].get(\"val_loss\")\n",
    "            if loss is not None:\n",
    "                return 1.0 / (1.0 + float(loss))\n",
    "        return 0.0\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    return {\n",
    "        \"best_hidden_dim\": study.best_params[\"hidden_dim\"],\n",
    "        \"best_dropout\": study.best_params[\"dropout\"],\n",
    "        \"best_lr\": study.best_params[\"lr\"],\n",
    "        \"best_accuracy\": study.best_value,\n",
    "        \"n_trials\": len(study.trials),\n",
    "    }\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def train_best_model(best_params: dict, datamodule: GraphDataModule) -> GraphLightningModule:\n",
    "    \"\"\"Step 4: Train a final model with the best Optuna parameters.\"\"\"\n",
    "    model = GroupClassifier(\n",
    "        num_classes=3,\n",
    "        hidden=best_params[\"best_hidden_dim\"],\n",
    "        dropout=best_params[\"best_dropout\"],\n",
    "    )\n",
    "    lightning_module = GraphLightningModule(model, task=\"classification\", lr=best_params[\"best_lr\"])\n",
    "\n",
    "    import pytorch_lightning as pl\n",
    "\n",
    "    accelerator, devices = detect_available_accelerator()\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        max_epochs=5,\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    datamodule.setup(stage=\"fit\")\n",
    "    trainer.fit(lightning_module, datamodule=datamodule)\n",
    "    return lightning_module.eval()\n",
    "\n",
    "\n",
    "@pipeline\n",
    "def tuning_pipeline(n_trials: int = 4):\n",
    "    data = create_data()\n",
    "    datamodule = create_datamodule(data)\n",
    "    best_params = run_hyperparameter_search(datamodule, n_trials=n_trials)\n",
    "    tuned_model = train_best_model(best_params, datamodule)\n",
    "    return tuned_model, datamodule, best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-section",
   "metadata": {},
   "source": [
    "## Run the Optuna Sweep\n",
    "\n",
    "Execute the pipeline with a small number of trials (increase `n_trials` for real sweeps).\n",
    "The pipeline stores all runs and best parameters in ZenML so you can reproduce the sweep later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = tuning_pipeline.with_options(enable_cache=False)(n_trials=4)\n",
    "print(f\"Pipeline run status: {run.status}\")\n",
    "\n",
    "tuned_module = load_step_output(run, \"train_best_model\")\n",
    "datamodule = load_step_output(run, \"create_datamodule\")\n",
    "best_params = load_step_output(run, \"run_hyperparameter_search\")\n",
    "\n",
    "if tuned_module is None or datamodule is None or best_params is None:\n",
    "    raise RuntimeError(\"Failed to load artifacts from the tuning pipeline.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tuned_module = tuned_module.to(device).eval()\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"- {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect",
   "metadata": {},
   "source": [
    "## Inspect the Tuned Model\n",
    "\n",
    "Check that the tuned model has the expected shape, parameter count, and device placement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inspect-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = next(tuned_module.parameters()).device\n",
    "param_count = sum(p.numel() for p in tuned_module.parameters())\n",
    "\n",
    "train_loader = datamodule.train_dataloader()\n",
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "print(\"Tuned Model Summary:\")\n",
    "print(f\"- Run: {run.name}\")\n",
    "print(f\"- Device: {device}\")\n",
    "print(f\"- Parameters: {param_count:,}\")\n",
    "print(f\"- Nodes per batch: {first_batch.x.shape[0]} | Features: {first_batch.x.shape[1]}\")\n",
    "print(f\"- Edges: {first_batch.edge_index.shape[1]}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = tuned_module(first_batch.to(device))\n",
    "    print(f\"- Output logits shape: {tuple(logits.shape)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accuracy-intro",
   "metadata": {},
   "source": [
    "## Evaluate Validation Accuracy\n",
    "\n",
    "Run the tuned model on the validation split. We handle label shapes explicitly because\n",
    "PyG batches graph-level labels into `(batch_size, num_classes)` tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accuracy-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = datamodule.val_dataloader()\n",
    "if isinstance(val_loader, list) and len(val_loader) == 0:\n",
    "    val_loader = datamodule.train_dataloader()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "tuned_module.eval()\n",
    "\n",
    "for batch in val_loader:\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = tuned_module(batch)\n",
    "\n",
    "    labels = batch.y\n",
    "    if labels.dim() == 1:\n",
    "        if labels.shape[0] % 3 == 0:\n",
    "            labels = labels.view(-1, 3)\n",
    "        else:\n",
    "            labels = labels.unsqueeze(0)\n",
    "    labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    correct += int((preds == labels).sum().item())\n",
    "    total += int(labels.numel())\n",
    "\n",
    "accuracy = correct / total if total > 0 else 0.0\n",
    "print(f\"Validation accuracy: {accuracy:.1%} ({correct}/{total})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}