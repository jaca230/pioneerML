{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b3c7dd",
   "metadata": {},
   "source": [
    "# Tutorial 1: Building ZenML Pipelines\n",
    "\n",
    "Learn how our tutorial pipelines are structured, trigger a run, and inspect\n",
    "the outputs produced by ZenML.\n",
    "\n",
    "What you'll see:\n",
    "- How to define ZenML steps/pipelines inline (no hidden magic).\n",
    "- How materializers control artifact serialization to avoid noisy warnings.\n",
    "- What each step contributes and how ZenML wires inputs/outputs.\n",
    "- A quick sanity-check metric and how to interpret the basic training run.\n",
    "\n",
    "Reading the notebook:\n",
    "- Markdown above each block explains inputs/outputs and why the code is there.\n",
    "- Pay attention to device placement when reloading artifacts (CPU vs GPU).\n",
    "- Treat the final accuracy as a smoke test, not a benchmark (synthetic data).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c068578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from zenml import pipeline, step\n",
    "from zenml.utils import source_utils\n",
    "\n",
    "from pioneerml.models import GroupClassifier\n",
    "from pioneerml.training import GraphDataModule, GraphLightningModule\n",
    "from pioneerml.zenml.materializers import (\n",
    "    GraphDataModuleMaterializer,\n",
    "    PyGDataListMaterializer,\n",
    ")\n",
    "from pioneerml.zenml.utils import detect_available_accelerator, load_step_output\n",
    "import pioneerml.zenml.utils as zenml_utils\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    \"\"\"Walk upward to locate the repo root (pyproject or .git).\"\"\"\n",
    "    start = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd().resolve()\n",
    "    for path in [start] + list(start.parents):\n",
    "        if (path / \"pyproject.toml\").exists() or (path / \".git\").exists():\n",
    "            return path\n",
    "    return start\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "source_utils.set_custom_source_root(PROJECT_ROOT / \"src\")\n",
    "\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(root_path=PROJECT_ROOT, use_in_memory=True)\n",
    "print(f\"Active ZenML stack: {zenml_client.active_stack_model.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eea712",
   "metadata": {},
   "source": [
    "## Define the basic training pipeline\n",
    "Build the steps directly in the notebook so you can see how ZenML pipelines\n",
    "are composed. The cell below walks through every piece:\n",
    "- `create_data`: synthetic graphs for a 3-class task, saved with a custom\n",
    "  materializer to avoid pickle spam.\n",
    "- `create_datamodule`: splits into train/val and sets sane batch/worker sizes.\n",
    "- `create_model` / `create_lightning_module`: model + Lightning wrapper.\n",
    "- `train_model`: short CPU/GPU-friendly fit with caching disabled.\n",
    "\n",
    "Inputs/outputs:\n",
    "- Steps communicate via return values; ZenML handles wiring.\n",
    "- Materializers specify how to serialize outputs; here we use lightweight\n",
    "  torch saves to keep artifact warnings quiet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96754ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_simple_synthetic_data(num_samples: int = 200) -> list[Data]:\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        num_nodes = torch.randint(4, 8, (1,)).item()\n",
    "        x = torch.randn(num_nodes, 5)\n",
    "        edge_index = torch.randint(0, num_nodes, (2, num_nodes * 2))\n",
    "        edge_attr = torch.randn(edge_index.shape[1], 4)\n",
    "        label = torch.randint(0, 3, (1,)).item()\n",
    "        y = torch.zeros(3)\n",
    "        y[label] = 1.0\n",
    "        data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n",
    "    return data\n",
    "\n",
    "\n",
    "@step(output_materializers=PyGDataListMaterializer, enable_cache=False)\n",
    "def create_data() -> list[Data]:\n",
    "    return create_simple_synthetic_data()\n",
    "\n",
    "\n",
    "@step(output_materializers=GraphDataModuleMaterializer, enable_cache=False)\n",
    "def create_datamodule(data: list[Data]) -> GraphDataModule:\n",
    "    return GraphDataModule(dataset=data, val_split=0.2, batch_size=32, num_workers=2)\n",
    "\n",
    "\n",
    "@step\n",
    "def create_model(num_classes: int = 3) -> GroupClassifier:\n",
    "    return GroupClassifier(num_classes=num_classes, hidden=64, num_blocks=1)\n",
    "\n",
    "\n",
    "@step\n",
    "def create_lightning_module(model: GroupClassifier) -> GraphLightningModule:\n",
    "    return GraphLightningModule(model, task=\"classification\", lr=1e-3)\n",
    "\n",
    "\n",
    "@step\n",
    "def train_model(lightning_module: GraphLightningModule, datamodule: GraphDataModule) -> GraphLightningModule:\n",
    "    import pytorch_lightning as pl\n",
    "\n",
    "    accelerator, devices = detect_available_accelerator()\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        max_epochs=3,\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.fit(lightning_module, datamodule=datamodule)\n",
    "    return lightning_module.eval()\n",
    "\n",
    "\n",
    "@pipeline\n",
    "def basic_training_pipeline_demo():\n",
    "    data = create_data()\n",
    "    datamodule = create_datamodule(data)\n",
    "    model = create_model()\n",
    "    lightning_module = create_lightning_module(model)\n",
    "    trained_module = train_model(lightning_module, datamodule)\n",
    "    return trained_module, datamodule\n",
    "\n",
    "\n",
    "# Reuse the packaged pipeline implementation for execution while keeping the\n",
    "# definition above for learning purposes.\n",
    "from pioneerml.zenml.pipelines.tutorial_examples.basic_training import (\n",
    "    basic_training_pipeline as packaged_basic_training_pipeline,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14070dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = packaged_basic_training_pipeline.with_options(enable_cache=False)()\n",
    "print(f\"Pipeline run {run.name} status: {run.status}\")\n",
    "\n",
    "# Load artifacts from the run so we can inspect them locally\n",
    "trained_module = load_step_output(run, \"train_model\")\n",
    "datamodule = load_step_output(run, \"create_datamodule\")\n",
    "model = getattr(trained_module, \"model\", None) if trained_module is not None else None\n",
    "\n",
    "if trained_module is None or datamodule is None:\n",
    "    raise RuntimeError(\"Could not load artifacts from the basic_training_pipeline run.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trained_module = trained_module.to(device).eval()\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7684f",
   "metadata": {},
   "source": [
    "## Inspect the outputs\n",
    "Check the dataset size, batch shape, and key model parameters. This helps\n",
    "validate that the data/materializers round-tripped correctly and that the\n",
    "model config is what we expect.\n",
    "- Dataset size: confirms split sizes match expectations.\n",
    "- Batch shape: confirms node/edge dimensions align with model input.\n",
    "- Model config: sanity check on hidden dim and class count.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = next(trained_module.parameters()).device\n",
    "train_loader = datamodule.train_dataloader()\n",
    "first_batch = next(iter(train_loader))\n",
    "train_size = len(datamodule.train_dataset) if datamodule.train_dataset is not None else 0\n",
    "val_size = len(datamodule.val_dataset) if datamodule.val_dataset is not None else 0\n",
    "\n",
    "print(\"Training summary:\")\n",
    "print(f\"- Run: {run.name}\")\n",
    "print(f\"- Device: {device}\")\n",
    "print(f\"- Dataset size: {train_size + val_size} samples (train={train_size}, val={val_size})\")\n",
    "print(f\"- Batch shape: x={tuple(first_batch.x.shape)}, edge_index={tuple(first_batch.edge_index.shape)}\")\n",
    "\n",
    "if model:\n",
    "    print(\"Model configuration:\")\n",
    "    print(f\"- Type: {type(model).__name__}\")\n",
    "    print(f\"- Hidden dimension: {getattr(model, 'hidden', 'n/a')}\")\n",
    "    print(f\"- Num classes: {getattr(model, 'num_classes', 'n/a')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95626a27",
   "metadata": {},
   "source": [
    "## Evaluate quickly on the validation split\n",
    "Use the trained module to compute a lightweight accuracy metric so we have\n",
    "a sanity check that training worked. Accuracy here is on a tiny synthetic\n",
    "validation set, so treat it as a smoke test rather than a real benchmark.\n",
    "\n",
    "Metric details:\n",
    "- Inputs: logits from the model vs one-hot labels.\n",
    "- Computation: argmax over logits and labels → class IDs → compare for exact\n",
    "  match, averaged over the validation set.\n",
    "- Interpretation: >0.33 means the model is learning above random (3 classes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85505554",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = datamodule.val_dataloader()\n",
    "if isinstance(val_loader, list) and len(val_loader) == 0:\n",
    "    val_loader = datamodule.train_dataloader()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for batch in val_loader:\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = trained_module(batch)\n",
    "    labels = batch.y\n",
    "    if labels.dim() == 1 and logits.shape[-1] > 0 and labels.numel() % logits.shape[-1] == 0:\n",
    "        labels = labels.view(-1, logits.shape[-1])\n",
    "    if labels.dim() > 1:\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    correct += int((preds == labels).sum().item())\n",
    "    total += int(labels.numel())\n",
    "\n",
    "accuracy = correct / total if total else 0.0\n",
    "print(f\"Validation accuracy (quick check): {accuracy:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}