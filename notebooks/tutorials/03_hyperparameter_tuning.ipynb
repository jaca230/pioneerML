{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Tutorial 3: Hyperparameter Tuning with Optuna\n",
    "\n",
    "This tutorial shows how to run Optuna sweeps inside a ZenML pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZenML initialized with stack: default\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import io\n",
    "import warnings\n",
    "import torch\n",
    "import optuna\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.data import Data\n",
    "from zenml import pipeline, step\n",
    "\n",
    "from pioneerml.models import GroupClassifier\n",
    "from pioneerml.training import GraphDataModule, GraphLightningModule\n",
    "from pioneerml.zenml.materializers import (\n",
    "    GraphDataModuleMaterializer,\n",
    "    PyGDataListMaterializer,\n",
    ")\n",
    "from pioneerml.zenml import load_step_output\n",
    "from pioneerml.zenml import utils as zenml_utils\n",
    "from pioneerml.zenml.utils import detect_available_accelerator\n",
    "\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(use_in_memory=True)\n",
    "print(f\"ZenML initialized with stack: {zenml_client.active_stack_model.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-overview",
   "metadata": {},
   "source": [
    "## Build the Tuning Pipeline\n",
    "\n",
    "The pipeline mirrors the structure from earlier tutorials and adds an Optuna step:\n",
    "\n",
    "1. `create_data`: synthetic graph classification dataset\n",
    "2. `create_datamodule`: wraps the dataset with train/val splits\n",
    "3. `run_hyperparameter_search`: Optuna study that picks hidden size, learning rate, dropout\n",
    "4. `train_best_model`: trains one final model with the best parameters\n",
    "\n",
    "Optuna runs entirely inside the pipeline, making the sweep reproducible and tracked in ZenML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pipeline-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_synthetic_tuning_data(num_samples: int = 400) -> list[Data]:\n",
    "    \"\"\"Generate a deliberately tricky dataset so Optuna can't hit 100% accuracy.\"\"\"\n",
    "    data: list[Data] = []\n",
    "\n",
    "    class_means = torch.tensor([\n",
    "        [0.7, -0.3, 0.2, 0.1, -0.1],\n",
    "        [-0.1, 0.8, -0.2, 0.3, 0.15],\n",
    "        [-0.6, -0.4, 0.4, -0.2, 0.25],\n",
    "    ])\n",
    "    class_drift = torch.tensor([\n",
    "        [0.4, 0.3, -0.1, 0.0, 0.2],\n",
    "        [-0.3, 0.2, 0.25, -0.15, -0.1],\n",
    "        [0.2, -0.4, 0.15, 0.25, -0.05],\n",
    "    ])\n",
    "    feature_scales = torch.tensor([\n",
    "        [1.0, 0.9, 1.1, 0.95, 1.05],\n",
    "        [0.95, 1.05, 0.85, 1.1, 0.9],\n",
    "        [1.1, 0.95, 0.9, 1.0, 1.0],\n",
    "    ])\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        label = torch.randint(0, 3, (1,)).item()\n",
    "        num_nodes = torch.randint(7, 18, (1,)).item()\n",
    "\n",
    "        mix_label = (label + torch.randint(1, 3, (1,)).item()) % 3\n",
    "        mix_ratio = torch.rand(1).item() * 0.6 + 0.2\n",
    "        prototype = mix_ratio * class_means[label] + (1 - mix_ratio) * class_means[mix_label]\n",
    "\n",
    "        t = torch.linspace(0, 1, steps=num_nodes).unsqueeze(1)\n",
    "        wiggles = torch.cat([\n",
    "            torch.sin(2.0 * torch.pi * t + label * 0.3),\n",
    "            torch.cos(3.0 * torch.pi * t + mix_ratio),\n",
    "            torch.sin(4.0 * torch.pi * t - mix_ratio * 0.5),\n",
    "            torch.cos(5.0 * torch.pi * t + label * 0.2),\n",
    "            torch.sin(6.0 * torch.pi * t - 0.1),\n",
    "        ], dim=1)\n",
    "\n",
    "        x = prototype + 0.4 * wiggles\n",
    "        x = x * feature_scales[label]\n",
    "\n",
    "        noise = torch.randn(num_nodes, 5)\n",
    "        correlated = noise + 0.35 * torch.matmul(noise, torch.ones(5, 5) * 0.1)\n",
    "        drift = class_drift[label] * torch.randn(num_nodes, 1)\n",
    "        x = x + 0.25 * correlated + drift\n",
    "\n",
    "        projection = torch.randn(5, 5) * 0.2 + torch.eye(5)\n",
    "        x = x @ projection\n",
    "\n",
    "        if label == 0:\n",
    "            ring = torch.stack([\n",
    "                torch.arange(num_nodes),\n",
    "                (torch.arange(num_nodes) + 1) % num_nodes,\n",
    "            ])\n",
    "            random_edges = torch.randint(0, num_nodes, (2, num_nodes * 2))\n",
    "            edge_index = torch.cat([ring, random_edges], dim=1)\n",
    "        elif label == 1:\n",
    "            cluster = max(3, num_nodes // 2)\n",
    "            src = torch.randint(0, cluster, (num_nodes * 3,))\n",
    "            dst = torch.randint(0, cluster, (num_nodes * 3,))\n",
    "            long_jump = torch.randint(0, num_nodes, (2, num_nodes))\n",
    "            edge_index = torch.cat([torch.stack([src, dst], dim=0), long_jump], dim=1)\n",
    "        else:\n",
    "            src = torch.randint(0, num_nodes, (num_nodes * 2,))\n",
    "            dst = (src + torch.randint(2, 7, (num_nodes * 2,))) % num_nodes\n",
    "            extra = torch.randint(0, num_nodes, (2, num_nodes))\n",
    "            edge_index = torch.cat([torch.stack([src, dst], dim=0), extra], dim=1)\n",
    "\n",
    "        edge_attr = torch.randn(edge_index.shape[1], 4) * 0.15 + label * 0.04\n",
    "\n",
    "        noisy_label = label\n",
    "        if torch.rand(1).item() < 0.1:\n",
    "            noisy_label = torch.randint(0, 3, (1,)).item()\n",
    "\n",
    "        y = torch.zeros(3)\n",
    "        y[noisy_label] = 1.0\n",
    "\n",
    "        data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n",
    "\n",
    "    return data\n",
    "\n",
    "def run_silently(fn):\n",
    "    \"\"\"Run a Lightning call with stdout/stderr, warnings, and PL logs disabled.\"\"\"\n",
    "    # Disable python warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        # Disable Lightning logs globally\n",
    "        pl._logger.setLevel(\"ERROR\")\n",
    "\n",
    "        # Silence stdout and stderr\n",
    "        buffer_out = io.StringIO()\n",
    "        buffer_err = io.StringIO()\n",
    "        with contextlib.redirect_stdout(buffer_out), contextlib.redirect_stderr(buffer_err):\n",
    "            return fn()\n",
    "\n",
    "\n",
    "\n",
    "@step(output_materializers=PyGDataListMaterializer, enable_cache=False)\n",
    "def create_data() -> list[Data]:\n",
    "    \"\"\"Step 1: Generate synthetic graphs for tuning.\"\"\"\n",
    "    return create_synthetic_tuning_data()\n",
    "\n",
    "\n",
    "@step(output_materializers=GraphDataModuleMaterializer, enable_cache=False)\n",
    "def create_datamodule(data: list[Data]) -> GraphDataModule:\n",
    "    \"\"\"Step 2: Wrap the dataset in a Lightning DataModule.\"\"\"\n",
    "    return GraphDataModule(dataset=data, val_split=0.25, batch_size=32, num_workers=0)\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def run_hyperparameter_search(datamodule: GraphDataModule, n_trials: int = 4) -> dict:\n",
    "    \"\"\"Step 3: Perform an Optuna search over hidden size, dropout, and learning rate.\"\"\"\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
    "        lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "\n",
    "        model = GroupClassifier(num_classes=3, hidden=hidden_dim, dropout=dropout)\n",
    "        lightning_module = GraphLightningModule(model, task=\"classification\", lr=lr)\n",
    "        accelerator, devices = detect_available_accelerator()\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator=accelerator,\n",
    "            devices=devices,\n",
    "            max_epochs=2,\n",
    "            logger=False,\n",
    "            enable_checkpointing=False,\n",
    "            enable_progress_bar=False,\n",
    "        )\n",
    "\n",
    "        datamodule.setup(stage=\"fit\")\n",
    "\n",
    "        def fit():\n",
    "            trainer.fit(lightning_module, datamodule=datamodule)\n",
    "\n",
    "        def validate():\n",
    "            return trainer.validate(lightning_module, datamodule=datamodule, verbose=False)\n",
    "\n",
    "        run_silently(fit)\n",
    "        val_metrics = run_silently(validate)\n",
    "\n",
    "        if val_metrics and isinstance(val_metrics[0], dict):\n",
    "            accuracy = val_metrics[0].get(\"val_accuracy\")\n",
    "            if accuracy is not None:\n",
    "                return float(accuracy)\n",
    "            loss = val_metrics[0].get(\"val_loss\")\n",
    "            if loss is not None:\n",
    "                return 1.0 / (1.0 + float(loss))\n",
    "        return 0.0\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    return {\n",
    "        \"best_hidden_dim\": study.best_params[\"hidden_dim\"],\n",
    "        \"best_dropout\": study.best_params[\"dropout\"],\n",
    "        \"best_lr\": study.best_params[\"lr\"],\n",
    "        \"best_accuracy\": study.best_value,\n",
    "        \"n_trials\": len(study.trials),\n",
    "    }\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def train_best_model(best_params: dict, datamodule: GraphDataModule) -> GraphLightningModule:\n",
    "    \"\"\"Step 4: Train a final model with the best Optuna parameters.\"\"\"\n",
    "    model = GroupClassifier(\n",
    "        num_classes=3,\n",
    "        hidden=best_params[\"best_hidden_dim\"],\n",
    "        dropout=best_params[\"best_dropout\"],\n",
    "    )\n",
    "    lightning_module = GraphLightningModule(\n",
    "        model,\n",
    "        task=\"classification\",\n",
    "        lr=best_params[\"best_lr\"],\n",
    "    )\n",
    "\n",
    "    accelerator, devices = detect_available_accelerator()\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        max_epochs=5,\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    datamodule.setup(stage=\"fit\")\n",
    "\n",
    "    def fit():\n",
    "        trainer.fit(lightning_module, datamodule=datamodule)\n",
    "\n",
    "    run_silently(fit)\n",
    "    return lightning_module.eval()\n",
    "\n",
    "\n",
    "@pipeline\n",
    "def tuning_pipeline(n_trials: int = 4):\n",
    "    data = create_data()\n",
    "    datamodule = create_datamodule(data)\n",
    "    best_params = run_hyperparameter_search(datamodule, n_trials=n_trials)\n",
    "    tuned_model = train_best_model(best_params, datamodule)\n",
    "    return tuned_model, datamodule, best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-section",
   "metadata": {},
   "source": [
    "## Run the Optuna Sweep\n",
    "\n",
    "Execute the pipeline with a small number of trials (increase `n_trials` for real sweeps).\n",
    "The pipeline stores all runs and best parameters in ZenML so you can reproduce the sweep later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "run-pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mInitiating a new run for the pipeline: \u001b[0m\u001b[38;5;105mtuning_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mCaching is disabled by default for \u001b[0m\u001b[38;5;105mtuning_pipeline\u001b[37m.\u001b[0m\n",
      "\u001b[37mUsing user: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mUsing stack: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  artifact_store: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  orchestrator: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37m  deployer: \u001b[0m\u001b[38;5;105mdefault\u001b[37m\u001b[0m\n",
      "\u001b[37mYou can visualize your pipeline runs in the \u001b[0m\u001b[38;5;105mZenML Dashboard\u001b[37m. In order to try it locally, please run \u001b[0m\u001b[38;5;105mzenml login --local\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_data\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_data\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.155s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_datamodule\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mcreate_datamodule\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.079s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mrun_hyperparameter_search\u001b[37m has started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-25 04:33:11,839] A new study created in memory with name: no-name-c8ed3a0e-7cf1-402f-b16e-24f43d077c29\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "[I 2025-11-25 04:33:12,581] Trial 0 finished with value: 0.6499999761581421 and parameters: {'hidden_dim': 64, 'dropout': 0.2487614317145586, 'lr': 0.0006290288921601403}. Best is trial 0 with value: 0.6499999761581421.\n",
      "[I 2025-11-25 04:33:12,919] Trial 1 finished with value: 0.7300000190734863 and parameters: {'hidden_dim': 256, 'dropout': 0.22582791873111144, 'lr': 0.000991135229666614}. Best is trial 1 with value: 0.7300000190734863.\n",
      "[I 2025-11-25 04:33:13,252] Trial 2 finished with value: 0.7633333802223206 and parameters: {'hidden_dim': 256, 'dropout': 0.16462237433646493, 'lr': 0.0016383759401386534}. Best is trial 2 with value: 0.7633333802223206.\n",
      "[I 2025-11-25 04:33:13,573] Trial 3 finished with value: 0.699999988079071 and parameters: {'hidden_dim': 256, 'dropout': 0.10999501701382403, 'lr': 0.00019560098503299211}. Best is trial 2 with value: 0.7633333802223206.\n",
      "[I 2025-11-25 04:33:13,861] Trial 4 finished with value: 0.6566666960716248 and parameters: {'hidden_dim': 128, 'dropout': 0.09200123879859176, 'lr': 0.00022530683485461829}. Best is trial 2 with value: 0.7633333802223206.\n",
      "[I 2025-11-25 04:33:14,141] Trial 5 finished with value: 0.7733333706855774 and parameters: {'hidden_dim': 64, 'dropout': 0.048264409118379044, 'lr': 0.0033446223148493348}. Best is trial 5 with value: 0.7733333706855774.\n",
      "[I 2025-11-25 04:33:14,418] Trial 6 finished with value: 0.6666666269302368 and parameters: {'hidden_dim': 64, 'dropout': 0.22741323054638, 'lr': 0.00012283752184641384}. Best is trial 5 with value: 0.7733333706855774.\n",
      "[I 2025-11-25 04:33:14,695] Trial 7 finished with value: 0.7266666293144226 and parameters: {'hidden_dim': 64, 'dropout': 0.03256437684083038, 'lr': 0.0017349411330359972}. Best is trial 5 with value: 0.7733333706855774.\n",
      "[I 2025-11-25 04:33:15,020] Trial 8 finished with value: 0.7566666603088379 and parameters: {'hidden_dim': 256, 'dropout': 0.13372833839085724, 'lr': 0.0004556431622480751}. Best is trial 5 with value: 0.7733333706855774.\n",
      "[I 2025-11-25 04:33:15,325] Trial 9 finished with value: 0.7000000476837158 and parameters: {'hidden_dim': 256, 'dropout': 0.0778548584003619, 'lr': 0.0031338719005572385}. Best is trial 5 with value: 0.7733333706855774.\n",
      "[I 2025-11-25 04:33:15,616] Trial 10 finished with value: 0.7466667294502258 and parameters: {'hidden_dim': 128, 'dropout': 0.001322696487203033, 'lr': 0.004345466075578117}. Best is trial 5 with value: 0.7733333706855774.\n",
      "[I 2025-11-25 04:33:15,894] Trial 11 finished with value: 0.6566666960716248 and parameters: {'hidden_dim': 64, 'dropout': 0.1691740830116364, 'lr': 0.001901619793532234}. Best is trial 5 with value: 0.7733333706855774.\n",
      "[I 2025-11-25 04:33:16,475] Trial 12 finished with value: 0.7866666913032532 and parameters: {'hidden_dim': 256, 'dropout': 0.1709514812336612, 'lr': 0.0019391192537244622}. Best is trial 12 with value: 0.7866666913032532.\n",
      "[I 2025-11-25 04:33:16,746] Trial 13 finished with value: 0.7566667199134827 and parameters: {'hidden_dim': 64, 'dropout': 0.28755124305665886, 'lr': 0.004849151314212542}. Best is trial 12 with value: 0.7866666913032532.\n",
      "[I 2025-11-25 04:33:17,029] Trial 14 finished with value: 0.8333333730697632 and parameters: {'hidden_dim': 128, 'dropout': 0.051362315304131684, 'lr': 0.002403259515774147}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:17,310] Trial 15 finished with value: 0.7766667008399963 and parameters: {'hidden_dim': 128, 'dropout': 0.18595966414444023, 'lr': 0.001032119442015336}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:17,596] Trial 16 finished with value: 0.736666738986969 and parameters: {'hidden_dim': 128, 'dropout': 0.13053253474746326, 'lr': 0.0024922627477295097}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:17,897] Trial 17 finished with value: 0.7033333778381348 and parameters: {'hidden_dim': 128, 'dropout': 0.19769797793183294, 'lr': 0.0010907968162437382}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:18,186] Trial 18 finished with value: 0.7200000286102295 and parameters: {'hidden_dim': 128, 'dropout': 0.061931421273946075, 'lr': 0.0005538506907665352}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:18,483] Trial 19 finished with value: 0.7600000500679016 and parameters: {'hidden_dim': 256, 'dropout': 0.010822971441512924, 'lr': 0.002315129444248727}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:18,787] Trial 20 finished with value: 0.7700001001358032 and parameters: {'hidden_dim': 256, 'dropout': 0.11312206644393545, 'lr': 0.0013078406191755403}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:19,078] Trial 21 finished with value: 0.8266667127609253 and parameters: {'hidden_dim': 128, 'dropout': 0.1874440378558565, 'lr': 0.0009648413925123725}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:19,371] Trial 22 finished with value: 0.68666672706604 and parameters: {'hidden_dim': 128, 'dropout': 0.2112143373258003, 'lr': 0.00041393802368420757}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:19,667] Trial 23 finished with value: 0.7800000905990601 and parameters: {'hidden_dim': 128, 'dropout': 0.15779158630671677, 'lr': 0.0007308811187438402}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:19,984] Trial 24 finished with value: 0.7300000190734863 and parameters: {'hidden_dim': 128, 'dropout': 0.26243432770047426, 'lr': 0.001398174093590259}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:20,277] Trial 25 finished with value: 0.7166666984558105 and parameters: {'hidden_dim': 128, 'dropout': 0.18293721134271093, 'lr': 0.002483409293718101}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:20,582] Trial 26 finished with value: 0.7233333587646484 and parameters: {'hidden_dim': 128, 'dropout': 0.1371235181705571, 'lr': 0.0008279739582121162}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:20,904] Trial 27 finished with value: 0.8066667318344116 and parameters: {'hidden_dim': 256, 'dropout': 0.10540708858174583, 'lr': 0.0034306701033625466}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:21,204] Trial 28 finished with value: 0.7333333492279053 and parameters: {'hidden_dim': 128, 'dropout': 0.08704684236427526, 'lr': 0.0035113503266666966}. Best is trial 14 with value: 0.8333333730697632.\n",
      "[I 2025-11-25 04:33:21,533] Trial 29 finished with value: 0.7433333396911621 and parameters: {'hidden_dim': 256, 'dropout': 0.0319592444814983, 'lr': 0.0003124201061207076}. Best is trial 14 with value: 0.8333333730697632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mrun_hyperparameter_search\u001b[37m has finished in \u001b[0m\u001b[38;5;105m9.767s\u001b[37m.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_best_model\u001b[37m has started.\u001b[0m\n",
      "\u001b[37mStep \u001b[0m\u001b[38;5;105mtrain_best_model\u001b[37m has finished in \u001b[0m\u001b[38;5;105m0.957s\u001b[37m.\u001b[0m\n",
      "\u001b[37mPipeline run has finished in \u001b[0m\u001b[38;5;105m12.851s\u001b[37m.\u001b[0m\n",
      "Pipeline run status: completed\n",
      "Best hyperparameters:\n",
      "- best_hidden_dim: 128\n",
      "- best_dropout: 0.051362315304131684\n",
      "- best_lr: 0.002403259515774147\n",
      "- best_accuracy: 0.8333333730697632\n",
      "- n_trials: 30\n"
     ]
    }
   ],
   "source": [
    "run = tuning_pipeline.with_options(enable_cache=False)(n_trials=30)\n",
    "print(f\"Pipeline run status: {run.status}\")\n",
    "\n",
    "tuned_module = load_step_output(run, \"train_best_model\")\n",
    "datamodule = load_step_output(run, \"create_datamodule\")\n",
    "best_params = load_step_output(run, \"run_hyperparameter_search\")\n",
    "\n",
    "if tuned_module is None or datamodule is None or best_params is None:\n",
    "    raise RuntimeError(\"Failed to load artifacts from the tuning pipeline.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tuned_module = tuned_module.to(device).eval()\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"- {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect",
   "metadata": {},
   "source": [
    "## Inspect the Tuned Model\n",
    "\n",
    "Check that the tuned model has the expected shape, parameter count, and device placement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inspect-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model Summary:\n",
      "- Run: tuning_pipeline-2025_11_25-09_33_10_887523\n",
      "- Device: cuda:0\n",
      "- Parameters: 465,412\n",
      "- Nodes per batch: 365 | Features: 5\n",
      "- Edges: 1162\n",
      "- Output logits shape: (32, 3)\n"
     ]
    }
   ],
   "source": [
    "device = next(tuned_module.parameters()).device\n",
    "param_count = sum(p.numel() for p in tuned_module.parameters())\n",
    "\n",
    "train_loader = datamodule.train_dataloader()\n",
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "print(\"Tuned Model Summary:\")\n",
    "print(f\"- Run: {run.name}\")\n",
    "print(f\"- Device: {device}\")\n",
    "print(f\"- Parameters: {param_count:,}\")\n",
    "print(f\"- Nodes per batch: {first_batch.x.shape[0]} | Features: {first_batch.x.shape[1]}\")\n",
    "print(f\"- Edges: {first_batch.edge_index.shape[1]}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = tuned_module(first_batch.to(device))\n",
    "    print(f\"- Output logits shape: {tuple(logits.shape)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accuracy-intro",
   "metadata": {},
   "source": [
    "## Evaluate Validation Accuracy\n",
    "\n",
    "Run the tuned model on the validation split. We handle label shapes explicitly because\n",
    "PyG batches graph-level labels into `(batch_size, num_classes)` tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accuracy-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 76.0% (76/100)\n"
     ]
    }
   ],
   "source": [
    "val_loader = datamodule.val_dataloader()\n",
    "if isinstance(val_loader, list) and len(val_loader) == 0:\n",
    "    val_loader = datamodule.train_dataloader()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "tuned_module.eval()\n",
    "\n",
    "for batch in val_loader:\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = tuned_module(batch)\n",
    "\n",
    "    labels = batch.y\n",
    "    if labels.dim() == 1:\n",
    "        if labels.shape[0] % 3 == 0:\n",
    "            labels = labels.view(-1, 3)\n",
    "        else:\n",
    "            labels = labels.unsqueeze(0)\n",
    "    labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    correct += int((preds == labels).sum().item())\n",
    "    total += int(labels.numel())\n",
    "\n",
    "accuracy = correct / total if total > 0 else 0.0\n",
    "print(f\"Validation accuracy: {accuracy:.1%} ({correct}/{total})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pioneerml)",
   "language": "python",
   "name": "pioneerml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
