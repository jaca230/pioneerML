{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b6e188",
   "metadata": {},
   "source": [
    "# Endpoint Regressor Validation\n",
    "\n",
    "Validate a trained endpoint regressor:\n",
    "- Load model from checkpoint\n",
    "- Load validation data\n",
    "- Generate predictions (all quantiles)\n",
    "- Plot regression diagnostics and Euclidean errors\n",
    "\n",
    "**Quantiles:** The model outputs three quantiles per coordinate: q16 (~-1σ), q50 (median), q84 (~+1σ). All plots are labeled with the corresponding quantile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from pioneerml.zenml import utils as zenml_utils\n",
    "from pioneerml.metadata import MetadataManager\n",
    "from pioneerml.data import load_hits_and_info\n",
    "from pioneerml.training.datamodules import EndpointDataModule\n",
    "from pioneerml.evaluation.plots import (\n",
    "    plot_regression_diagnostics,\n",
    "    plot_euclidean_error_histogram,\n",
    ")\n",
    "\n",
    "PROJECT_ROOT = zenml_utils.find_project_root()\n",
    "metadata_manager = MetadataManager(root=PROJECT_ROOT)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090bd3e1",
   "metadata": {},
   "source": [
    "## List Available Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed2fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = metadata_manager.print_checkpoints(\"EndpointRegressor\")\n",
    "if not checkpoints:\n",
    "    raise ValueError(\"No checkpoints found for EndpointRegressor\")\n",
    "\n",
    "print(f\"\n",
    "Using checkpoint: {checkpoints[0]['checkpoint_path'].name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8dddde",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b2418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, metadata = metadata_manager.load_model(\n",
    "    \"EndpointRegressor\",\n",
    "    index=0,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(f\"\n",
    "Model loaded successfully on {device}\")\n",
    "print(f\"  Checkpoint: {checkpoints[0]['checkpoint_path'].name}\")\n",
    "print(f\"  Timestamp: {metadata.timestamp}\")\n",
    "print(f\"  Run: {metadata.run_name or 'unknown'}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36e1289",
   "metadata": {},
   "source": [
    "## Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e61cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_pattern = str(Path(PROJECT_ROOT) / \"data\" / \"raw_hits_info\" / \"hits_batch_*.npy\")\n",
    "info_pattern = str(Path(PROJECT_ROOT) / \"data\" / \"raw_hits_info\" / \"group_info_batch_*.npy\")\n",
    "\n",
    "validation_groups = load_hits_and_info(\n",
    "    hits_pattern=hits_pattern,\n",
    "    info_pattern=info_pattern,\n",
    "    max_files=1,\n",
    "    limit_groups=None,\n",
    "    min_hits=2,\n",
    "    include_hit_labels=False,\n",
    "    verbose=True,\n",
    ")\n",
    "validation_groups = [g for g in validation_groups if getattr(g, \"true_start\", None) is not None and getattr(g, \"true_end\", None) is not None]\n",
    "print(f\"Loaded {len(validation_groups)} groups for validation\")\n",
    "\n",
    "datamodule = EndpointDataModule(\n",
    "    records=validation_groups,\n",
    "    batch_size=128,\n",
    "    num_workers=0,\n",
    "    val_split=0.0,\n",
    "    test_split=0.0,\n",
    "    seed=42,\n",
    ")\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n",
    "val_dataset = datamodule.val_dataset or datamodule.train_dataset\n",
    "if val_dataset is None:\n",
    "    raise ValueError(\"No validation dataset available\")\n",
    "\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcea31e",
   "metadata": {},
   "source": [
    "## Generate Predictions (all quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "quantiles = [0.16, 0.50, 0.84]\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "all_preds, all_tgts = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        batch = batch.to(device)\n",
    "        preds = model(batch)    # [B, 2, 3, Q]\n",
    "        tgts = batch.y          # [B, 2, 3, Q] (targets repeated across quantiles)\n",
    "\n",
    "        preds = preds.squeeze()\n",
    "        tgts = tgts.squeeze()\n",
    "        if tgts.dim() == 5:\n",
    "            tgts = tgts.squeeze(1)\n",
    "        if preds.dim() == 3:\n",
    "            preds = preds.unsqueeze(-1)\n",
    "            tgts = tgts.unsqueeze(-1)\n",
    "\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_tgts.append(tgts.cpu())\n",
    "\n",
    "predictions = torch.cat(all_preds, dim=0)   # [N, 2, 3, Q]\n",
    "targets = torch.cat(all_tgts, dim=0)        # [N, 2, 3, Q]\n",
    "\n",
    "predictions_flat = predictions.view(predictions.size(0), -1)\n",
    "targets_flat = targets.view(targets.size(0), -1)\n",
    "\n",
    "# Median (q50) for Euclidean error plots\n",
    "preds_mid = predictions[..., 1]\n",
    "tgts_mid = targets[..., 1]\n",
    "start_pred, end_pred = preds_mid[:, 0, :], preds_mid[:, 1, :]\n",
    "start_true, end_true = tgts_mid[:, 0, :], tgts_mid[:, 1, :]\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")\n",
    "print(f\"Flattened shapes: preds={predictions_flat.shape}, targets={targets_flat.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4370dd",
   "metadata": {},
   "source": [
    "## Regression Diagnostics (all quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44730cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_names = []\n",
    "labels = [\"start\", \"end\"]\n",
    "coord_labels = [\"x\", \"y\", \"z\"]\n",
    "quant_labels = [\"q16\", \"q50\", \"q84\"]\n",
    "for le in labels:\n",
    "    for lc in coord_labels:\n",
    "        for lq in quant_labels:\n",
    "            component_names.append(f\"{le}_{lc}_{lq}\")\n",
    "\n",
    "plot_regression_diagnostics(\n",
    "    predictions=predictions_flat,\n",
    "    targets=targets_flat,\n",
    "    component_names=component_names,\n",
    "    show=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cacc954",
   "metadata": {},
   "source": [
    "## Euclidean Error (Median Quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start point\n",
    "plot_euclidean_error_histogram(\n",
    "    predictions=start_pred,\n",
    "    targets=start_true,\n",
    "    log_scale=False,\n",
    "    title=\"Endpoint start (q50): Euclidean error\",\n",
    "    show=True,\n",
    ")\n",
    "plot_euclidean_error_histogram(\n",
    "    predictions=start_pred,\n",
    "    targets=start_true,\n",
    "    log_scale=True,\n",
    "    title=\"Endpoint start (q50): Euclidean error (log scale)\",\n",
    "    show=True,\n",
    ")\n",
    "\n",
    "# End point\n",
    "plot_euclidean_error_histogram(\n",
    "    predictions=end_pred,\n",
    "    targets=end_true,\n",
    "    log_scale=False,\n",
    "    title=\"Endpoint end (q50): Euclidean error\",\n",
    "    show=True,\n",
    ")\n",
    "plot_euclidean_error_histogram(\n",
    "    predictions=end_pred,\n",
    "    targets=end_true,\n",
    "    log_scale=True,\n",
    "    title=\"Endpoint end (q50): Euclidean error (log scale)\",\n",
    "    show=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
