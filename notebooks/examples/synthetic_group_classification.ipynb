{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3be7ff1",
   "metadata": {},
   "source": [
    "# Synthetic Group Classification (Pipeline Tutorial)\n",
    "\n",
    "This notebook mirrors the Python script example using the PIONEER ML pipeline. We:\n",
    "- Detect GPU/MPS/CPU and configure Lightning accordingly\n",
    "- Generate synthetic graph records with three binary labels\n",
    "- Wrap the data in `GroupClassificationDataModule`\n",
    "- Train `GroupClassifier` through `LightningTrainStage`\n",
    "- Visualize losses, per-class predictions, confusion matrices, and probability histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44384fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Add project root to path (assumes notebook sits in notebooks/examples)\n",
    "cwd = Path().resolve()\n",
    "ROOT = None\n",
    "for parent in [cwd] + list(cwd.parents):\n",
    "    if (parent / \"src\" / \"pioneerml\").exists():\n",
    "        ROOT = parent\n",
    "        break\n",
    "if ROOT is None:\n",
    "    raise RuntimeError(\"Could not find project root containing src/pioneerml\")\n",
    "sys.path.append(str(ROOT / \"src\"))\n",
    "\n",
    "from pioneerml.data.datasets.graph_group import GraphRecord\n",
    "from pioneerml.training.datamodules import GroupClassificationDataModule\n",
    "from pioneerml.models import GroupClassifier\n",
    "from pioneerml.training import GraphLightningModule, CleanProgressBar, default_precision_for_accelerator\n",
    "from pioneerml.pipelines import Pipeline, Context\n",
    "from pioneerml.pipelines.stage import StageConfig\n",
    "from pioneerml.pipelines.stages import LightningTrainStage\n",
    "\n",
    "pl.seed_everything(123, workers=True)\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "plt.style.use(\"seaborn-v0_8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b5c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label thresholds\n",
    "ENERGY_THRESHOLD = 25.0\n",
    "HIT_THRESHOLD = 18\n",
    "SPREAD_THRESHOLD = 1.0  # std > 1 counts as wide\n",
    "\n",
    "CLASS_CONFIG = [\n",
    "    (\"High energy\", \"total_energy\", ENERGY_THRESHOLD),\n",
    "    (\"High hit count\", \"num_hits\", HIT_THRESHOLD),\n",
    "    (\"Wide spatial spread\", \"spread\", SPREAD_THRESHOLD),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52579930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_device():\n",
    "    \"\"\"Pick accelerator/devices/device triple for Lightning and torch.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return \"gpu\", 1, torch.device(\"cuda\")\n",
    "    if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        return \"mps\", 1, torch.device(\"mps\")\n",
    "    return \"cpu\", 1, torch.device(\"cpu\")\n",
    "\n",
    "accelerator, devices, device = choose_device()\n",
    "pin_memory = accelerator in {\"gpu\", \"cuda\"}\n",
    "print(f\"Using accelerator={accelerator}, devices={devices}, torch device={device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe13bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_record(idx: int, rng: np.random.Generator) -> GraphRecord:\n",
    "    \"\"\"Create one synthetic GraphRecord with metric-driven labels.\"\"\"\n",
    "    num_hits = int(rng.integers(6, 40))\n",
    "    spread_scale = float(rng.choice([0.35, 0.6, 1.4]))\n",
    "\n",
    "    coord = rng.normal(loc=rng.normal(0.0, 0.5), scale=spread_scale, size=num_hits)\n",
    "    z = rng.normal(\n",
    "        loc=rng.normal(0.2, 0.6), scale=spread_scale * rng.uniform(0.8, 1.3), size=num_hits\n",
    "    )\n",
    "    energy = rng.gamma(shape=rng.uniform(1.2, 2.0), scale=rng.uniform(2.5, 4.5), size=num_hits)\n",
    "    view = rng.integers(0, 2, size=num_hits)\n",
    "\n",
    "    total_energy = float(energy.sum())\n",
    "    spread = float(np.sqrt(coord.std() ** 2 + z.std() ** 2))\n",
    "\n",
    "    high_energy = total_energy > ENERGY_THRESHOLD\n",
    "    high_hits = num_hits > HIT_THRESHOLD\n",
    "    wide_spread = spread > SPREAD_THRESHOLD\n",
    "\n",
    "    labels = []\n",
    "    if high_energy:\n",
    "        labels.append(0)\n",
    "    if high_hits:\n",
    "        labels.append(1)\n",
    "    if wide_spread:\n",
    "        labels.append(2)\n",
    "\n",
    "    record = GraphRecord(\n",
    "        coord=coord,\n",
    "        z=z,\n",
    "        energy=energy,\n",
    "        view=view,\n",
    "        labels=labels,\n",
    "        event_id=idx,\n",
    "        group_id=idx,\n",
    "    )\n",
    "    record.metrics = {\n",
    "        \"total_energy\": total_energy,\n",
    "        \"num_hits\": num_hits,\n",
    "        \"spread\": spread,\n",
    "        \"high_energy\": high_energy,\n",
    "        \"high_hit_count\": high_hits,\n",
    "        \"wide_spread\": wide_spread,\n",
    "    }\n",
    "    return record\n",
    "\n",
    "\n",
    "def build_dataset(num_samples: int, seed: int = 7) -> list[GraphRecord]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return [generate_synthetic_record(i, rng) for i in range(num_samples)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0636f256",
   "metadata": {},
   "source": [
    "Generate synthetic records and inspect the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ce067",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = build_dataset(240, seed=7)\n",
    "print(\n",
    "    f\"First sample -> total_energy={records[0].metrics['total_energy']:.2f}, \"\n",
    "    f\"hits={records[0].metrics['num_hits']}, spread={records[0].metrics['spread']:.2f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datamodule(records: list[GraphRecord], batch_size: int = 32) -> GroupClassificationDataModule:\n",
    "    dm = GroupClassificationDataModule(\n",
    "        records,\n",
    "        num_classes=3,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        pin_memory=pin_memory,\n",
    "        val_split=0.2,\n",
    "        seed=123,\n",
    "    )\n",
    "    dm.setup()\n",
    "    return dm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = build_datamodule(records, batch_size=32)\n",
    "print(f\"Train graphs: {len(datamodule.train_dataset)}, val graphs: {len(datamodule.val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecefd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_pipeline(datamodule, accelerator: str, devices: int, max_epochs: int = 15):\n",
    "    model = GroupClassifier(num_classes=3, hidden=128, num_blocks=2, heads=4, dropout=0.1)\n",
    "    lightning_module = GraphLightningModule(\n",
    "        model,\n",
    "        task=\"classification\",\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "    )\n",
    "\n",
    "    train_stage = LightningTrainStage(\n",
    "        config=StageConfig(\n",
    "            name=\"train_synthetic_classifier\",\n",
    "            params={\n",
    "                \"module\": lightning_module,\n",
    "                \"datamodule\": datamodule,\n",
    "                \"trainer_params\": {\n",
    "                    \"accelerator\": accelerator,\n",
    "                    \"devices\": devices,\n",
    "                    \"max_epochs\": max_epochs,\n",
    "                    \"logger\": False,\n",
    "                    \"enable_checkpointing\": False,\n",
    "                    \"precision\": default_precision_for_accelerator(accelerator),\n",
    "                    \"enable_model_summary\": True,\n",
    "                    \"enable_progress_bar\": False,\n",
    "                    \"callbacks\": [CleanProgressBar(bar_width=30)],\n",
    "                },\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(stages=[train_stage], name=\"synthetic_classification_pipeline\")\n",
    "    ctx = pipeline.run(Context())\n",
    "    return ctx[\"lightning_module\"], ctx[\"trainer\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8a751",
   "metadata": {},
   "source": [
    "Train the model via the pipeline wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_module, trainer = train_with_pipeline(datamodule, accelerator=accelerator, devices=devices, max_epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc205be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(module: GraphLightningModule):\n",
    "    train_loss = module.train_epoch_loss_history\n",
    "    val_loss = module.val_epoch_loss_history\n",
    "    if len(val_loss) > len(train_loss):\n",
    "        val_loss = val_loss[1:]\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    train_epochs = np.arange(1, len(train_loss) + 1)\n",
    "    plt.plot(train_epochs, train_loss, label=\"Train\")\n",
    "    if val_loss:\n",
    "        val_epochs = np.arange(1, len(val_loss) + 1)\n",
    "        plt.plot(val_epochs, val_loss, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training vs validation loss\")\n",
    "    plt.legend(loc=\"center left\", bbox_to_anchor=(1.02, 0.5), borderaxespad=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b392d",
   "metadata": {},
   "source": [
    "Plot training and validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec76c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(lightning_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_validation_outputs(module: GraphLightningModule, datamodule: GroupClassificationDataModule):\n",
    "    module.eval()\n",
    "    device = next(module.parameters()).device\n",
    "\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "    metrics = []\n",
    "\n",
    "    num_classes = getattr(getattr(module, \"model\", module), \"num_classes\", None)\n",
    "    if num_classes is None and hasattr(datamodule, \"train_dataset\") and datamodule.train_dataset is not None:\n",
    "        base_ds = getattr(datamodule.train_dataset, \"dataset\", None)\n",
    "        num_classes = getattr(base_ds, \"num_classes\", None)\n",
    "\n",
    "    def _ensure_2d(arr: np.ndarray) -> np.ndarray:\n",
    "        arr = np.asarray(arr)\n",
    "        if arr.ndim == 1 and num_classes:\n",
    "            if arr.size % num_classes == 0:\n",
    "                return arr.reshape(-1, num_classes)\n",
    "        if arr.ndim == 1:\n",
    "            return arr[:, None]\n",
    "        return arr\n",
    "\n",
    "    def _metrics_from_data(g):\n",
    "        if hasattr(g, \"_raw\") and getattr(g._raw, \"metrics\", None) is not None:\n",
    "            return g._raw.metrics\n",
    "        x = g.x\n",
    "        coord = x[:, 0].cpu().numpy()\n",
    "        z = x[:, 1].cpu().numpy()\n",
    "        energy = x[:, 2].cpu().numpy()\n",
    "        total_energy = float(energy.sum())\n",
    "        spread = float(np.sqrt(coord.std() ** 2 + z.std() ** 2))\n",
    "        num_hits = int(x.shape[0])\n",
    "        return {\n",
    "            \"total_energy\": total_energy,\n",
    "            \"num_hits\": num_hits,\n",
    "            \"spread\": spread,\n",
    "            \"high_energy\": total_energy > ENERGY_THRESHOLD,\n",
    "            \"high_hit_count\": num_hits > HIT_THRESHOLD,\n",
    "            \"wide_spread\": spread > SPREAD_THRESHOLD,\n",
    "        }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in datamodule.val_dataloader():\n",
    "            batch = batch.to(device)\n",
    "            logits = module(batch)\n",
    "            all_probs.append(torch.sigmoid(logits).cpu())\n",
    "            all_targets.append(batch.y.cpu())\n",
    "            metrics.extend([_metrics_from_data(g) for g in batch.to_data_list()])\n",
    "\n",
    "    probs = torch.cat(all_probs, dim=0).numpy() if all_probs else np.zeros((0, 3))\n",
    "    targets = torch.cat(all_targets, dim=0).numpy() if all_targets else np.zeros((0, 3))\n",
    "\n",
    "    probs = _ensure_2d(probs)\n",
    "    targets = _ensure_2d(targets)\n",
    "    return probs, targets, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9e241",
   "metadata": {},
   "source": [
    "Collect validation predictions/labels for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d51a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, targets, metrics = collect_validation_outputs(lightning_module, datamodule)\n",
    "print(probs.shape, targets.shape, len(metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_predictions(probs, targets, metrics):\n",
    "    for class_idx, (label, metric_key, threshold) in enumerate(CLASS_CONFIG):\n",
    "        if probs.size == 0 or targets.size == 0:\n",
    "            print(\"Warning: empty validation predictions/targets; skipping class plots.\")\n",
    "            return\n",
    "        values = np.array([m[metric_key] for m in metrics], dtype=float)\n",
    "        preds_binary = (probs[:, class_idx] > 0.5).astype(int)\n",
    "        truth = targets[:, class_idx].astype(int)\n",
    "        incorrect = preds_binary != truth\n",
    "        colors = np.where(preds_binary == 1, \"tab:green\", \"tab:red\")\n",
    "        xs = np.arange(len(values))\n",
    "\n",
    "        plt.figure(figsize=(9, 3))\n",
    "        plt.scatter(xs, values, c=colors, alpha=0.7, label=\"Prediction\")\n",
    "        if incorrect.any():\n",
    "            plt.scatter(\n",
    "                xs[incorrect],\n",
    "                values[incorrect],\n",
    "                marker=\"x\",\n",
    "                color=\"black\",\n",
    "                s=80,\n",
    "                label=\"Incorrect\",\n",
    "            )\n",
    "        plt.axhline(threshold, color=\"k\", linestyle=\"--\", label=f\"Truth threshold = {threshold}\")\n",
    "        plt.xlabel(\"Validation sample index\")\n",
    "        plt.ylabel(label)\n",
    "        plt.title(f\"{label}: green=pred 1, red=pred 0\")\n",
    "        plt.legend(loc=\"center left\", bbox_to_anchor=(1.02, 0.5), borderaxespad=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c90cdbd",
   "metadata": {},
   "source": [
    "Visualize predictions per class against the generating metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_predictions(probs, targets, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrices(probs, targets):\n",
    "    preds_binary = (probs > 0.5).astype(int)\n",
    "    class_names = [cfg[0] for cfg in CLASS_CONFIG]\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(class_names), figsize=(15, 4))\n",
    "    for class_idx, ax in enumerate(axes):\n",
    "        y_true = targets[:, class_idx].flatten()\n",
    "        y_pred = preds_binary[:, class_idx].flatten()\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sns.heatmap(\n",
    "            cm,\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=\"Blues\",\n",
    "            ax=ax,\n",
    "            xticklabels=[\"Negative\", \"Positive\"],\n",
    "            yticklabels=[\"Negative\", \"Positive\"],\n",
    "            cbar=False,\n",
    "        )\n",
    "        ax.set_title(f\"{class_names[class_idx]} Confusion Matrix\")\n",
    "        ax.set_ylabel(\"True Label\")\n",
    "        ax.set_xlabel(\"Predicted Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a808e11",
   "metadata": {},
   "source": [
    "Confusion matrices per class (binary heads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices(probs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probability_histograms(probs, targets):\n",
    "    class_names = [cfg[0] for cfg in CLASS_CONFIG]\n",
    "    fig, axes = plt.subplots(1, len(class_names), figsize=(15, 4))\n",
    "\n",
    "    for class_idx, ax in enumerate(axes):\n",
    "        y_true = targets[:, class_idx].flatten()\n",
    "        pos_probs = probs[y_true == 1, class_idx]\n",
    "        neg_probs = probs[y_true == 0, class_idx]\n",
    "\n",
    "        ax.hist(neg_probs, bins=20, alpha=0.5, label=\"True Negative\", color=\"red\")\n",
    "        ax.hist(pos_probs, bins=20, alpha=0.5, label=\"True Positive\", color=\"blue\")\n",
    "        ax.axvline(0.5, color=\"black\", linestyle=\"--\", linewidth=2, label=\"Threshold (0.5)\")\n",
    "        ax.set_xlabel(\"Predicted Probability\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_title(f\"{class_names[class_idx]} - Probability Distribution\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(loc=\"center left\", bbox_to_anchor=(1.02, 0.5), borderaxespad=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91373c0",
   "metadata": {},
   "source": [
    "Probability distributions for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad50e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probability_histograms(probs, targets)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
