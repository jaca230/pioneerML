{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7561695",
   "metadata": {},
   "source": [
    "# Tutorial 3: Hyperparameter Tuning with Optuna\n",
    "\n",
    "Run a ZenML pipeline that performs a short Optuna sweep and then trains a\n",
    "model with the best parameters found.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from pioneerml.zenml import load_step_output\n",
    "from pioneerml.zenml import utils as zenml_utils\n",
    "from pioneerml.zenml.pipelines import hyperparameter_tuning_pipeline\n",
    "\n",
    "if \"__file__\" in globals():\n",
    "    PROJECT_ROOT = Path(__file__).resolve().parents[2]\n",
    "else:\n",
    "    PROJECT_ROOT = Path.cwd().resolve()\n",
    "\n",
    "zenml_client = zenml_utils.setup_zenml_for_notebook(root_path=PROJECT_ROOT, use_in_memory=True)\n",
    "print(f\"ZenML ready. Stack: {zenml_client.active_stack_model.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2955f00f",
   "metadata": {},
   "source": [
    "## Run the tuning pipeline\n",
    "The pipeline generates synthetic data, runs a small Optuna search, and trains\n",
    "a final model with the best hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb0f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = hyperparameter_tuning_pipeline.with_options(enable_cache=False)(n_trials=2)\n",
    "print(f\"Pipeline run {run.name} status: {run.status}\")\n",
    "\n",
    "trained_module = load_step_output(run, \"train_with_best_params\")\n",
    "datamodule = load_step_output(run, \"prepare_tuning_datamodule\")\n",
    "best_params = load_step_output(run, \"hyperparameter_search\")\n",
    "\n",
    "if trained_module is None or datamodule is None or best_params is None:\n",
    "    raise RuntimeError(\"Could not load artifacts from the hyperparameter_tuning_pipeline run.\")\n",
    "\n",
    "trained_module.eval()\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"- {key}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d611d175",
   "metadata": {},
   "source": [
    "## Evaluate the tuned model\n",
    "Run a quick accuracy check on the validation split using the tuned model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = next(trained_module.parameters()).device\n",
    "val_loader = datamodule.val_dataloader()\n",
    "if isinstance(val_loader, list) and len(val_loader) == 0:\n",
    "    val_loader = datamodule.train_dataloader()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for batch in val_loader:\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = trained_module(batch)\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    labels = torch.argmax(batch.y, dim=1)\n",
    "    correct += int((preds == labels).sum().item())\n",
    "    total += int(labels.numel())\n",
    "\n",
    "accuracy = correct / total if total else 0.0\n",
    "print(f\"Tuned model validation accuracy: {accuracy:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}