{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {},
 "cells": [
  {
   "id": "b09822fb",
   "cell_type": "markdown",
   "source": "# Validate Pion Stop Regressor",
   "metadata": {}
  },
  {
   "id": "0e771ed1",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "import json\nfrom pathlib import Path\nfrom datetime import datetime\n\nimport torch\n\nfrom pioneerml.zenml import utils as zenml_utils\nfrom pioneerml.training.lightning import GraphLightningModule\n\nfrom pioneerml.models.regressors import PionStopRegressor\nfrom pioneerml.data.loaders import load_pion_stop_groups\nfrom pioneerml.training.datamodules import PionStopDataModule\nfrom pioneerml.evaluation import plot_regression_diagnostics\n\nPROJECT_ROOT = zenml_utils.find_project_root()\ncheckpoints_dir = Path(PROJECT_ROOT) / 'trained_models' / 'pion_stop'\ncheckpoints_dir.mkdir(parents=True, exist_ok=True)\nprint(f'Project root: {PROJECT_ROOT}')\nprint(f'Checkpoints directory: {checkpoints_dir}')\n",
   "outputs": []
  },
  {
   "id": "0b3f23a6",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Load latest checkpoint\ncheckpoint_files = sorted(checkpoints_dir.glob('pion_stop_*.pt'), reverse=True)\nif not checkpoint_files:\n    raise ValueError('No pion_stop checkpoints found')\nselected_checkpoint = checkpoint_files[0]\nstate_dict = torch.load(selected_checkpoint, map_location='cpu')\nmodel = PionStopRegressor()\nmodel.load_state_dict(state_dict)\nmodel.eval()\nprint(f'Loaded checkpoint: {selected_checkpoint.name}')\n",
   "outputs": []
  },
  {
   "id": "4a0f69b7",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Load validation data\nfile_pattern = str(Path(PROJECT_ROOT) / 'data' / 'pionStopGroups_*.npy')\nrecords = load_pion_stop_groups(file_pattern, max_files=None, verbose=True)\ndatamodule = PionStopDataModule(records=records, batch_size=128, num_workers=0, val_split=0.0)\ndatamodule.setup('fit')\nval_dataset = datamodule.val_dataset or datamodule.train_dataset\nprint(f'Validation size: {len(val_dataset)}')\n",
   "outputs": []
  },
  {
   "id": "6cf89eeb",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Predict\nfrom torch_geometric.loader import DataLoader\nloader = DataLoader(val_dataset, batch_size=128, shuffle=False)\nall_preds, all_targets = [], []\nwith torch.no_grad():\n    for batch in loader:\n        preds = model(batch)\n        all_preds.append(preds.cpu())\n        all_targets.append(batch.y.cpu())\npredictions = torch.cat(all_preds, dim=0)\ntargets = torch.cat(all_targets, dim=0)\nprint(predictions.shape, targets.shape)\n",
   "outputs": []
  },
  {
   "id": "34430bd1",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Plots\nplot_regression_diagnostics(predictions=predictions, targets=targets, show=True)\n",
   "outputs": []
  }
 ]
}