{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e310e5",
   "metadata": {},
   "source": [
    "# Quickstart: Train and Evaluate a Graph Classifier\n",
    "Train a GroupClassifier on synthetic data, then evaluate with standardized metrics and plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from pioneerml.models import GroupClassifier\n",
    "from pioneerml.training import GraphLightningModule, GraphDataModule, plot_loss_curves\n",
    "from pioneerml.pipelines import Pipeline, Context, StageConfig\n",
    "from pioneerml.pipelines.stages import LightningTrainStage, EvaluateStage, CollectPredsStage\n",
    "from pioneerml.evaluation import (\n",
    "    plot_multilabel_confusion_matrix,\n",
    "    plot_precision_recall_curves,\n",
    "    resolve_preds_targets,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce9fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_synthetic_group(num_nodes=16, num_classes=3):\n",
    "    # Class-specific offsets with some overlap so the task is non-trivial\n",
    "    class_offsets = torch.tensor([\n",
    "        [1.0, 0.0, 0.0, 0.0, 0.0],  # pi-ish\n",
    "        [0.0, 1.0, 0.0, 0.0, 0.0],  # mu-ish\n",
    "        [0.0, 0.0, 1.0, 0.0, 0.0],  # e+ ish\n",
    "    ])\n",
    "    label = torch.randint(0, num_classes, (1,)).item()\n",
    "    x = torch.randn(num_nodes, 5) * 1.2 + class_offsets[label]\n",
    "    edge_index = torch.randint(0, num_nodes, (2, num_nodes * 2))\n",
    "    edge_attr = torch.randn(edge_index.shape[1], 4)\n",
    "    y = torch.zeros(num_classes)\n",
    "    y[label] = 1.0  # one-hot label\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "records = [make_synthetic_group() for _ in range(256)]\n",
    "datamodule = GraphDataModule(dataset=records, val_split=0.25, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GroupClassifier(num_classes=3)\n",
    "lightning_module = GraphLightningModule(model, task='classification', lr=5e-4)\n",
    "\n",
    "train_stage = LightningTrainStage(\n",
    "    config=StageConfig(\n",
    "        name='train',\n",
    "        params={\n",
    "            'module': lightning_module,\n",
    "            'datamodule': datamodule,\n",
    "            'trainer_params': {\n",
    "                'max_epochs': 10,\n",
    "                'limit_train_batches': 5,\n",
    "                'limit_val_batches': 1,\n",
    "                'logger': False,\n",
    "                'enable_checkpointing': False,\n",
    "            },\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "collect_stage = CollectPredsStage(\n",
    "    config=StageConfig(\n",
    "        name='collect_preds',\n",
    "        inputs=['lightning_module', 'datamodule'],\n",
    "        outputs=['preds', 'targets'],\n",
    "        params={\n",
    "            'dataloader': 'val',\n",
    "            'preds_key': 'preds',\n",
    "            'targets_key': 'targets',\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "eval_stage = EvaluateStage(\n",
    "    config=StageConfig(\n",
    "        name='evaluate',\n",
    "        inputs=['preds', 'targets'],\n",
    "        outputs=['metrics'],\n",
    "        params={\n",
    "            'task': 'multilabel',\n",
    "            'plots': ['multilabel_confusion', 'precision_recall'],\n",
    "            'save_dir': 'outputs/tutorial_quickstart',\n",
    "            'metric_params': {'class_names': ['pi', 'mu', 'e+']},\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([train_stage, collect_stage, eval_stage], name='quickstart')\n",
    "ctx = pipeline.run(Context())\n",
    "ctx['metrics']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5887daf9",
   "metadata": {},
   "source": [
    "## Loss curves\n",
    "Training/validation loss should trend down; divergence can signal overfitting or learning-rate issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c25815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ = plot_loss_curves(\n",
    "    ctx['lightning_module'],\n",
    "    title='Training/Validation Loss (quickstart)',\n",
    "    xlabel='Epoch',\n",
    "    show=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e537be6",
   "metadata": {},
   "source": [
    "## Metrics and plots\n",
    "Precisionâ€“recall curves come from sweeping the decision threshold; confusion matrices show class-wise true/false positives/negatives (normalized to sum to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d2166",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds, targets = resolve_preds_targets(ctx)\n",
    "\n",
    "plot_multilabel_confusion_matrix(\n",
    "    predictions=preds,\n",
    "    targets=targets,\n",
    "    class_names=['pi', 'mu', 'e+'],\n",
    "    threshold=0.5,\n",
    "    normalize=True,\n",
    "    show=True,\n",
    ")\n",
    "\n",
    "plot_precision_recall_curves(\n",
    "    predictions=preds,\n",
    "    targets=targets,\n",
    "    class_names=['pi', 'mu', 'e+'],\n",
    "    show=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
